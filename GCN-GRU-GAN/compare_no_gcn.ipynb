{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Image, display\n",
    "from datetime import date, timedelta\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import *\n",
    "from sklearn import preprocessing\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "def build_area_seqs(target_area, start='2016-08-01', end='2017-01-01'):\n",
    "    # 整合到一个文件中\n",
    "    area_df = pd.DataFrame()\n",
    "    for name in target_area.parking_name:\n",
    "        file_name = 'generated/data/seqs/'+name+'_seq.csv'\n",
    "        file_df = pd.read_csv(file_name)\n",
    "        file_df['parking'] = nks[name]\n",
    "        cols = file_df.columns.tolist()\n",
    "        cols = [cols[0], cols[2], cols[1]]\n",
    "        file_df = file_df[cols]\n",
    "        if len(area_df)>0:\n",
    "            area_df = pd.concat([area_df, file_df])\n",
    "        else:\n",
    "            area_df = file_df\n",
    "\n",
    "    out_bound_indexes = area_df[(area_df['date'] < start) | (area_df['date'] >= end)].index \n",
    "    area_df.drop(out_bound_indexes, inplace = True) \n",
    "    return area_df.pivot_table('occupy', ['date'], 'parking')\n",
    "\n",
    "\n",
    "def get_nodes_features(area_df):\n",
    "    node_f = area_df[['total_space','monthly_fee','building_type']]\n",
    "    node_f.loc[:,['total_space', 'monthly_fee']] = min_max_scaler.fit_transform(node_f[['total_space', 'monthly_fee']])\n",
    "    building_type_oneHot = pd.get_dummies(node_f['building_type'])\n",
    "    node_f = node_f.drop('building_type',axis = 1)\n",
    "    node_f = node_f.join(building_type_oneHot)\n",
    "    return node_f\n",
    "\n",
    "def max_min_scale(raw):\n",
    "    x_scaled = min_max_scaler.fit_transform(raw.numpy())\n",
    "    return pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_info_df = pd.read_csv('generated/data/parkings_info.csv')\n",
    "basic_info_df['lat_long'] = list(zip(basic_info_df['latitude'], basic_info_df['longitude']))\n",
    "\n",
    "from graph_utils import build_graph\n",
    "\n",
    "target_park = '大信大厦'\n",
    "use_gcn=False\n",
    "graph_nodes_max_dis = 0.5 if use_gcn else 0.1\n",
    "\n",
    "target_area, adj, target_map, nks, kns = build_graph(basic_info_df, target_park, max_dis=graph_nodes_max_dis)\n",
    "target_park_basic_info = basic_info_df.loc[basic_info_df.parking_name == target_park].iloc[0]\n",
    "key = nks[target_park]\n",
    "node_f = get_nodes_features(target_area)\n",
    "seqs_raw = build_area_seqs(target_area , start='2016-06-02', end='2016-08-04')\n",
    "seqs_normal = seqs_raw.copy().fillna(0)\n",
    "seqs_normal[seqs_normal.columns.values] = min_max_scaler.fit_transform(seqs_normal[seqs_normal.columns.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using local port 21193\n",
      "INFO:tensorflow:Using local port 17282\n",
      "INFO:tensorflow:Using local port 23957\n",
      "INFO:tensorflow:Using local port 16997\n",
      "INFO:tensorflow:Using local port 18490\n",
      "INFO:tensorflow:Using local port 21323\n",
      "INFO:tensorflow:Using local port 15833\n",
      "INFO:tensorflow:Using local port 15335\n",
      "INFO:tensorflow:Using local port 23242\n",
      "INFO:tensorflow:Using local port 16635\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from abc import ABC\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dropout, GRU, Flatten, Dense, LeakyReLU\n",
    "from spektral.layers import GraphConv\n",
    "\n",
    "l2_reg = 5e-4 / 2  # L2 regularization rate\n",
    "\n",
    "\n",
    "class Generator(Model, ABC):\n",
    "\n",
    "    def __init__(self, adj, nodes_features, base=8, dropout=0.5):\n",
    "        super(Generator, self).__init__()\n",
    "        self.adj = adj\n",
    "        self.nodes_features = nodes_features\n",
    "\n",
    "        self.dropout = Dropout(dropout)\n",
    "        self.flatten = Flatten()\n",
    "        self.graph_conv_1 = GraphConv(128,\n",
    "                                      activation='elu',\n",
    "                                      kernel_regularizer=l2(l2_reg),\n",
    "                                      use_bias=False)\n",
    "        self.graph_conv_2 = GraphConv(64,\n",
    "                                      activation='elu',\n",
    "                                      kernel_regularizer=l2(l2_reg),\n",
    "                                      use_bias=False)\n",
    "        self.dense_1 = Dense(256, activation='relu')\n",
    "        self.dense_2 = Dense(512, activation='relu')\n",
    "        self.gru = GRU(128, return_sequences=True)\n",
    "        self.final_dense = Dense(1, activation='tanh')\n",
    "\n",
    "    def call(self, seq, training=True):\n",
    "        s = tf.convert_to_tensor(seq)  # S*N\n",
    "        \n",
    "        if use_gcn:\n",
    "            f = tf.convert_to_tensor(self.nodes_features)  # N*F\n",
    "            g = tf.convert_to_tensor(self.adj)  # N*N\n",
    "            c = self.graph_conv_1([f, g])  # N*Cov1\n",
    "            c = self.graph_conv_2([c, g])  # N*Cov2\n",
    "            s = tf.matmul(s, c)  # S*N x N*Cov2\n",
    "\n",
    "        fc = self.dense_1(s)  # S*D1\n",
    "        fc = self.dropout(fc, training=training)\n",
    "        fc = self.dense_2(fc)  # S*D2\n",
    "        fc = self.dropout(fc, training=training)\n",
    "\n",
    "        fc = tf.expand_dims(fc, axis=0) \n",
    "        ro = self.gru(fc)\n",
    "        ro = tf.squeeze(ro, axis=0)  # S*R\n",
    "        return self.final_dense(ro)  # S*1\n",
    "\n",
    "\n",
    "class Discriminator(Model, ABC):\n",
    "\n",
    "    def __init__(self, adj, nodes_features, base=8, dropout=0.5, alpha=0.2):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.adj = adj\n",
    "        self.nodes_features = nodes_features\n",
    "\n",
    "        self.leaky_relu = LeakyReLU(alpha=alpha)\n",
    "        self.dropout = Dropout(dropout)\n",
    "        self.flatten = Flatten()\n",
    "        self.graph_conv_1 = GraphConv(128,\n",
    "                                      activation='elu',\n",
    "                                      kernel_regularizer=l2(l2_reg),\n",
    "                                      use_bias=False)\n",
    "        self.graph_conv_2 = GraphConv(64,\n",
    "                                      activation='elu',\n",
    "                                      kernel_regularizer=l2(l2_reg),\n",
    "                                      use_bias=False)\n",
    "        self.dense_1 = Dense(256)\n",
    "        self.dense_2 = Dense(512)\n",
    "        self.gru = GRU(128, return_sequences=True)\n",
    "        self.final_dense = Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, seq, training=True):\n",
    "        s = tf.convert_to_tensor(seq)  # S*N\n",
    "        \n",
    "        if use_gcn:\n",
    "            f = tf.convert_to_tensor(self.nodes_features)  # N*F\n",
    "            g = tf.convert_to_tensor(self.adj)  # N*N\n",
    "            c = self.graph_conv_1([f, g])  # N*Cov1\n",
    "            c = self.graph_conv_2([c, g])  # N*Cov2\n",
    "            s = tf.matmul(s, c)  # S*N x N*Cov2\n",
    "        \n",
    "        fc = self.dense_1(s)  # S*D1\n",
    "        fc = self.leaky_relu(fc)\n",
    "        fc = self.dropout(fc, training=training)\n",
    "        fc = self.dense_2(fc)  # S*D2\n",
    "        fc = self.leaky_relu(fc)\n",
    "        fc = self.dropout(fc, training=training)\n",
    "\n",
    "        fc = tf.expand_dims(fc, axis=0)\n",
    "        ro = self.gru(fc)\n",
    "        ro = tf.squeeze(ro, axis=0)  # S*R\n",
    "        return self.final_dense(ro)  # S*1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from spektral.utils import normalized_laplacian\n",
    "# from model import Generator, Discriminator\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "save_week_interval = 10\n",
    "save_all_interval = 100\n",
    "\n",
    "class Train:\n",
    "    def __init__(self, seqs, adj, nodes_features, epochs=1000,\n",
    "                 lr = 1e-3, adam_beta_1 = 0.5, base=8, dropout=0.5, alpha=0.2):\n",
    "        self.epochs = epochs\n",
    "        self.seqs = seqs.astype('float32')\n",
    "\n",
    "        self.gen_optimizer = Adam(lr, adam_beta_1)\n",
    "        self.desc_optimizer = Adam(lr, adam_beta_1)\n",
    "\n",
    "        self.adj = normalized_laplacian(adj.astype('float32'))\n",
    "        self.nodes_features = nodes_features.astype('float32')\n",
    "        self.generator = Generator(self.adj, self.nodes_features, base, dropout)\n",
    "        self.discriminator = Discriminator(self.adj, self.nodes_features, base, dropout, alpha)\n",
    "        self.cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "    def __call__(self, epochs=None ,save_path='generated/'):\n",
    "        save_path += str(time.time())\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        if epochs is None:\n",
    "            epochs = self.epochs\n",
    "            \n",
    "        time_len = self.seqs.shape[0]\n",
    "        num_nodes = self.seqs.shape[1]\n",
    "        total_batch = int(time_len / batch_size)  # 2976/96=31\n",
    "\n",
    "        time_consumed_total = 0.\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            start = time.time()\n",
    "            total_gen_loss = 0\n",
    "            total_disc_loss = 0\n",
    "\n",
    "            for week in range(0, total_batch):\n",
    "                current_seqs = self.seqs[week*batch_size:week*batch_size + batch_size]\n",
    "                seqs_noised = current_seqs.copy()\n",
    "                max_s = current_seqs[key].max()\n",
    "                seqs_noised[key] = np.random.normal(max_s / 2.0, max_s / 10.0,\n",
    "                                                         size=(current_seqs.shape[0])).astype('float32')\n",
    "                gen_loss, disc_loss = self.train_step(current_seqs, seqs_noised)\n",
    "                total_gen_loss += gen_loss\n",
    "                total_disc_loss += disc_loss\n",
    "\n",
    "            time_consumed = time.time() - start\n",
    "            time_consumed_total += time_consumed\n",
    "            time_consumed_agv = time_consumed_total / epoch\n",
    "            epochs_last = epochs - epoch\n",
    "            estimate_time_last = epochs_last * time_consumed_agv\n",
    "            print('epoch {}({})/{}({}) - gen_loss = {}, disc_loss = {}, estimated to finish: {}'\n",
    "              .format(epoch, round(time.time() - start, 2),\n",
    "                      epochs, round(time_consumed_total, 2),\n",
    "                      round(float(total_gen_loss / total_batch), 5),\n",
    "                      round(float(total_disc_loss / total_batch), 5),\n",
    "                      round(estimate_time_last, 2)))\n",
    "            \n",
    "            if epoch % save_week_interval == 0:\n",
    "                self.compare_plot('week_'+str(epoch), save_path, int(total_batch/2)*7)\n",
    "            if epoch % save_all_interval == 0:\n",
    "                self.compare_plot('all_'+str(epochs), save_path, 0, total_batch) \n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, seqs, seqs_noised):\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            real_output = self.discriminator(seqs)  # 评价高\n",
    "            generated = self.generator(seqs_noised)\n",
    "            left = tf.slice(seqs, [0, 0], [batch_size, key])\n",
    "            right = tf.slice(seqs, [0, key + 1], [batch_size, -1])\n",
    "            combined = tf.concat([left, generated, right], 1)\n",
    "            generated_output = self.discriminator(combined)  # 初始评价低\n",
    "\n",
    "            loss_g = self.generator_loss(self.cross_entropy, generated_output)\n",
    "            loss_d = self.discriminator_loss(self.cross_entropy, real_output, generated_output)\n",
    "\n",
    "        grad_gen = tape.gradient(loss_g, self.generator.trainable_variables)\n",
    "        grad_disc = tape.gradient(loss_d, self.discriminator.trainable_variables)\n",
    "\n",
    "        self.gen_optimizer.apply_gradients(zip(grad_gen, self.generator.trainable_variables))\n",
    "        self.desc_optimizer.apply_gradients(zip(grad_disc, self.discriminator.trainable_variables))\n",
    "\n",
    "        return loss_g, loss_d\n",
    "\n",
    "    def generate_first(self):\n",
    "        import random as random\n",
    "        week = 1 # random.randint(0,31)\n",
    "        seqs_replace = self.seqs[week*batch_size:week*batch_size + batch_size].copy()\n",
    "        max_s = seqs_replace[key].max()\n",
    "        seqs_replace[key] = np.random.normal(max_s / 2.0, max_s / 10.0, size=(seqs_replace.shape[0])).astype(\n",
    "            'float32')\n",
    "        gen_data = self.generator(seqs_replace, training=False)\n",
    "        return max_min_scale(gen_data)\n",
    "\n",
    "    def generate(self, real_seqs):\n",
    "        seqs_replace = real_seqs.copy()\n",
    "        max_s = seqs_replace[key].max()\n",
    "        seqs_replace[key] = np.random.normal(max_s / 2.0, max_s / 10.0, size=(seqs_replace.shape[0])).astype(\n",
    "            'float32')\n",
    "        gen_data = self.generator(seqs_replace, training=False)\n",
    "        return pd.DataFrame(gen_data.numpy())\n",
    "    \n",
    "    @staticmethod\n",
    "    def discriminator_loss(loss_object, real_output, fake_output):\n",
    "        real_loss = loss_object(tf.ones_like(real_output), real_output)\n",
    "        fake_loss = loss_object(tf.zeros_like(fake_output), fake_output)\n",
    "        total_loss = real_loss + fake_loss\n",
    "        return total_loss\n",
    "\n",
    "    @staticmethod\n",
    "    def generator_loss(loss_object, fake_output):\n",
    "        return loss_object(tf.ones_like(fake_output), fake_output)\n",
    "    \n",
    "    def compare_plot(self, name, save_path, start_day=0, week=1):\n",
    "        fig, ax = subplots()\n",
    "        fig.set_figheight(8)\n",
    "        fig.set_figwidth(20)\n",
    "        real_seqs = self.seqs[start_day:start_day+batch_size*week]\n",
    "        generated_seqs = []\n",
    "        for w in range(week):\n",
    "            generated_seq = self.generate(real_seqs[start_day*w:start_day*w+batch_size])\n",
    "            if len(generated_seqs) == 0:\n",
    "                generated_seqs = generated_seq\n",
    "            else:\n",
    "                generated_seqs =  generated_seqs.append(generated_seq, ignore_index=True)\n",
    "        all_seqs = pd.concat([pd.DataFrame(real_seqs[key].values), generated_seqs], axis=1)\n",
    "        all_seqs.plot(ax=ax)\n",
    "        n=2\n",
    "        ax.legend(['real'+str(w) for w in range(1,n)]+['gen'+str(w) for w in range(1,n)]);\n",
    "        fig.savefig(save_path+\"/compare_\" + name + \".png\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 96*7\n",
    "\n",
    "lr = 0.0001\n",
    "adm1 = 0.5\n",
    "base = 8\n",
    "epochs=1200\n",
    "dropout = 0.3\n",
    "alpha = 0.2\n",
    "name='GCN_'+str(use_gcn)+'_'+str(lr)+'_'+str(adm1)+'_'+str(dropout)+'_'+str(alpha)\n",
    "save_path='generated/'+str(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marko\\anaconda3\\lib\\site-packages\\spektral\\utils\\convolution.py:30: RuntimeWarning: divide by zero encountered in power\n",
      "  degrees = np.power(np.array(A.sum(1)), k).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1(7.8)/1200(7.8) - gen_loss = 0.68714, disc_loss = 1.35392, estimated to finish: 9349.77\n",
      "epoch 2(4.24)/1200(12.04) - gen_loss = 0.63602, disc_loss = 1.35221, estimated to finish: 7213.14\n",
      "epoch 3(3.92)/1200(15.96) - gen_loss = 0.61399, disc_loss = 1.41618, estimated to finish: 6368.83\n",
      "epoch 4(3.92)/1200(19.89) - gen_loss = 0.71979, disc_loss = 1.40191, estimated to finish: 5945.9\n",
      "epoch 5(3.95)/1200(23.84) - gen_loss = 0.82296, disc_loss = 1.37186, estimated to finish: 5696.68\n",
      "epoch 6(4.18)/1200(28.02) - gen_loss = 0.8119, disc_loss = 1.38248, estimated to finish: 5575.48\n",
      "epoch 7(4.29)/1200(32.31) - gen_loss = 0.72334, disc_loss = 1.39821, estimated to finish: 5506.8\n",
      "epoch 8(4.01)/1200(36.32) - gen_loss = 0.6733, disc_loss = 1.37784, estimated to finish: 5412.2\n",
      "epoch 9(4.14)/1200(40.47) - gen_loss = 0.64093, disc_loss = 1.38162, estimated to finish: 5354.94\n",
      "epoch 10(4.12)/1200(44.58) - gen_loss = 0.66186, disc_loss = 1.39756, estimated to finish: 5305.44\n",
      "epoch 11(4.15)/1200(48.74) - gen_loss = 0.74252, disc_loss = 1.38128, estimated to finish: 5268.08\n",
      "epoch 12(4.16)/1200(52.9) - gen_loss = 0.76831, disc_loss = 1.38237, estimated to finish: 5236.86\n",
      "epoch 13(3.99)/1200(56.89) - gen_loss = 0.71339, disc_loss = 1.39349, estimated to finish: 5194.27\n",
      "epoch 14(3.9)/1200(60.78) - gen_loss = 0.67046, disc_loss = 1.37759, estimated to finish: 5149.32\n",
      "epoch 15(4.02)/1200(64.8) - gen_loss = 0.64271, disc_loss = 1.38461, estimated to finish: 5119.52\n",
      "epoch 16(4.19)/1200(68.99) - gen_loss = 0.67818, disc_loss = 1.39376, estimated to finish: 5105.45\n",
      "epoch 17(4.14)/1200(73.13) - gen_loss = 0.7565, disc_loss = 1.3752, estimated to finish: 5089.1\n",
      "epoch 18(4.1)/1200(77.23) - gen_loss = 0.74845, disc_loss = 1.3864, estimated to finish: 5071.51\n",
      "epoch 19(4.05)/1200(81.28) - gen_loss = 0.68642, disc_loss = 1.3904, estimated to finish: 5052.01\n",
      "epoch 20(3.94)/1200(85.21) - gen_loss = 0.65156, disc_loss = 1.36115, estimated to finish: 5027.57\n",
      "epoch 21(4.05)/1200(89.26) - gen_loss = 0.61733, disc_loss = 1.39947, estimated to finish: 5011.26\n",
      "epoch 22(4.17)/1200(93.43) - gen_loss = 0.71265, disc_loss = 1.39006, estimated to finish: 5002.81\n",
      "epoch 23(4.09)/1200(97.52) - gen_loss = 0.80765, disc_loss = 1.35904, estimated to finish: 4990.64\n",
      "epoch 24(3.87)/1200(101.4) - gen_loss = 0.74307, disc_loss = 1.39426, estimated to finish: 4968.46\n",
      "epoch 25(3.93)/1200(105.33) - gen_loss = 0.6551, disc_loss = 1.40907, estimated to finish: 4950.32\n",
      "epoch 26(3.92)/1200(109.25) - gen_loss = 0.65268, disc_loss = 1.31086, estimated to finish: 4933.02\n",
      "epoch 27(3.83)/1200(113.08) - gen_loss = 0.54695, disc_loss = 1.40034, estimated to finish: 4912.7\n",
      "epoch 28(3.86)/1200(116.94) - gen_loss = 0.63275, disc_loss = 1.44259, estimated to finish: 4894.86\n",
      "epoch 29(3.91)/1200(120.85) - gen_loss = 0.78847, disc_loss = 1.3748, estimated to finish: 4879.72\n",
      "epoch 30(3.89)/1200(124.74) - gen_loss = 0.89373, disc_loss = 1.34256, estimated to finish: 4864.82\n",
      "epoch 31(3.92)/1200(128.66) - gen_loss = 0.81572, disc_loss = 1.38732, estimated to finish: 4851.69\n",
      "epoch 32(3.9)/1200(132.56) - gen_loss = 0.69157, disc_loss = 1.42218, estimated to finish: 4838.41\n",
      "epoch 33(3.9)/1200(136.46) - gen_loss = 0.67025, disc_loss = 1.38251, estimated to finish: 4825.55\n",
      "epoch 34(3.87)/1200(140.32) - gen_loss = 0.65612, disc_loss = 1.34372, estimated to finish: 4812.26\n",
      "epoch 35(3.82)/1200(144.15) - gen_loss = 0.60414, disc_loss = 1.37053, estimated to finish: 4798.07\n",
      "epoch 36(3.92)/1200(148.07) - gen_loss = 0.60847, disc_loss = 1.4268, estimated to finish: 4787.57\n",
      "epoch 37(3.92)/1200(151.99) - gen_loss = 0.69476, disc_loss = 1.40171, estimated to finish: 4777.29\n",
      "epoch 38(3.83)/1200(155.81) - gen_loss = 0.78556, disc_loss = 1.36478, estimated to finish: 4764.6\n",
      "epoch 39(3.92)/1200(159.73) - gen_loss = 0.83513, disc_loss = 1.35548, estimated to finish: 4755.1\n",
      "epoch 40(4.05)/1200(163.78) - gen_loss = 0.76574, disc_loss = 1.39584, estimated to finish: 4749.56\n",
      "epoch 41(3.95)/1200(167.73) - gen_loss = 0.68779, disc_loss = 1.41716, estimated to finish: 4741.44\n",
      "epoch 42(3.91)/1200(171.64) - gen_loss = 0.67453, disc_loss = 1.38494, estimated to finish: 4732.28\n",
      "epoch 43(4.17)/1200(175.8) - gen_loss = 0.67108, disc_loss = 1.33597, estimated to finish: 4730.32\n",
      "epoch 44(4.22)/1200(180.02) - gen_loss = 0.62505, disc_loss = 1.32505, estimated to finish: 4729.71\n",
      "epoch 45(4.62)/1200(184.64) - gen_loss = 0.56307, disc_loss = 1.43891, estimated to finish: 4739.18\n",
      "epoch 46(4.83)/1200(189.47) - gen_loss = 0.65536, disc_loss = 1.42932, estimated to finish: 4753.29\n",
      "epoch 47(4.48)/1200(193.96) - gen_loss = 0.76274, disc_loss = 1.37818, estimated to finish: 4758.13\n",
      "epoch 48(4.36)/1200(198.32) - gen_loss = 0.85569, disc_loss = 1.34327, estimated to finish: 4759.62\n",
      "epoch 49(4.45)/1200(202.76) - gen_loss = 0.85256, disc_loss = 1.36099, estimated to finish: 4762.9\n",
      "epoch 50(4.78)/1200(207.54) - gen_loss = 0.72929, disc_loss = 1.42098, estimated to finish: 4773.41\n",
      "epoch 51(4.44)/1200(211.98) - gen_loss = 0.67779, disc_loss = 1.41867, estimated to finish: 4775.89\n",
      "epoch 52(4.36)/1200(216.35) - gen_loss = 0.6782, disc_loss = 1.38282, estimated to finish: 4776.27\n",
      "epoch 53(4.67)/1200(221.02) - gen_loss = 0.68355, disc_loss = 1.33796, estimated to finish: 4783.13\n",
      "epoch 54(4.05)/1200(225.06) - gen_loss = 0.66481, disc_loss = 1.3034, estimated to finish: 4776.33\n",
      "epoch 55(4.02)/1200(229.08) - gen_loss = 0.57389, disc_loss = 1.41058, estimated to finish: 4769.12\n",
      "epoch 56(4.12)/1200(233.2) - gen_loss = 0.60857, disc_loss = 1.45842, estimated to finish: 4763.99\n",
      "epoch 57(4.24)/1200(237.44) - gen_loss = 0.72084, disc_loss = 1.4022, estimated to finish: 4761.37\n",
      "epoch 58(4.27)/1200(241.71) - gen_loss = 0.83574, disc_loss = 1.35163, estimated to finish: 4759.2\n",
      "epoch 59(3.96)/1200(245.67) - gen_loss = 0.90058, disc_loss = 1.33537, estimated to finish: 4750.96\n",
      "epoch 60(4.06)/1200(249.72) - gen_loss = 0.79347, disc_loss = 1.39727, estimated to finish: 4744.75\n",
      "epoch 61(4.12)/1200(253.84) - gen_loss = 0.68941, disc_loss = 1.43108, estimated to finish: 4739.82\n",
      "epoch 62(4.19)/1200(258.04) - gen_loss = 0.67459, disc_loss = 1.40364, estimated to finish: 4736.2\n",
      "epoch 63(3.97)/1200(262.0) - gen_loss = 0.68001, disc_loss = 1.36516, estimated to finish: 4728.54\n",
      "epoch 64(4.02)/1200(266.02) - gen_loss = 0.68764, disc_loss = 1.31627, estimated to finish: 4721.83\n",
      "epoch 65(4.0)/1200(270.01) - gen_loss = 0.65779, disc_loss = 1.30525, estimated to finish: 4714.85\n",
      "epoch 66(4.21)/1200(274.22) - gen_loss = 0.56489, disc_loss = 1.45005, estimated to finish: 4711.57\n",
      "epoch 67(4.36)/1200(278.57) - gen_loss = 0.63739, disc_loss = 1.45505, estimated to finish: 4710.8\n",
      "epoch 68(4.69)/1200(283.27) - gen_loss = 0.76912, disc_loss = 1.38639, estimated to finish: 4715.59\n",
      "epoch 69(4.34)/1200(287.61) - gen_loss = 0.89615, disc_loss = 1.33235, estimated to finish: 4714.31\n",
      "epoch 70(4.18)/1200(291.79) - gen_loss = 0.9015, disc_loss = 1.33787, estimated to finish: 4710.35\n",
      "epoch 71(4.53)/1200(296.32) - gen_loss = 0.72703, disc_loss = 1.42806, estimated to finish: 4711.88\n",
      "epoch 72(4.3)/1200(300.62) - gen_loss = 0.65928, disc_loss = 1.43437, estimated to finish: 4709.66\n",
      "epoch 73(4.15)/1200(304.77) - gen_loss = 0.66738, disc_loss = 1.38782, estimated to finish: 4705.08\n",
      "epoch 74(4.12)/1200(308.89) - gen_loss = 0.68293, disc_loss = 1.33877, estimated to finish: 4700.1\n",
      "epoch 75(4.15)/1200(313.04) - gen_loss = 0.69306, disc_loss = 1.291, estimated to finish: 4695.59\n",
      "epoch 76(4.04)/1200(317.08) - gen_loss = 0.61653, disc_loss = 1.36584, estimated to finish: 4689.44\n",
      "epoch 77(4.53)/1200(321.61) - gen_loss = 0.57133, disc_loss = 1.48255, estimated to finish: 4690.49\n",
      "epoch 78(4.84)/1200(326.45) - gen_loss = 0.65688, disc_loss = 1.44297, estimated to finish: 4695.91\n",
      "epoch 79(4.51)/1200(330.96) - gen_loss = 0.76272, disc_loss = 1.38115, estimated to finish: 4696.33\n",
      "epoch 80(4.48)/1200(335.44) - gen_loss = 0.86892, disc_loss = 1.33272, estimated to finish: 4696.15\n",
      "epoch 81(4.47)/1200(339.91) - gen_loss = 0.89212, disc_loss = 1.33466, estimated to finish: 4695.77\n",
      "epoch 82(4.47)/1200(344.38) - gen_loss = 0.76058, disc_loss = 1.4128, estimated to finish: 4695.36\n",
      "epoch 83(4.26)/1200(348.64) - gen_loss = 0.68116, disc_loss = 1.4344, estimated to finish: 4691.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84(4.38)/1200(353.02) - gen_loss = 0.67076, disc_loss = 1.40625, estimated to finish: 4690.1\n",
      "epoch 85(4.68)/1200(357.7) - gen_loss = 0.6724, disc_loss = 1.37994, estimated to finish: 4692.14\n",
      "epoch 86(4.74)/1200(362.44) - gen_loss = 0.67729, disc_loss = 1.35233, estimated to finish: 4694.83\n",
      "epoch 87(4.48)/1200(366.92) - gen_loss = 0.68033, disc_loss = 1.32127, estimated to finish: 4694.06\n",
      "epoch 88(4.47)/1200(371.4) - gen_loss = 0.65926, disc_loss = 1.31659, estimated to finish: 4693.1\n",
      "epoch 89(4.77)/1200(376.16) - gen_loss = 0.59289, disc_loss = 1.41081, estimated to finish: 4695.71\n",
      "epoch 90(4.39)/1200(380.55) - gen_loss = 0.60338, disc_loss = 1.46311, estimated to finish: 4693.45\n",
      "epoch 91(4.23)/1200(384.78) - gen_loss = 0.68207, disc_loss = 1.42168, estimated to finish: 4689.19\n",
      "epoch 92(4.58)/1200(389.36) - gen_loss = 0.76799, disc_loss = 1.37068, estimated to finish: 4689.23\n",
      "epoch 93(4.56)/1200(393.92) - gen_loss = 0.85084, disc_loss = 1.32678, estimated to finish: 4688.94\n",
      "epoch 94(4.38)/1200(398.3) - gen_loss = 0.87604, disc_loss = 1.31586, estimated to finish: 4686.39\n",
      "epoch 95(3.88)/1200(402.19) - gen_loss = 0.75293, disc_loss = 1.39084, estimated to finish: 4678.06\n",
      "epoch 96(3.86)/1200(406.05) - gen_loss = 0.62624, disc_loss = 1.48739, estimated to finish: 4669.58\n",
      "epoch 97(3.91)/1200(409.96) - gen_loss = 0.64012, disc_loss = 1.44641, estimated to finish: 4661.67\n",
      "epoch 98(3.75)/1200(413.7) - gen_loss = 0.70113, disc_loss = 1.36304, estimated to finish: 4652.04\n",
      "epoch 99(3.78)/1200(417.49) - gen_loss = 0.77325, disc_loss = 1.29495, estimated to finish: 4642.95\n",
      "epoch 100(3.82)/1200(421.3) - gen_loss = 0.71315, disc_loss = 1.37396, estimated to finish: 4634.33\n",
      "epoch 101(3.88)/1200(425.18) - gen_loss = 0.64232, disc_loss = 1.44169, estimated to finish: 4626.49\n",
      "epoch 102(3.83)/1200(429.02) - gen_loss = 0.64197, disc_loss = 1.43953, estimated to finish: 4618.23\n",
      "epoch 103(3.79)/1200(432.81) - gen_loss = 0.67351, disc_loss = 1.41405, estimated to finish: 4609.63\n",
      "epoch 104(3.82)/1200(436.63) - gen_loss = 0.71708, disc_loss = 1.38348, estimated to finish: 4601.42\n",
      "epoch 105(3.87)/1200(440.5) - gen_loss = 0.7614, disc_loss = 1.35899, estimated to finish: 4593.8\n",
      "epoch 106(3.86)/1200(444.36) - gen_loss = 0.78476, disc_loss = 1.35434, estimated to finish: 4586.17\n",
      "epoch 107(3.83)/1200(448.19) - gen_loss = 0.75747, disc_loss = 1.38147, estimated to finish: 4578.24\n",
      "epoch 108(3.87)/1200(452.06) - gen_loss = 0.70754, disc_loss = 1.41258, estimated to finish: 4570.87\n",
      "epoch 109(3.88)/1200(455.94) - gen_loss = 0.68048, disc_loss = 1.41636, estimated to finish: 4563.61\n",
      "epoch 110(3.81)/1200(459.76) - gen_loss = 0.67304, disc_loss = 1.40379, estimated to finish: 4555.77\n",
      "epoch 111(3.92)/1200(463.68) - gen_loss = 0.67201, disc_loss = 1.3899, estimated to finish: 4549.1\n",
      "epoch 112(3.82)/1200(467.51) - gen_loss = 0.67323, disc_loss = 1.37591, estimated to finish: 4541.48\n",
      "epoch 113(3.83)/1200(471.33) - gen_loss = 0.67523, disc_loss = 1.36066, estimated to finish: 4533.96\n",
      "epoch 114(3.84)/1200(475.18) - gen_loss = 0.67651, disc_loss = 1.34291, estimated to finish: 4526.67\n",
      "epoch 115(3.88)/1200(479.06) - gen_loss = 0.67155, disc_loss = 1.32736, estimated to finish: 4519.79\n",
      "epoch 116(3.82)/1200(482.87) - gen_loss = 0.64246, disc_loss = 1.34705, estimated to finish: 4512.36\n",
      "epoch 117(3.87)/1200(486.75) - gen_loss = 0.6005, disc_loss = 1.42952, estimated to finish: 4505.53\n",
      "epoch 118(3.88)/1200(490.63) - gen_loss = 0.63481, disc_loss = 1.44729, estimated to finish: 4498.79\n",
      "epoch 119(3.91)/1200(494.54) - gen_loss = 0.70949, disc_loss = 1.4044, estimated to finish: 4492.37\n",
      "epoch 120(3.84)/1200(498.37) - gen_loss = 0.78387, disc_loss = 1.35883, estimated to finish: 4485.34\n",
      "epoch 121(3.83)/1200(502.2) - gen_loss = 0.85846, disc_loss = 1.31547, estimated to finish: 4478.27\n",
      "epoch 122(3.81)/1200(506.01) - gen_loss = 0.8902, disc_loss = 1.29698, estimated to finish: 4471.1\n",
      "epoch 123(3.87)/1200(509.87) - gen_loss = 0.74826, disc_loss = 1.38682, estimated to finish: 4464.5\n",
      "epoch 124(3.86)/1200(513.74) - gen_loss = 0.60805, disc_loss = 1.505, estimated to finish: 4457.9\n",
      "epoch 125(3.83)/1200(517.57) - gen_loss = 0.63327, disc_loss = 1.45406, estimated to finish: 4451.1\n",
      "epoch 126(3.83)/1200(521.4) - gen_loss = 0.67081, disc_loss = 1.39901, estimated to finish: 4444.31\n",
      "epoch 127(3.82)/1200(525.21) - gen_loss = 0.70831, disc_loss = 1.35372, estimated to finish: 4437.44\n",
      "epoch 128(3.81)/1200(529.02) - gen_loss = 0.73314, disc_loss = 1.33202, estimated to finish: 4430.54\n",
      "epoch 129(3.81)/1200(532.83) - gen_loss = 0.70949, disc_loss = 1.36472, estimated to finish: 4423.7\n",
      "epoch 130(3.73)/1200(536.56) - gen_loss = 0.66836, disc_loss = 1.40644, estimated to finish: 4416.31\n",
      "epoch 131(3.91)/1200(540.47) - gen_loss = 0.6503, disc_loss = 1.42322, estimated to finish: 4410.4\n",
      "epoch 132(3.83)/1200(544.3) - gen_loss = 0.65775, disc_loss = 1.4202, estimated to finish: 4403.85\n",
      "epoch 133(3.91)/1200(548.2) - gen_loss = 0.67863, disc_loss = 1.40618, estimated to finish: 4397.97\n",
      "epoch 134(3.81)/1200(552.01) - gen_loss = 0.70918, disc_loss = 1.38594, estimated to finish: 4391.36\n",
      "epoch 135(3.86)/1200(555.87) - gen_loss = 0.74547, disc_loss = 1.36374, estimated to finish: 4385.17\n",
      "epoch 136(3.89)/1200(559.76) - gen_loss = 0.77406, disc_loss = 1.35073, estimated to finish: 4379.31\n",
      "epoch 137(3.8)/1200(563.56) - gen_loss = 0.77283, disc_loss = 1.35911, estimated to finish: 4372.73\n",
      "epoch 138(3.89)/1200(567.45) - gen_loss = 0.73386, disc_loss = 1.38966, estimated to finish: 4366.9\n",
      "epoch 139(3.84)/1200(571.29) - gen_loss = 0.69121, disc_loss = 1.41567, estimated to finish: 4360.69\n",
      "epoch 140(3.82)/1200(575.11) - gen_loss = 0.67075, disc_loss = 1.41754, estimated to finish: 4354.4\n",
      "epoch 141(3.87)/1200(578.98) - gen_loss = 0.66643, disc_loss = 1.40694, estimated to finish: 4348.53\n",
      "epoch 142(3.85)/1200(582.84) - gen_loss = 0.66979, disc_loss = 1.39103, estimated to finish: 4342.55\n",
      "epoch 143(3.9)/1200(586.74) - gen_loss = 0.67777, disc_loss = 1.37113, estimated to finish: 4336.92\n",
      "epoch 144(3.75)/1200(590.49) - gen_loss = 0.68369, disc_loss = 1.35159, estimated to finish: 4330.25\n",
      "epoch 145(3.84)/1200(594.33) - gen_loss = 0.68295, disc_loss = 1.33391, estimated to finish: 4324.26\n",
      "epoch 146(3.89)/1200(598.22) - gen_loss = 0.66384, disc_loss = 1.33573, estimated to finish: 4318.65\n",
      "epoch 147(3.85)/1200(602.07) - gen_loss = 0.60901, disc_loss = 1.41017, estimated to finish: 4312.79\n",
      "epoch 148(3.92)/1200(605.99) - gen_loss = 0.61368, disc_loss = 1.4623, estimated to finish: 4307.42\n",
      "epoch 149(3.82)/1200(609.81) - gen_loss = 0.68207, disc_loss = 1.42367, estimated to finish: 4301.39\n",
      "epoch 150(3.78)/1200(613.59) - gen_loss = 0.75116, disc_loss = 1.37545, estimated to finish: 4295.12\n",
      "epoch 151(3.91)/1200(617.5) - gen_loss = 0.82219, disc_loss = 1.33112, estimated to finish: 4289.77\n",
      "epoch 152(4.07)/1200(621.56) - gen_loss = 0.88556, disc_loss = 1.29663, estimated to finish: 4285.51\n",
      "epoch 153(4.07)/1200(625.63) - gen_loss = 0.85317, disc_loss = 1.32527, estimated to finish: 4281.26\n",
      "epoch 154(3.99)/1200(629.62) - gen_loss = 0.70178, disc_loss = 1.43352, estimated to finish: 4276.5\n",
      "epoch 155(3.92)/1200(633.53) - gen_loss = 0.63839, disc_loss = 1.46862, estimated to finish: 4271.25\n",
      "epoch 156(3.82)/1200(637.35) - gen_loss = 0.63893, disc_loss = 1.44391, estimated to finish: 4265.36\n",
      "epoch 157(3.8)/1200(641.15) - gen_loss = 0.67623, disc_loss = 1.39089, estimated to finish: 4259.35\n",
      "epoch 158(3.99)/1200(645.13) - gen_loss = 0.70483, disc_loss = 1.35975, estimated to finish: 4254.62\n",
      "epoch 159(3.86)/1200(649.0) - gen_loss = 0.70152, disc_loss = 1.37155, estimated to finish: 4249.11\n",
      "epoch 160(3.91)/1200(652.9) - gen_loss = 0.69006, disc_loss = 1.39043, estimated to finish: 4243.88\n",
      "epoch 161(3.87)/1200(656.77) - gen_loss = 0.67952, disc_loss = 1.4006, estimated to finish: 4238.42\n",
      "epoch 162(3.84)/1200(660.61) - gen_loss = 0.6731, disc_loss = 1.40408, estimated to finish: 4232.83\n",
      "epoch 163(3.82)/1200(664.44) - gen_loss = 0.67088, disc_loss = 1.40303, estimated to finish: 4227.12\n",
      "epoch 164(3.85)/1200(668.29) - gen_loss = 0.67251, disc_loss = 1.39984, estimated to finish: 4221.62\n",
      "epoch 165(3.85)/1200(672.14) - gen_loss = 0.678, disc_loss = 1.39432, estimated to finish: 4216.16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 166(3.86)/1200(676.0) - gen_loss = 0.68635, disc_loss = 1.38759, estimated to finish: 4210.77\n",
      "epoch 167(3.82)/1200(679.83) - gen_loss = 0.69558, disc_loss = 1.38127, estimated to finish: 4205.15\n",
      "epoch 168(3.83)/1200(683.65) - gen_loss = 0.70316, disc_loss = 1.37699, estimated to finish: 4199.59\n",
      "epoch 169(3.89)/1200(687.54) - gen_loss = 0.70666, disc_loss = 1.37602, estimated to finish: 4194.43\n",
      "epoch 170(3.91)/1200(691.46) - gen_loss = 0.70457, disc_loss = 1.37832, estimated to finish: 4189.42\n",
      "epoch 171(3.83)/1200(695.28) - gen_loss = 0.69734, disc_loss = 1.38371, estimated to finish: 4183.91\n",
      "epoch 172(3.87)/1200(699.16) - gen_loss = 0.68962, disc_loss = 1.38779, estimated to finish: 4178.68\n",
      "epoch 173(3.83)/1200(702.99) - gen_loss = 0.68369, disc_loss = 1.39041, estimated to finish: 4173.22\n",
      "epoch 174(3.88)/1200(706.86) - gen_loss = 0.68134, disc_loss = 1.38959, estimated to finish: 4168.04\n",
      "epoch 175(3.81)/1200(710.67) - gen_loss = 0.6823, disc_loss = 1.38584, estimated to finish: 4162.48\n",
      "epoch 176(3.84)/1200(714.5) - gen_loss = 0.69358, disc_loss = 1.37036, estimated to finish: 4157.1\n",
      "epoch 177(3.85)/1200(718.35) - gen_loss = 0.71875, disc_loss = 1.33809, estimated to finish: 4151.84\n",
      "epoch 178(3.89)/1200(722.24) - gen_loss = 0.74426, disc_loss = 1.29836, estimated to finish: 4146.82\n",
      "epoch 179(3.85)/1200(726.09) - gen_loss = 0.71094, disc_loss = 1.30471, estimated to finish: 4141.56\n",
      "epoch 180(3.79)/1200(729.88) - gen_loss = 0.58586, disc_loss = 1.50355, estimated to finish: 4135.98\n",
      "epoch 181(3.85)/1200(733.72) - gen_loss = 0.66197, disc_loss = 1.47959, estimated to finish: 4130.75\n",
      "epoch 182(3.82)/1200(737.54) - gen_loss = 0.72396, disc_loss = 1.41894, estimated to finish: 4125.38\n",
      "epoch 183(3.85)/1200(741.39) - gen_loss = 0.76741, disc_loss = 1.37795, estimated to finish: 4120.19\n",
      "epoch 184(3.85)/1200(745.24) - gen_loss = 0.8131, disc_loss = 1.3429, estimated to finish: 4115.02\n",
      "epoch 185(3.95)/1200(749.19) - gen_loss = 0.86645, disc_loss = 1.3074, estimated to finish: 4110.43\n",
      "epoch 186(3.89)/1200(753.08) - gen_loss = 0.90082, disc_loss = 1.28753, estimated to finish: 4105.52\n",
      "epoch 187(3.89)/1200(756.97) - gen_loss = 0.81485, disc_loss = 1.34422, estimated to finish: 4100.6\n",
      "epoch 188(3.85)/1200(760.82) - gen_loss = 0.66684, disc_loss = 1.44585, estimated to finish: 4095.48\n",
      "epoch 189(3.82)/1200(764.64) - gen_loss = 0.61071, disc_loss = 1.47969, estimated to finish: 4090.23\n",
      "epoch 190(3.84)/1200(768.49) - gen_loss = 0.61899, disc_loss = 1.44825, estimated to finish: 4085.11\n",
      "epoch 191(3.81)/1200(772.3) - gen_loss = 0.65541, disc_loss = 1.38836, estimated to finish: 4079.84\n",
      "epoch 192(3.89)/1200(776.19) - gen_loss = 0.69998, disc_loss = 1.32974, estimated to finish: 4074.98\n",
      "epoch 193(3.83)/1200(780.02) - gen_loss = 0.68488, disc_loss = 1.35695, estimated to finish: 4069.84\n",
      "epoch 194(3.84)/1200(783.86) - gen_loss = 0.65407, disc_loss = 1.41471, estimated to finish: 4064.77\n",
      "epoch 195(3.9)/1200(787.77) - gen_loss = 0.65631, disc_loss = 1.42348, estimated to finish: 4060.03\n",
      "epoch 196(3.86)/1200(791.63) - gen_loss = 0.66847, disc_loss = 1.4141, estimated to finish: 4055.09\n",
      "epoch 197(3.91)/1200(795.55) - gen_loss = 0.68154, disc_loss = 1.40268, estimated to finish: 4050.42\n",
      "epoch 198(3.86)/1200(799.41) - gen_loss = 0.69365, disc_loss = 1.39242, estimated to finish: 4045.5\n",
      "epoch 199(3.85)/1200(803.26) - gen_loss = 0.70392, disc_loss = 1.38451, estimated to finish: 4040.53\n",
      "epoch 200(3.81)/1200(807.07) - gen_loss = 0.71192, disc_loss = 1.3792, estimated to finish: 4035.37\n",
      "epoch 201(3.84)/1200(810.91) - gen_loss = 0.71567, disc_loss = 1.3779, estimated to finish: 4030.35\n",
      "epoch 202(3.81)/1200(814.72) - gen_loss = 0.71457, disc_loss = 1.37944, estimated to finish: 4025.22\n",
      "epoch 203(3.82)/1200(818.54) - gen_loss = 0.70888, disc_loss = 1.38327, estimated to finish: 4020.11\n",
      "epoch 204(3.79)/1200(822.33) - gen_loss = 0.70062, disc_loss = 1.38655, estimated to finish: 4014.92\n",
      "epoch 205(3.86)/1200(826.19) - gen_loss = 0.69218, disc_loss = 1.3891, estimated to finish: 4010.06\n",
      "epoch 206(3.87)/1200(830.06) - gen_loss = 0.68487, disc_loss = 1.38947, estimated to finish: 4005.24\n",
      "epoch 207(3.83)/1200(833.89) - gen_loss = 0.67996, disc_loss = 1.38721, estimated to finish: 4000.26\n",
      "epoch 208(3.79)/1200(837.68) - gen_loss = 0.67718, disc_loss = 1.38264, estimated to finish: 3995.11\n",
      "epoch 209(3.9)/1200(841.59) - gen_loss = 0.67683, disc_loss = 1.37436, estimated to finish: 3990.49\n",
      "epoch 210(3.85)/1200(845.44) - gen_loss = 0.68014, disc_loss = 1.35899, estimated to finish: 3985.65\n",
      "epoch 211(3.88)/1200(849.32) - gen_loss = 0.68856, disc_loss = 1.32966, estimated to finish: 3980.95\n",
      "epoch 212(3.83)/1200(853.15) - gen_loss = 0.69462, disc_loss = 1.28235, estimated to finish: 3976.0\n",
      "epoch 213(3.81)/1200(856.96) - gen_loss = 0.60131, disc_loss = 1.38224, estimated to finish: 3970.97\n",
      "epoch 214(3.79)/1200(860.75) - gen_loss = 0.71233, disc_loss = 1.49786, estimated to finish: 3965.89\n",
      "epoch 215(3.85)/1200(864.6) - gen_loss = 0.76844, disc_loss = 1.40708, estimated to finish: 3961.09\n",
      "epoch 216(3.84)/1200(868.44) - gen_loss = 0.8054, disc_loss = 1.342, estimated to finish: 3956.25\n",
      "epoch 217(3.87)/1200(872.32) - gen_loss = 0.86065, disc_loss = 1.26027, estimated to finish: 3951.56\n",
      "epoch 218(3.86)/1200(876.18) - gen_loss = 0.92516, disc_loss = 1.1287, estimated to finish: 3946.83\n",
      "epoch 219(3.98)/1200(880.16) - gen_loss = 0.69583, disc_loss = 1.33091, estimated to finish: 3942.65\n",
      "epoch 220(3.81)/1200(883.97) - gen_loss = 0.57021, disc_loss = 1.77687, estimated to finish: 3937.68\n",
      "epoch 221(3.9)/1200(887.87) - gen_loss = 0.95801, disc_loss = 0.87141, estimated to finish: 3933.15\n",
      "epoch 222(3.88)/1200(891.75) - gen_loss = 1.51849, disc_loss = 0.27572, estimated to finish: 3928.53\n",
      "epoch 223(3.84)/1200(895.59) - gen_loss = 1.88492, disc_loss = 1.08933, estimated to finish: 3923.74\n",
      "epoch 224(3.86)/1200(899.45) - gen_loss = 1.46493, disc_loss = 1.77708, estimated to finish: 3919.03\n",
      "epoch 225(3.82)/1200(903.27) - gen_loss = 1.14551, disc_loss = 1.19409, estimated to finish: 3914.19\n",
      "epoch 226(3.85)/1200(907.12) - gen_loss = 1.1684, disc_loss = 0.68653, estimated to finish: 3909.45\n",
      "epoch 227(3.87)/1200(910.99) - gen_loss = 1.67172, disc_loss = 0.36073, estimated to finish: 3904.81\n",
      "epoch 228(3.81)/1200(914.79) - gen_loss = 1.9855, disc_loss = 0.28619, estimated to finish: 3899.92\n",
      "epoch 229(3.88)/1200(918.67) - gen_loss = 1.27486, disc_loss = 1.09518, estimated to finish: 3895.33\n",
      "epoch 230(3.87)/1200(922.54) - gen_loss = 1.21106, disc_loss = 0.67257, estimated to finish: 3890.71\n",
      "epoch 231(3.82)/1200(926.35) - gen_loss = 2.40639, disc_loss = 0.14165, estimated to finish: 3885.88\n",
      "epoch 232(3.81)/1200(930.17) - gen_loss = 3.5271, disc_loss = 0.06109, estimated to finish: 3881.04\n",
      "epoch 233(3.88)/1200(934.04) - gen_loss = 3.62407, disc_loss = 0.05337, estimated to finish: 3876.47\n",
      "epoch 234(3.89)/1200(937.93) - gen_loss = 3.54219, disc_loss = 0.05303, estimated to finish: 3871.98\n",
      "epoch 235(3.84)/1200(941.77) - gen_loss = 3.45927, disc_loss = 0.05368, estimated to finish: 3867.28\n",
      "epoch 236(3.84)/1200(945.61) - gen_loss = 3.26443, disc_loss = 0.05982, estimated to finish: 3862.58\n",
      "epoch 237(3.85)/1200(949.46) - gen_loss = 3.35732, disc_loss = 1.94808, estimated to finish: 3857.92\n",
      "epoch 238(3.85)/1200(953.31) - gen_loss = 2.83911, disc_loss = 2.09851, estimated to finish: 3853.3\n",
      "epoch 239(3.79)/1200(957.1) - gen_loss = 1.87627, disc_loss = 0.8613, estimated to finish: 3848.43\n",
      "epoch 240(3.86)/1200(960.96) - gen_loss = 2.00619, disc_loss = 2.33183, estimated to finish: 3843.84\n",
      "epoch 241(3.82)/1200(964.78) - gen_loss = 2.0388, disc_loss = 1.79947, estimated to finish: 3839.12\n",
      "epoch 242(3.83)/1200(968.61) - gen_loss = 1.60196, disc_loss = 1.38243, estimated to finish: 3834.43\n",
      "epoch 243(3.77)/1200(972.38) - gen_loss = 1.24085, disc_loss = 0.84951, estimated to finish: 3829.5\n",
      "epoch 244(3.86)/1200(976.25) - gen_loss = 0.80177, disc_loss = 1.34085, estimated to finish: 3824.97\n",
      "epoch 245(3.86)/1200(980.11) - gen_loss = 0.8064, disc_loss = 1.74974, estimated to finish: 3820.43\n",
      "epoch 246(3.89)/1200(984.0) - gen_loss = 0.82073, disc_loss = 1.735, estimated to finish: 3816.01\n",
      "epoch 247(3.87)/1200(987.87) - gen_loss = 1.00803, disc_loss = 1.53682, estimated to finish: 3811.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 248(3.91)/1200(991.78) - gen_loss = 1.09234, disc_loss = 1.39373, estimated to finish: 3807.16\n",
      "epoch 249(3.81)/1200(995.59) - gen_loss = 1.0445, disc_loss = 1.26438, estimated to finish: 3802.44\n",
      "epoch 250(3.89)/1200(999.48) - gen_loss = 0.98158, disc_loss = 1.03022, estimated to finish: 3798.03\n",
      "epoch 251(3.8)/1200(1003.29) - gen_loss = 0.96537, disc_loss = 0.79853, estimated to finish: 3793.3\n",
      "epoch 252(3.87)/1200(1007.16) - gen_loss = 0.99613, disc_loss = 0.62466, estimated to finish: 3788.83\n",
      "epoch 253(3.8)/1200(1010.95) - gen_loss = 1.03632, disc_loss = 0.60562, estimated to finish: 3784.08\n",
      "epoch 254(3.83)/1200(1014.78) - gen_loss = 1.06474, disc_loss = 0.59641, estimated to finish: 3779.47\n",
      "epoch 255(3.85)/1200(1018.64) - gen_loss = 1.07338, disc_loss = 0.60294, estimated to finish: 3774.95\n",
      "epoch 256(3.81)/1200(1022.45) - gen_loss = 0.39346, disc_loss = 2.85406, estimated to finish: 3770.27\n",
      "epoch 257(3.86)/1200(1026.31) - gen_loss = 0.05304, disc_loss = 3.11382, estimated to finish: 3765.78\n",
      "epoch 258(3.85)/1200(1030.16) - gen_loss = 0.10745, disc_loss = 2.44478, estimated to finish: 3761.28\n",
      "epoch 259(3.76)/1200(1033.92) - gen_loss = 0.19313, disc_loss = 1.96439, estimated to finish: 3756.45\n",
      "epoch 260(3.83)/1200(1037.76) - gen_loss = 0.30243, disc_loss = 1.66646, estimated to finish: 3751.89\n",
      "epoch 261(3.79)/1200(1041.54) - gen_loss = 0.40954, disc_loss = 1.51454, estimated to finish: 3747.16\n",
      "epoch 262(3.84)/1200(1045.39) - gen_loss = 0.4968, disc_loss = 1.44544, estimated to finish: 3742.64\n",
      "epoch 263(3.83)/1200(1049.22) - gen_loss = 0.56219, disc_loss = 1.41395, estimated to finish: 3738.08\n",
      "epoch 264(3.85)/1200(1053.07) - gen_loss = 0.60895, disc_loss = 1.39892, estimated to finish: 3733.6\n",
      "epoch 265(3.83)/1200(1056.9) - gen_loss = 0.64153, disc_loss = 1.39157, estimated to finish: 3729.05\n",
      "epoch 266(3.93)/1200(1060.82) - gen_loss = 0.66449, disc_loss = 1.38639, estimated to finish: 3724.85\n",
      "epoch 267(3.87)/1200(1064.7) - gen_loss = 0.6805, disc_loss = 1.38254, estimated to finish: 3720.46\n",
      "epoch 268(3.92)/1200(1068.61) - gen_loss = 0.69079, disc_loss = 1.37997, estimated to finish: 3716.23\n",
      "epoch 269(3.82)/1200(1072.43) - gen_loss = 0.69793, disc_loss = 1.37754, estimated to finish: 3711.65\n",
      "epoch 270(3.9)/1200(1076.33) - gen_loss = 0.70271, disc_loss = 1.37505, estimated to finish: 3707.36\n",
      "epoch 271(3.88)/1200(1080.21) - gen_loss = 0.70607, disc_loss = 1.37288, estimated to finish: 3703.02\n",
      "epoch 272(3.82)/1200(1084.03) - gen_loss = 0.70741, disc_loss = 1.3721, estimated to finish: 3698.47\n",
      "epoch 273(3.89)/1200(1087.93) - gen_loss = 0.70885, disc_loss = 1.37031, estimated to finish: 3694.17\n",
      "epoch 274(3.85)/1200(1091.78) - gen_loss = 0.70902, disc_loss = 1.36958, estimated to finish: 3689.73\n",
      "epoch 275(3.82)/1200(1095.6) - gen_loss = 0.70968, disc_loss = 1.3683, estimated to finish: 3685.19\n",
      "epoch 276(3.76)/1200(1099.36) - gen_loss = 0.70943, disc_loss = 1.36778, estimated to finish: 3680.46\n",
      "epoch 277(3.89)/1200(1103.24) - gen_loss = 0.7089, disc_loss = 1.36763, estimated to finish: 3676.15\n",
      "epoch 278(3.83)/1200(1107.08) - gen_loss = 0.70765, disc_loss = 1.36799, estimated to finish: 3671.68\n",
      "epoch 279(3.87)/1200(1110.95) - gen_loss = 0.70663, disc_loss = 1.36831, estimated to finish: 3667.34\n",
      "epoch 280(3.85)/1200(1114.8) - gen_loss = 0.70533, disc_loss = 1.36918, estimated to finish: 3662.92\n",
      "epoch 281(3.81)/1200(1118.61) - gen_loss = 0.70346, disc_loss = 1.37033, estimated to finish: 3658.37\n",
      "epoch 282(3.87)/1200(1122.48) - gen_loss = 0.70156, disc_loss = 1.37195, estimated to finish: 3654.03\n",
      "epoch 283(3.86)/1200(1126.34) - gen_loss = 0.69969, disc_loss = 1.3739, estimated to finish: 3649.65\n",
      "epoch 284(3.85)/1200(1130.18) - gen_loss = 0.69816, disc_loss = 1.3751, estimated to finish: 3645.24\n",
      "epoch 285(3.79)/1200(1133.97) - gen_loss = 0.69598, disc_loss = 1.37711, estimated to finish: 3640.64\n",
      "epoch 286(3.92)/1200(1137.88) - gen_loss = 0.69395, disc_loss = 1.37919, estimated to finish: 3636.46\n",
      "epoch 287(3.79)/1200(1141.67) - gen_loss = 0.69214, disc_loss = 1.38107, estimated to finish: 3631.87\n",
      "epoch 288(3.83)/1200(1145.5) - gen_loss = 0.68987, disc_loss = 1.38314, estimated to finish: 3627.43\n",
      "epoch 289(3.79)/1200(1149.29) - gen_loss = 0.68701, disc_loss = 1.3858, estimated to finish: 3622.86\n",
      "epoch 290(3.84)/1200(1153.14) - gen_loss = 0.68535, disc_loss = 1.38714, estimated to finish: 3618.47\n",
      "epoch 291(3.89)/1200(1157.03) - gen_loss = 0.68325, disc_loss = 1.3889, estimated to finish: 3614.22\n",
      "epoch 292(3.8)/1200(1160.83) - gen_loss = 0.68123, disc_loss = 1.39122, estimated to finish: 3609.71\n",
      "epoch 293(3.84)/1200(1164.67) - gen_loss = 0.67987, disc_loss = 1.39197, estimated to finish: 3605.32\n",
      "epoch 294(3.79)/1200(1168.46) - gen_loss = 0.67812, disc_loss = 1.39242, estimated to finish: 3600.76\n",
      "epoch 295(3.86)/1200(1172.32) - gen_loss = 0.67672, disc_loss = 1.39255, estimated to finish: 3596.45\n",
      "epoch 296(3.85)/1200(1176.18) - gen_loss = 0.67509, disc_loss = 1.39269, estimated to finish: 3592.1\n",
      "epoch 297(3.88)/1200(1180.05) - gen_loss = 0.67391, disc_loss = 1.39256, estimated to finish: 3587.83\n",
      "epoch 298(3.86)/1200(1183.92) - gen_loss = 0.6733, disc_loss = 1.39162, estimated to finish: 3583.53\n",
      "epoch 299(3.81)/1200(1187.72) - gen_loss = 0.67326, disc_loss = 1.38956, estimated to finish: 3579.05\n",
      "epoch 300(3.85)/1200(1191.57) - gen_loss = 0.67233, disc_loss = 1.3878, estimated to finish: 3574.72\n",
      "epoch 301(3.86)/1200(1195.44) - gen_loss = 0.67201, disc_loss = 1.38683, estimated to finish: 3570.42\n",
      "epoch 302(3.79)/1200(1199.23) - gen_loss = 0.67363, disc_loss = 1.38172, estimated to finish: 3565.93\n",
      "epoch 303(3.92)/1200(1203.15) - gen_loss = 0.67195, disc_loss = 1.38145, estimated to finish: 3561.81\n",
      "epoch 304(3.9)/1200(1207.05) - gen_loss = 0.67323, disc_loss = 1.37983, estimated to finish: 3557.63\n",
      "epoch 305(3.81)/1200(1210.86) - gen_loss = 0.67563, disc_loss = 1.37583, estimated to finish: 3553.18\n",
      "epoch 306(3.82)/1200(1214.69) - gen_loss = 0.67564, disc_loss = 1.37536, estimated to finish: 3548.79\n",
      "epoch 307(3.79)/1200(1218.47) - gen_loss = 0.67713, disc_loss = 1.37295, estimated to finish: 3544.28\n",
      "epoch 308(3.83)/1200(1222.3) - gen_loss = 0.6783, disc_loss = 1.37102, estimated to finish: 3539.91\n",
      "epoch 309(3.89)/1200(1226.19) - gen_loss = 0.67977, disc_loss = 1.36934, estimated to finish: 3535.7\n",
      "epoch 310(3.85)/1200(1230.04) - gen_loss = 0.68166, disc_loss = 1.36688, estimated to finish: 3531.39\n",
      "epoch 311(3.79)/1200(1233.83) - gen_loss = 0.6826, disc_loss = 1.36386, estimated to finish: 3526.93\n",
      "epoch 312(3.87)/1200(1237.7) - gen_loss = 0.68311, disc_loss = 1.36181, estimated to finish: 3522.7\n",
      "epoch 313(3.85)/1200(1241.55) - gen_loss = 0.68448, disc_loss = 1.36029, estimated to finish: 3518.4\n",
      "epoch 314(3.86)/1200(1245.41) - gen_loss = 0.68648, disc_loss = 1.35833, estimated to finish: 3514.13\n",
      "epoch 315(3.8)/1200(1249.21) - gen_loss = 0.68914, disc_loss = 1.3553, estimated to finish: 3509.68\n",
      "epoch 316(3.83)/1200(1253.04) - gen_loss = 0.69083, disc_loss = 1.35278, estimated to finish: 3505.33\n",
      "epoch 317(3.83)/1200(1256.86) - gen_loss = 0.69311, disc_loss = 1.34976, estimated to finish: 3500.98\n",
      "epoch 318(3.87)/1200(1260.73) - gen_loss = 0.6951, disc_loss = 1.34701, estimated to finish: 3496.75\n",
      "epoch 319(3.8)/1200(1264.53) - gen_loss = 0.69728, disc_loss = 1.34402, estimated to finish: 3492.33\n",
      "epoch 320(3.88)/1200(1268.41) - gen_loss = 0.69968, disc_loss = 1.34172, estimated to finish: 3488.14\n",
      "epoch 321(3.84)/1200(1272.26) - gen_loss = 0.70177, disc_loss = 1.33949, estimated to finish: 3483.85\n",
      "epoch 322(3.82)/1200(1276.08) - gen_loss = 0.7043, disc_loss = 1.33807, estimated to finish: 3479.5\n",
      "epoch 323(3.91)/1200(1280.0) - gen_loss = 0.70555, disc_loss = 1.33746, estimated to finish: 3475.41\n",
      "epoch 324(3.85)/1200(1283.85) - gen_loss = 0.70693, disc_loss = 1.3388, estimated to finish: 3471.14\n",
      "epoch 325(3.85)/1200(1287.7) - gen_loss = 0.70631, disc_loss = 1.34138, estimated to finish: 3466.89\n",
      "epoch 326(3.84)/1200(1291.54) - gen_loss = 0.70451, disc_loss = 1.347, estimated to finish: 3462.59\n",
      "epoch 327(3.84)/1200(1295.37) - gen_loss = 0.70287, disc_loss = 1.35435, estimated to finish: 3458.29\n",
      "epoch 328(3.89)/1200(1299.26) - gen_loss = 0.69857, disc_loss = 1.36476, estimated to finish: 3454.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 329(3.82)/1200(1303.08) - gen_loss = 0.69523, disc_loss = 1.3755, estimated to finish: 3449.81\n",
      "epoch 330(3.84)/1200(1306.92) - gen_loss = 0.69382, disc_loss = 1.38476, estimated to finish: 3445.53\n",
      "epoch 331(3.9)/1200(1310.83) - gen_loss = 0.69353, disc_loss = 1.39352, estimated to finish: 3441.41\n",
      "epoch 332(3.85)/1200(1314.67) - gen_loss = 0.69296, disc_loss = 1.40103, estimated to finish: 3437.16\n",
      "epoch 333(3.84)/1200(1318.51) - gen_loss = 0.69639, disc_loss = 1.40405, estimated to finish: 3432.88\n",
      "epoch 334(3.86)/1200(1322.37) - gen_loss = 0.70098, disc_loss = 1.40452, estimated to finish: 3428.66\n",
      "epoch 335(3.88)/1200(1326.24) - gen_loss = 0.70884, disc_loss = 1.39895, estimated to finish: 3424.48\n",
      "epoch 336(3.82)/1200(1330.07) - gen_loss = 0.71709, disc_loss = 1.38973, estimated to finish: 3420.17\n",
      "epoch 337(3.92)/1200(1333.98) - gen_loss = 0.72603, disc_loss = 1.3784, estimated to finish: 3416.1\n",
      "epoch 338(3.83)/1200(1337.81) - gen_loss = 0.73476, disc_loss = 1.36434, estimated to finish: 3411.81\n",
      "epoch 339(3.81)/1200(1341.62) - gen_loss = 0.74358, disc_loss = 1.35042, estimated to finish: 3407.48\n",
      "epoch 340(3.88)/1200(1345.5) - gen_loss = 0.75225, disc_loss = 1.33477, estimated to finish: 3403.34\n",
      "epoch 341(3.85)/1200(1349.35) - gen_loss = 0.76018, disc_loss = 1.31836, estimated to finish: 3399.1\n",
      "epoch 342(3.79)/1200(1353.14) - gen_loss = 0.76767, disc_loss = 1.30371, estimated to finish: 3394.71\n",
      "epoch 343(3.76)/1200(1356.89) - gen_loss = 0.7749, disc_loss = 1.28803, estimated to finish: 3390.26\n",
      "epoch 344(3.86)/1200(1360.75) - gen_loss = 0.77977, disc_loss = 1.27543, estimated to finish: 3386.05\n",
      "epoch 345(3.87)/1200(1364.62) - gen_loss = 0.78475, disc_loss = 1.26458, estimated to finish: 3381.89\n",
      "epoch 346(3.89)/1200(1368.51) - gen_loss = 0.78564, disc_loss = 1.25889, estimated to finish: 3377.77\n",
      "epoch 347(3.8)/1200(1372.31) - gen_loss = 0.78228, disc_loss = 1.25935, estimated to finish: 3373.43\n",
      "epoch 348(3.87)/1200(1376.17) - gen_loss = 0.77761, disc_loss = 1.26186, estimated to finish: 3369.26\n",
      "epoch 349(3.86)/1200(1380.04) - gen_loss = 0.77073, disc_loss = 1.2692, estimated to finish: 3365.08\n",
      "epoch 350(3.9)/1200(1383.93) - gen_loss = 0.75271, disc_loss = 1.28916, estimated to finish: 3360.98\n",
      "epoch 351(3.88)/1200(1387.82) - gen_loss = 0.72491, disc_loss = 1.32356, estimated to finish: 3356.86\n",
      "epoch 352(3.79)/1200(1391.61) - gen_loss = 0.68043, disc_loss = 1.38059, estimated to finish: 3352.51\n",
      "epoch 353(3.86)/1200(1395.46) - gen_loss = 0.67266, disc_loss = 1.39621, estimated to finish: 3348.32\n",
      "epoch 354(3.85)/1200(1399.32) - gen_loss = 0.6475, disc_loss = 1.38599, estimated to finish: 3344.13\n",
      "epoch 355(3.87)/1200(1403.19) - gen_loss = 0.65733, disc_loss = 1.39351, estimated to finish: 3339.98\n",
      "epoch 356(3.88)/1200(1407.07) - gen_loss = 0.67771, disc_loss = 1.36075, estimated to finish: 3335.86\n",
      "epoch 357(3.83)/1200(1410.9) - gen_loss = 0.6727, disc_loss = 1.35179, estimated to finish: 3331.62\n",
      "epoch 358(3.85)/1200(1414.75) - gen_loss = 0.69785, disc_loss = 1.33319, estimated to finish: 3327.42\n",
      "epoch 359(3.88)/1200(1418.63) - gen_loss = 0.71435, disc_loss = 1.32667, estimated to finish: 3323.31\n",
      "epoch 360(3.79)/1200(1422.42) - gen_loss = 0.71041, disc_loss = 1.33286, estimated to finish: 3318.98\n",
      "epoch 361(3.82)/1200(1426.24) - gen_loss = 0.71834, disc_loss = 1.32163, estimated to finish: 3314.73\n",
      "epoch 362(3.81)/1200(1430.06) - gen_loss = 0.71088, disc_loss = 1.32466, estimated to finish: 3310.47\n",
      "epoch 363(3.84)/1200(1433.9) - gen_loss = 0.75468, disc_loss = 1.23486, estimated to finish: 3306.26\n",
      "epoch 364(3.83)/1200(1437.72) - gen_loss = 0.68652, disc_loss = 1.30049, estimated to finish: 3302.02\n",
      "epoch 365(3.88)/1200(1441.6) - gen_loss = 0.71831, disc_loss = 1.29542, estimated to finish: 3297.91\n",
      "epoch 366(3.8)/1200(1445.4) - gen_loss = 0.7367, disc_loss = 1.29147, estimated to finish: 3293.62\n",
      "epoch 367(3.83)/1200(1449.23) - gen_loss = 0.7438, disc_loss = 1.29147, estimated to finish: 3289.4\n",
      "epoch 368(3.86)/1200(1453.09) - gen_loss = 0.75116, disc_loss = 1.28757, estimated to finish: 3285.25\n",
      "epoch 369(3.87)/1200(1456.96) - gen_loss = 0.75147, disc_loss = 1.28593, estimated to finish: 3281.12\n",
      "epoch 370(3.86)/1200(1460.82) - gen_loss = 0.74995, disc_loss = 1.28836, estimated to finish: 3276.97\n",
      "epoch 371(3.9)/1200(1464.72) - gen_loss = 0.75455, disc_loss = 1.28259, estimated to finish: 3272.93\n",
      "epoch 372(3.86)/1200(1468.58) - gen_loss = 0.7549, disc_loss = 1.28308, estimated to finish: 3268.77\n",
      "epoch 373(3.8)/1200(1472.38) - gen_loss = 0.74424, disc_loss = 1.28952, estimated to finish: 3264.49\n",
      "epoch 374(3.83)/1200(1476.2) - gen_loss = 0.74512, disc_loss = 1.3017, estimated to finish: 3260.28\n",
      "epoch 375(3.91)/1200(1480.11) - gen_loss = 1.00068, disc_loss = 0.97652, estimated to finish: 3256.25\n",
      "epoch 376(3.87)/1200(1483.98) - gen_loss = 1.05856, disc_loss = 0.82005, estimated to finish: 3252.13\n",
      "epoch 377(3.88)/1200(1487.87) - gen_loss = 0.3992, disc_loss = 1.46717, estimated to finish: 3248.05\n",
      "epoch 378(3.82)/1200(1491.69) - gen_loss = 0.57224, disc_loss = 1.32094, estimated to finish: 3243.84\n",
      "epoch 379(3.87)/1200(1495.56) - gen_loss = 0.67871, disc_loss = 1.28131, estimated to finish: 3239.73\n",
      "epoch 380(3.81)/1200(1499.37) - gen_loss = 0.72384, disc_loss = 1.27714, estimated to finish: 3235.49\n",
      "epoch 381(3.84)/1200(1503.21) - gen_loss = 0.75024, disc_loss = 1.26815, estimated to finish: 3231.31\n",
      "epoch 382(3.81)/1200(1507.02) - gen_loss = 0.75945, disc_loss = 1.26764, estimated to finish: 3227.08\n",
      "epoch 383(3.81)/1200(1510.83) - gen_loss = 0.75564, disc_loss = 1.27531, estimated to finish: 3222.84\n",
      "epoch 384(3.96)/1200(1514.79) - gen_loss = 0.67462, disc_loss = 1.37449, estimated to finish: 3218.93\n",
      "epoch 385(3.84)/1200(1518.63) - gen_loss = 0.88512, disc_loss = 1.2459, estimated to finish: 3214.76\n",
      "epoch 386(3.87)/1200(1522.5) - gen_loss = 0.55575, disc_loss = 1.45463, estimated to finish: 3210.65\n",
      "epoch 387(3.84)/1200(1526.33) - gen_loss = 0.59126, disc_loss = 1.46096, estimated to finish: 3206.49\n",
      "epoch 388(3.87)/1200(1530.21) - gen_loss = 0.65244, disc_loss = 1.35562, estimated to finish: 3202.39\n",
      "epoch 389(3.84)/1200(1534.05) - gen_loss = 0.62549, disc_loss = 1.44068, estimated to finish: 3198.24\n",
      "epoch 390(3.92)/1200(1537.97) - gen_loss = 0.61082, disc_loss = 1.45726, estimated to finish: 3194.26\n",
      "epoch 391(3.86)/1200(1541.83) - gen_loss = 0.64208, disc_loss = 1.42603, estimated to finish: 3190.14\n",
      "epoch 392(3.82)/1200(1545.66) - gen_loss = 0.66529, disc_loss = 1.40371, estimated to finish: 3185.94\n",
      "epoch 393(3.88)/1200(1549.53) - gen_loss = 0.67554, disc_loss = 1.40137, estimated to finish: 3181.86\n",
      "epoch 394(3.86)/1200(1553.39) - gen_loss = 0.68144, disc_loss = 1.39839, estimated to finish: 3177.74\n",
      "epoch 395(3.88)/1200(1557.26) - gen_loss = 0.6845, disc_loss = 1.39885, estimated to finish: 3173.67\n",
      "epoch 396(3.9)/1200(1561.17) - gen_loss = 0.68841, disc_loss = 1.39617, estimated to finish: 3169.65\n",
      "epoch 397(3.84)/1200(1565.01) - gen_loss = 0.69332, disc_loss = 1.39487, estimated to finish: 3165.49\n",
      "epoch 398(3.86)/1200(1568.87) - gen_loss = 0.69352, disc_loss = 1.39473, estimated to finish: 3161.39\n",
      "epoch 399(3.94)/1200(1572.8) - gen_loss = 0.69574, disc_loss = 1.39195, estimated to finish: 3157.44\n",
      "epoch 400(3.86)/1200(1576.67) - gen_loss = 0.69066, disc_loss = 1.39539, estimated to finish: 3153.34\n",
      "epoch 401(3.9)/1200(1580.57) - gen_loss = 0.6885, disc_loss = 1.39773, estimated to finish: 3149.31\n",
      "epoch 402(3.88)/1200(1584.45) - gen_loss = 0.68074, disc_loss = 1.40706, estimated to finish: 3145.24\n",
      "epoch 403(3.87)/1200(1588.31) - gen_loss = 0.69899, disc_loss = 1.3922, estimated to finish: 3141.16\n",
      "epoch 404(3.87)/1200(1592.18) - gen_loss = 0.7311, disc_loss = 1.35678, estimated to finish: 3137.07\n",
      "epoch 405(3.87)/1200(1596.05) - gen_loss = 0.75947, disc_loss = 1.31921, estimated to finish: 3132.99\n",
      "epoch 406(3.91)/1200(1599.96) - gen_loss = 0.77846, disc_loss = 1.28734, estimated to finish: 3128.99\n",
      "epoch 407(4.01)/1200(1603.97) - gen_loss = 0.79316, disc_loss = 1.26153, estimated to finish: 3125.17\n",
      "epoch 408(3.88)/1200(1607.84) - gen_loss = 0.76849, disc_loss = 1.27012, estimated to finish: 3121.1\n",
      "epoch 409(3.9)/1200(1611.74) - gen_loss = 0.71423, disc_loss = 1.39548, estimated to finish: 3117.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 410(3.93)/1200(1615.67) - gen_loss = 0.83051, disc_loss = 1.239, estimated to finish: 3113.13\n",
      "epoch 411(3.89)/1200(1619.57) - gen_loss = 0.85747, disc_loss = 1.20014, estimated to finish: 3109.1\n",
      "epoch 412(3.89)/1200(1623.46) - gen_loss = 0.88021, disc_loss = 1.16864, estimated to finish: 3105.06\n",
      "epoch 413(3.89)/1200(1627.35) - gen_loss = 0.9014, disc_loss = 1.13587, estimated to finish: 3101.02\n",
      "epoch 414(3.94)/1200(1631.29) - gen_loss = 0.91602, disc_loss = 1.10696, estimated to finish: 3097.08\n",
      "epoch 415(4.32)/1200(1635.61) - gen_loss = 0.93637, disc_loss = 1.07442, estimated to finish: 3093.87\n",
      "epoch 416(3.98)/1200(1639.59) - gen_loss = 0.95321, disc_loss = 1.04911, estimated to finish: 3090.0\n",
      "epoch 417(3.88)/1200(1643.47) - gen_loss = 0.97006, disc_loss = 1.02215, estimated to finish: 3085.93\n",
      "epoch 418(4.26)/1200(1647.72) - gen_loss = 0.99041, disc_loss = 0.99819, estimated to finish: 3082.58\n",
      "epoch 419(4.37)/1200(1652.09) - gen_loss = 1.00191, disc_loss = 0.98196, estimated to finish: 3079.43\n",
      "epoch 420(4.36)/1200(1656.45) - gen_loss = 1.00898, disc_loss = 0.96935, estimated to finish: 3076.27\n",
      "epoch 421(4.29)/1200(1660.74) - gen_loss = 0.9922, disc_loss = 0.97426, estimated to finish: 3072.97\n",
      "epoch 422(4.25)/1200(1664.99) - gen_loss = 0.9382, disc_loss = 1.01484, estimated to finish: 3069.59\n",
      "epoch 423(4.35)/1200(1669.34) - gen_loss = 0.66083, disc_loss = 1.32077, estimated to finish: 3066.38\n",
      "epoch 424(4.15)/1200(1673.5) - gen_loss = 0.50629, disc_loss = 1.72166, estimated to finish: 3062.81\n",
      "epoch 425(4.52)/1200(1678.02) - gen_loss = 0.50634, disc_loss = 1.65834, estimated to finish: 3059.92\n",
      "epoch 426(4.38)/1200(1682.4) - gen_loss = 0.5492, disc_loss = 1.61702, estimated to finish: 3056.75\n",
      "epoch 427(4.31)/1200(1686.71) - gen_loss = 0.56162, disc_loss = 1.60456, estimated to finish: 3053.45\n",
      "epoch 428(4.4)/1200(1691.1) - gen_loss = 0.55357, disc_loss = 1.587, estimated to finish: 3050.3\n",
      "epoch 429(4.35)/1200(1695.46) - gen_loss = 0.60569, disc_loss = 1.54806, estimated to finish: 3047.08\n",
      "epoch 430(4.41)/1200(1699.87) - gen_loss = 0.62345, disc_loss = 1.52071, estimated to finish: 3043.95\n",
      "epoch 431(4.31)/1200(1704.18) - gen_loss = 0.63126, disc_loss = 1.51493, estimated to finish: 3040.63\n",
      "epoch 432(3.8)/1200(1707.98) - gen_loss = 0.67579, disc_loss = 1.45608, estimated to finish: 3036.41\n",
      "epoch 433(4.13)/1200(1712.11) - gen_loss = 0.67495, disc_loss = 1.45234, estimated to finish: 3032.77\n",
      "epoch 434(4.13)/1200(1716.24) - gen_loss = 0.69136, disc_loss = 1.42475, estimated to finish: 3029.13\n",
      "epoch 435(4.28)/1200(1720.52) - gen_loss = 0.68534, disc_loss = 1.43293, estimated to finish: 3025.75\n",
      "epoch 436(4.34)/1200(1724.87) - gen_loss = 0.66661, disc_loss = 1.43965, estimated to finish: 3022.47\n",
      "epoch 437(4.18)/1200(1729.04) - gen_loss = 0.71857, disc_loss = 1.39519, estimated to finish: 3018.9\n",
      "epoch 438(3.97)/1200(1733.01) - gen_loss = 0.69049, disc_loss = 1.40882, estimated to finish: 3014.97\n",
      "epoch 439(4.13)/1200(1737.15) - gen_loss = 0.70694, disc_loss = 1.38967, estimated to finish: 3011.32\n",
      "epoch 440(4.07)/1200(1741.21) - gen_loss = 0.71703, disc_loss = 1.37515, estimated to finish: 3007.55\n",
      "epoch 441(4.17)/1200(1745.38) - gen_loss = 0.71464, disc_loss = 1.37222, estimated to finish: 3003.96\n",
      "epoch 442(4.2)/1200(1749.58) - gen_loss = 0.70179, disc_loss = 1.38519, estimated to finish: 3000.41\n",
      "epoch 443(4.16)/1200(1753.74) - gen_loss = 0.70304, disc_loss = 1.38333, estimated to finish: 2996.79\n",
      "epoch 444(4.57)/1200(1758.3) - gen_loss = 0.7203, disc_loss = 1.35921, estimated to finish: 2993.87\n",
      "epoch 445(3.82)/1200(1762.12) - gen_loss = 0.74797, disc_loss = 1.32051, estimated to finish: 2989.67\n",
      "epoch 446(3.79)/1200(1765.91) - gen_loss = 0.7749, disc_loss = 1.27897, estimated to finish: 2985.42\n",
      "epoch 447(3.94)/1200(1769.85) - gen_loss = 0.78657, disc_loss = 1.24592, estimated to finish: 2981.43\n",
      "epoch 448(4.24)/1200(1774.09) - gen_loss = 0.78149, disc_loss = 1.23655, estimated to finish: 2977.94\n",
      "epoch 449(4.01)/1200(1778.1) - gen_loss = 0.67056, disc_loss = 1.34862, estimated to finish: 2974.06\n",
      "epoch 450(3.93)/1200(1782.03) - gen_loss = 0.62736, disc_loss = 1.46318, estimated to finish: 2970.04\n",
      "epoch 451(3.76)/1200(1785.78) - gen_loss = 0.83147, disc_loss = 1.25412, estimated to finish: 2965.75\n",
      "epoch 452(3.8)/1200(1789.58) - gen_loss = 0.85666, disc_loss = 1.20015, estimated to finish: 2961.52\n",
      "epoch 453(4.21)/1200(1793.79) - gen_loss = 0.8805, disc_loss = 1.15522, estimated to finish: 2957.97\n",
      "epoch 454(3.92)/1200(1797.71) - gen_loss = 0.90396, disc_loss = 1.11333, estimated to finish: 2953.94\n",
      "epoch 455(3.86)/1200(1801.57) - gen_loss = 0.91543, disc_loss = 1.07988, estimated to finish: 2949.82\n",
      "epoch 456(3.79)/1200(1805.36) - gen_loss = 0.92922, disc_loss = 1.05251, estimated to finish: 2945.58\n",
      "epoch 457(3.72)/1200(1809.07) - gen_loss = 0.93863, disc_loss = 1.03373, estimated to finish: 2941.23\n",
      "epoch 458(3.76)/1200(1812.83) - gen_loss = 0.94148, disc_loss = 1.02321, estimated to finish: 2936.95\n",
      "epoch 459(3.74)/1200(1816.58) - gen_loss = 0.92271, disc_loss = 1.03026, estimated to finish: 2932.64\n",
      "epoch 460(3.7)/1200(1820.28) - gen_loss = 0.83004, disc_loss = 1.10851, estimated to finish: 2928.28\n",
      "epoch 461(3.76)/1200(1824.04) - gen_loss = 0.45278, disc_loss = 1.65811, estimated to finish: 2924.0\n",
      "epoch 462(3.8)/1200(1827.84) - gen_loss = 0.54951, disc_loss = 1.62596, estimated to finish: 2919.8\n",
      "epoch 463(3.76)/1200(1831.6) - gen_loss = 0.57789, disc_loss = 1.55274, estimated to finish: 2915.53\n",
      "epoch 464(3.78)/1200(1835.38) - gen_loss = 0.64619, disc_loss = 1.43939, estimated to finish: 2911.29\n",
      "epoch 465(3.79)/1200(1839.17) - gen_loss = 0.69895, disc_loss = 1.41849, estimated to finish: 2907.07\n",
      "epoch 466(4.08)/1200(1843.24) - gen_loss = 0.68182, disc_loss = 1.4111, estimated to finish: 2903.31\n",
      "epoch 467(4.04)/1200(1847.29) - gen_loss = 0.8902, disc_loss = 1.21715, estimated to finish: 2899.49\n",
      "epoch 468(4.04)/1200(1851.33) - gen_loss = 0.8349, disc_loss = 1.20622, estimated to finish: 2895.66\n",
      "epoch 469(4.21)/1200(1855.53) - gen_loss = 0.68693, disc_loss = 1.34723, estimated to finish: 2892.1\n",
      "epoch 470(3.94)/1200(1859.47) - gen_loss = 0.68513, disc_loss = 1.388, estimated to finish: 2888.11\n",
      "epoch 471(3.84)/1200(1863.31) - gen_loss = 0.75085, disc_loss = 1.33184, estimated to finish: 2883.98\n",
      "epoch 472(3.86)/1200(1867.17) - gen_loss = 0.77194, disc_loss = 1.2919, estimated to finish: 2879.87\n",
      "epoch 473(4.0)/1200(1871.16) - gen_loss = 0.77275, disc_loss = 1.28845, estimated to finish: 2875.98\n",
      "epoch 474(3.96)/1200(1875.13) - gen_loss = 0.84913, disc_loss = 1.2211, estimated to finish: 2872.03\n",
      "epoch 475(3.96)/1200(1879.09) - gen_loss = 0.85894, disc_loss = 1.20906, estimated to finish: 2868.08\n",
      "epoch 476(3.87)/1200(1882.95) - gen_loss = 0.70776, disc_loss = 1.31438, estimated to finish: 2863.99\n",
      "epoch 477(3.94)/1200(1886.9) - gen_loss = 0.70569, disc_loss = 1.31582, estimated to finish: 2860.01\n",
      "epoch 478(4.1)/1200(1891.0) - gen_loss = 0.75659, disc_loss = 1.26967, estimated to finish: 2856.28\n",
      "epoch 479(3.87)/1200(1894.87) - gen_loss = 0.82032, disc_loss = 1.20554, estimated to finish: 2852.19\n",
      "epoch 480(3.83)/1200(1898.7) - gen_loss = 0.87236, disc_loss = 1.14312, estimated to finish: 2848.05\n",
      "epoch 481(4.12)/1200(1902.82) - gen_loss = 0.9186, disc_loss = 1.08713, estimated to finish: 2844.34\n",
      "epoch 482(3.9)/1200(1906.72) - gen_loss = 0.95415, disc_loss = 1.03042, estimated to finish: 2840.3\n",
      "epoch 483(4.04)/1200(1910.76) - gen_loss = 0.99126, disc_loss = 0.97838, estimated to finish: 2836.47\n",
      "epoch 484(3.79)/1200(1914.55) - gen_loss = 1.02203, disc_loss = 0.93328, estimated to finish: 2832.26\n",
      "epoch 485(3.84)/1200(1918.39) - gen_loss = 1.05432, disc_loss = 0.89752, estimated to finish: 2828.13\n",
      "epoch 486(3.85)/1200(1922.23) - gen_loss = 1.08027, disc_loss = 0.8661, estimated to finish: 2824.02\n",
      "epoch 487(3.69)/1200(1925.92) - gen_loss = 1.09897, disc_loss = 0.84321, estimated to finish: 2819.68\n",
      "epoch 488(3.8)/1200(1929.72) - gen_loss = 1.08685, disc_loss = 0.84196, estimated to finish: 2815.49\n",
      "epoch 489(3.78)/1200(1933.5) - gen_loss = 0.7531, disc_loss = 1.15717, estimated to finish: 2811.28\n",
      "epoch 490(3.76)/1200(1937.26) - gen_loss = 0.38391, disc_loss = 1.79001, estimated to finish: 2807.04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 491(3.85)/1200(1941.11) - gen_loss = 0.50801, disc_loss = 1.59398, estimated to finish: 2802.94\n",
      "epoch 492(4.25)/1200(1945.36) - gen_loss = 0.6051, disc_loss = 1.48053, estimated to finish: 2799.42\n",
      "epoch 493(4.05)/1200(1949.41) - gen_loss = 0.66044, disc_loss = 1.42296, estimated to finish: 2795.6\n",
      "epoch 494(4.13)/1200(1953.54) - gen_loss = 0.69799, disc_loss = 1.375, estimated to finish: 2791.9\n",
      "epoch 495(3.74)/1200(1957.28) - gen_loss = 0.73491, disc_loss = 1.33378, estimated to finish: 2787.64\n",
      "epoch 496(3.96)/1200(1961.24) - gen_loss = 0.76192, disc_loss = 1.29804, estimated to finish: 2783.7\n",
      "epoch 497(3.91)/1200(1965.15) - gen_loss = 0.79162, disc_loss = 1.26227, estimated to finish: 2779.68\n",
      "epoch 498(3.9)/1200(1969.05) - gen_loss = 0.81556, disc_loss = 1.23578, estimated to finish: 2775.65\n",
      "epoch 499(3.8)/1200(1972.85) - gen_loss = 0.85579, disc_loss = 1.21022, estimated to finish: 2771.48\n",
      "epoch 500(3.91)/1200(1976.76) - gen_loss = 0.87415, disc_loss = 1.17223, estimated to finish: 2767.46\n",
      "epoch 501(4.09)/1200(1980.85) - gen_loss = 0.89781, disc_loss = 1.14513, estimated to finish: 2763.7\n",
      "epoch 502(4.06)/1200(1984.91) - gen_loss = 0.9175, disc_loss = 1.1206, estimated to finish: 2759.89\n",
      "epoch 503(3.79)/1200(1988.7) - gen_loss = 0.93849, disc_loss = 1.07745, estimated to finish: 2755.71\n",
      "epoch 504(3.96)/1200(1992.66) - gen_loss = 0.95892, disc_loss = 1.04796, estimated to finish: 2751.76\n",
      "epoch 505(4.11)/1200(1996.77) - gen_loss = 0.99068, disc_loss = 1.0219, estimated to finish: 2748.03\n",
      "epoch 506(4.11)/1200(2000.88) - gen_loss = 1.00573, disc_loss = 1.00406, estimated to finish: 2744.28\n",
      "epoch 507(4.17)/1200(2005.05) - gen_loss = 0.97305, disc_loss = 1.03391, estimated to finish: 2740.63\n",
      "epoch 508(4.54)/1200(2009.59) - gen_loss = 0.59654, disc_loss = 1.40323, estimated to finish: 2737.47\n",
      "epoch 509(4.12)/1200(2013.7) - gen_loss = 0.72058, disc_loss = 1.33392, estimated to finish: 2733.73\n",
      "epoch 510(4.65)/1200(2018.35) - gen_loss = 0.90394, disc_loss = 1.16298, estimated to finish: 2730.7\n",
      "epoch 511(4.54)/1200(2022.89) - gen_loss = 1.05077, disc_loss = 1.00976, estimated to finish: 2727.53\n",
      "epoch 512(3.93)/1200(2026.82) - gen_loss = 1.15041, disc_loss = 0.89123, estimated to finish: 2723.54\n",
      "epoch 513(3.99)/1200(2030.81) - gen_loss = 1.23437, disc_loss = 0.79722, estimated to finish: 2719.62\n",
      "epoch 514(3.9)/1200(2034.71) - gen_loss = 1.30876, disc_loss = 0.7255, estimated to finish: 2715.58\n",
      "epoch 515(3.75)/1200(2038.46) - gen_loss = 1.38476, disc_loss = 0.66261, estimated to finish: 2711.34\n",
      "epoch 516(3.77)/1200(2042.22) - gen_loss = 1.45279, disc_loss = 0.61121, estimated to finish: 2707.13\n",
      "epoch 517(3.69)/1200(2045.92) - gen_loss = 1.52818, disc_loss = 0.56386, estimated to finish: 2702.83\n",
      "epoch 518(3.71)/1200(2049.63) - gen_loss = 1.59622, disc_loss = 0.52319, estimated to finish: 2698.55\n",
      "epoch 519(3.77)/1200(2053.4) - gen_loss = 1.66914, disc_loss = 0.48614, estimated to finish: 2694.34\n",
      "epoch 520(3.63)/1200(2057.02) - gen_loss = 1.73274, disc_loss = 0.45495, estimated to finish: 2689.95\n",
      "epoch 521(3.73)/1200(2060.75) - gen_loss = 1.79457, disc_loss = 0.4267, estimated to finish: 2685.7\n",
      "epoch 522(3.75)/1200(2064.5) - gen_loss = 1.84837, disc_loss = 0.40235, estimated to finish: 2681.48\n",
      "epoch 523(3.73)/1200(2068.23) - gen_loss = 1.88796, disc_loss = 0.38631, estimated to finish: 2677.23\n",
      "epoch 524(3.74)/1200(2071.97) - gen_loss = 1.89541, disc_loss = 0.3764, estimated to finish: 2673.0\n",
      "epoch 525(3.77)/1200(2075.74) - gen_loss = 1.36996, disc_loss = 0.69201, estimated to finish: 2668.81\n",
      "epoch 526(3.77)/1200(2079.51) - gen_loss = 0.31016, disc_loss = 1.93296, estimated to finish: 2664.61\n",
      "epoch 527(3.78)/1200(2083.28) - gen_loss = 0.54249, disc_loss = 1.50377, estimated to finish: 2660.43\n",
      "epoch 528(3.78)/1200(2087.07) - gen_loss = 0.58485, disc_loss = 1.41388, estimated to finish: 2656.27\n",
      "epoch 529(3.73)/1200(2090.8) - gen_loss = 0.73556, disc_loss = 1.26947, estimated to finish: 2652.03\n",
      "epoch 530(3.76)/1200(2094.56) - gen_loss = 0.81821, disc_loss = 1.17477, estimated to finish: 2647.84\n",
      "epoch 531(3.7)/1200(2098.26) - gen_loss = 0.88443, disc_loss = 1.11503, estimated to finish: 2643.57\n",
      "epoch 532(3.77)/1200(2102.03) - gen_loss = 0.95434, disc_loss = 1.05147, estimated to finish: 2639.39\n",
      "epoch 533(3.77)/1200(2105.8) - gen_loss = 1.01282, disc_loss = 0.99086, estimated to finish: 2635.21\n",
      "epoch 534(3.75)/1200(2109.55) - gen_loss = 1.0858, disc_loss = 0.9207, estimated to finish: 2631.01\n",
      "epoch 535(3.75)/1200(2113.3) - gen_loss = 1.14876, disc_loss = 0.85104, estimated to finish: 2626.82\n",
      "epoch 536(3.77)/1200(2117.08) - gen_loss = 1.22344, disc_loss = 0.77477, estimated to finish: 2622.65\n",
      "epoch 537(3.76)/1200(2120.83) - gen_loss = 1.32232, disc_loss = 0.69941, estimated to finish: 2618.46\n",
      "epoch 538(3.75)/1200(2124.59) - gen_loss = 1.41697, disc_loss = 0.61903, estimated to finish: 2614.27\n",
      "epoch 539(3.82)/1200(2128.41) - gen_loss = 1.55157, disc_loss = 0.5498, estimated to finish: 2610.17\n",
      "epoch 540(3.75)/1200(2132.16) - gen_loss = 1.65948, disc_loss = 0.48261, estimated to finish: 2605.98\n",
      "epoch 541(3.75)/1200(2135.92) - gen_loss = 1.66484, disc_loss = 0.47588, estimated to finish: 2601.79\n",
      "epoch 542(3.79)/1200(2139.71) - gen_loss = 1.82674, disc_loss = 0.57703, estimated to finish: 2597.66\n",
      "epoch 543(3.75)/1200(2143.46) - gen_loss = 1.3869, disc_loss = 0.89471, estimated to finish: 2593.46\n",
      "epoch 544(3.76)/1200(2147.22) - gen_loss = 1.82992, disc_loss = 0.53782, estimated to finish: 2589.29\n",
      "epoch 545(3.69)/1200(2150.9) - gen_loss = 2.20529, disc_loss = 0.39286, estimated to finish: 2585.03\n",
      "epoch 546(3.82)/1200(2154.72) - gen_loss = 2.37247, disc_loss = 0.33762, estimated to finish: 2580.93\n",
      "epoch 547(3.75)/1200(2158.47) - gen_loss = 2.49491, disc_loss = 0.30361, estimated to finish: 2576.74\n",
      "epoch 548(3.78)/1200(2162.25) - gen_loss = 2.57259, disc_loss = 0.27565, estimated to finish: 2572.6\n",
      "epoch 549(3.76)/1200(2166.01) - gen_loss = 2.62893, disc_loss = 0.2546, estimated to finish: 2568.43\n",
      "epoch 550(3.79)/1200(2169.79) - gen_loss = 2.67968, disc_loss = 0.23728, estimated to finish: 2564.3\n",
      "epoch 551(3.84)/1200(2173.63) - gen_loss = 2.73768, disc_loss = 0.22421, estimated to finish: 2560.23\n",
      "epoch 552(3.77)/1200(2177.4) - gen_loss = 2.7793, disc_loss = 0.20688, estimated to finish: 2556.08\n",
      "epoch 553(3.72)/1200(2181.12) - gen_loss = 2.81788, disc_loss = 0.19875, estimated to finish: 2551.87\n",
      "epoch 554(3.71)/1200(2184.83) - gen_loss = 2.87254, disc_loss = 0.18663, estimated to finish: 2547.65\n",
      "epoch 555(3.72)/1200(2188.55) - gen_loss = 2.90857, disc_loss = 0.17554, estimated to finish: 2543.45\n",
      "epoch 556(3.73)/1200(2192.28) - gen_loss = 2.98006, disc_loss = 0.16678, estimated to finish: 2539.26\n",
      "epoch 557(3.73)/1200(2196.0) - gen_loss = 3.02479, disc_loss = 0.15565, estimated to finish: 2535.06\n",
      "epoch 558(3.77)/1200(2199.78) - gen_loss = 3.08365, disc_loss = 0.14751, estimated to finish: 2530.93\n",
      "epoch 559(3.75)/1200(2203.52) - gen_loss = 3.13512, disc_loss = 0.13998, estimated to finish: 2526.76\n",
      "epoch 560(3.78)/1200(2207.3) - gen_loss = 3.18215, disc_loss = 0.13369, estimated to finish: 2522.63\n",
      "epoch 561(3.76)/1200(2211.06) - gen_loss = 3.24217, disc_loss = 0.12949, estimated to finish: 2518.48\n",
      "epoch 562(3.78)/1200(2214.84) - gen_loss = 3.27262, disc_loss = 0.12587, estimated to finish: 2514.36\n",
      "epoch 563(3.77)/1200(2218.61) - gen_loss = 3.1249, disc_loss = 0.1367, estimated to finish: 2510.22\n",
      "epoch 564(3.74)/1200(2222.35) - gen_loss = 1.13014, disc_loss = 0.97657, estimated to finish: 2506.05\n",
      "epoch 565(3.72)/1200(2226.07) - gen_loss = 1.49529, disc_loss = 0.55103, estimated to finish: 2501.87\n",
      "epoch 566(3.76)/1200(2229.83) - gen_loss = 1.74691, disc_loss = 0.41406, estimated to finish: 2497.73\n",
      "epoch 567(3.76)/1200(2233.6) - gen_loss = 2.11458, disc_loss = 0.2944, estimated to finish: 2493.59\n",
      "epoch 568(3.72)/1200(2237.32) - gen_loss = 2.50057, disc_loss = 0.62878, estimated to finish: 2489.41\n",
      "epoch 569(3.75)/1200(2241.07) - gen_loss = 1.94175, disc_loss = 0.35777, estimated to finish: 2485.27\n",
      "epoch 570(3.75)/1200(2244.83) - gen_loss = 2.20035, disc_loss = 0.30704, estimated to finish: 2481.12\n",
      "epoch 571(3.7)/1200(2248.53) - gen_loss = 2.35898, disc_loss = 0.29227, estimated to finish: 2476.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 572(3.74)/1200(2252.27) - gen_loss = 2.43077, disc_loss = 0.26059, estimated to finish: 2472.77\n",
      "epoch 573(3.75)/1200(2256.02) - gen_loss = 2.31847, disc_loss = 0.29336, estimated to finish: 2468.63\n",
      "epoch 574(3.76)/1200(2259.78) - gen_loss = 2.39434, disc_loss = 0.2903, estimated to finish: 2464.5\n",
      "epoch 575(3.71)/1200(2263.49) - gen_loss = 2.52434, disc_loss = 0.27096, estimated to finish: 2460.31\n",
      "epoch 576(3.79)/1200(2267.27) - gen_loss = 2.53361, disc_loss = 0.25691, estimated to finish: 2456.21\n",
      "epoch 577(3.83)/1200(2271.1) - gen_loss = 2.53433, disc_loss = 0.27538, estimated to finish: 2452.16\n",
      "epoch 578(3.77)/1200(2274.87) - gen_loss = 2.65111, disc_loss = 0.29834, estimated to finish: 2448.04\n",
      "epoch 579(3.74)/1200(2278.61) - gen_loss = 2.57169, disc_loss = 0.2454, estimated to finish: 2443.9\n",
      "epoch 580(3.74)/1200(2282.35) - gen_loss = 2.54089, disc_loss = 0.26798, estimated to finish: 2439.76\n",
      "epoch 581(3.97)/1200(2286.33) - gen_loss = 2.66541, disc_loss = 0.23417, estimated to finish: 2435.86\n",
      "epoch 582(4.06)/1200(2290.39) - gen_loss = 2.77013, disc_loss = 0.27178, estimated to finish: 2432.06\n",
      "epoch 583(3.79)/1200(2294.18) - gen_loss = 2.79725, disc_loss = 0.24829, estimated to finish: 2427.97\n",
      "epoch 584(3.75)/1200(2297.92) - gen_loss = 2.85379, disc_loss = 0.24933, estimated to finish: 2423.84\n",
      "epoch 585(3.78)/1200(2301.7) - gen_loss = 2.79529, disc_loss = 0.24814, estimated to finish: 2419.74\n",
      "epoch 586(3.8)/1200(2305.5) - gen_loss = 2.82197, disc_loss = 0.23098, estimated to finish: 2415.66\n",
      "epoch 587(3.73)/1200(2309.23) - gen_loss = 3.16912, disc_loss = 0.21294, estimated to finish: 2411.51\n",
      "epoch 588(3.75)/1200(2312.99) - gen_loss = 4.43956, disc_loss = 0.13986, estimated to finish: 2407.39\n",
      "epoch 589(3.75)/1200(2316.73) - gen_loss = 2.94474, disc_loss = 0.2491, estimated to finish: 2403.27\n",
      "epoch 590(3.78)/1200(2320.51) - gen_loss = 2.86518, disc_loss = 0.22694, estimated to finish: 2399.17\n",
      "epoch 591(3.85)/1200(2324.36) - gen_loss = 2.80257, disc_loss = 0.21498, estimated to finish: 2395.15\n",
      "epoch 592(3.7)/1200(2328.06) - gen_loss = 2.80995, disc_loss = 0.20785, estimated to finish: 2390.98\n",
      "epoch 593(3.77)/1200(2331.83) - gen_loss = 2.8958, disc_loss = 0.19775, estimated to finish: 2386.88\n",
      "epoch 594(3.73)/1200(2335.56) - gen_loss = 3.08598, disc_loss = 0.2161, estimated to finish: 2382.74\n",
      "epoch 595(3.8)/1200(2339.36) - gen_loss = 3.01415, disc_loss = 0.24408, estimated to finish: 2378.68\n",
      "epoch 596(3.8)/1200(2343.16) - gen_loss = 2.88643, disc_loss = 0.21737, estimated to finish: 2374.62\n",
      "epoch 597(3.82)/1200(2346.98) - gen_loss = 2.98631, disc_loss = 0.21554, estimated to finish: 2370.57\n",
      "epoch 598(3.77)/1200(2350.75) - gen_loss = 3.2082, disc_loss = 0.24006, estimated to finish: 2366.48\n",
      "epoch 599(3.77)/1200(2354.52) - gen_loss = 3.16046, disc_loss = 0.27355, estimated to finish: 2362.38\n",
      "epoch 600(3.74)/1200(2358.26) - gen_loss = 2.29248, disc_loss = 1.41327, estimated to finish: 2358.26\n",
      "epoch 601(3.75)/1200(2362.02) - gen_loss = 3.21474, disc_loss = 1.01772, estimated to finish: 2354.16\n",
      "epoch 602(3.75)/1200(2365.76) - gen_loss = 2.69977, disc_loss = 0.44324, estimated to finish: 2350.04\n",
      "epoch 603(3.78)/1200(2369.54) - gen_loss = 2.73824, disc_loss = 0.34931, estimated to finish: 2345.96\n",
      "epoch 604(3.75)/1200(2373.29) - gen_loss = 2.83084, disc_loss = 0.30361, estimated to finish: 2341.86\n",
      "epoch 605(3.78)/1200(2377.08) - gen_loss = 2.91367, disc_loss = 0.27682, estimated to finish: 2337.79\n",
      "epoch 606(3.7)/1200(2380.78) - gen_loss = 2.98208, disc_loss = 0.25381, estimated to finish: 2333.64\n",
      "epoch 607(3.75)/1200(2384.53) - gen_loss = 3.03225, disc_loss = 0.2309, estimated to finish: 2329.53\n",
      "epoch 608(3.77)/1200(2388.3) - gen_loss = 3.09957, disc_loss = 0.22165, estimated to finish: 2325.45\n",
      "epoch 609(3.75)/1200(2392.04) - gen_loss = 3.13263, disc_loss = 0.20439, estimated to finish: 2321.34\n",
      "epoch 610(3.79)/1200(2395.83) - gen_loss = 3.21383, disc_loss = 0.19342, estimated to finish: 2317.28\n",
      "epoch 611(3.81)/1200(2399.64) - gen_loss = 3.25617, disc_loss = 0.18234, estimated to finish: 2313.24\n",
      "epoch 612(3.77)/1200(2403.41) - gen_loss = 3.32701, disc_loss = 0.17758, estimated to finish: 2309.16\n",
      "epoch 613(3.75)/1200(2407.16) - gen_loss = 3.35175, disc_loss = 0.16727, estimated to finish: 2305.06\n",
      "epoch 614(3.73)/1200(2410.89) - gen_loss = 3.38607, disc_loss = 0.16003, estimated to finish: 2300.95\n",
      "epoch 615(3.8)/1200(2414.69) - gen_loss = 3.42314, disc_loss = 0.15231, estimated to finish: 2296.9\n",
      "epoch 616(3.78)/1200(2418.47) - gen_loss = 3.47159, disc_loss = 0.14748, estimated to finish: 2292.83\n",
      "epoch 617(3.77)/1200(2422.24) - gen_loss = 3.51455, disc_loss = 0.14253, estimated to finish: 2288.76\n",
      "epoch 618(3.76)/1200(2426.0) - gen_loss = 3.56297, disc_loss = 0.13741, estimated to finish: 2284.68\n",
      "epoch 619(3.77)/1200(2429.77) - gen_loss = 3.5927, disc_loss = 0.13262, estimated to finish: 2280.61\n",
      "epoch 620(3.74)/1200(2433.51) - gen_loss = 3.62611, disc_loss = 0.13002, estimated to finish: 2276.51\n",
      "epoch 621(3.88)/1200(2437.38) - gen_loss = 3.66349, disc_loss = 0.12872, estimated to finish: 2272.54\n",
      "epoch 622(3.8)/1200(2441.18) - gen_loss = 3.67456, disc_loss = 0.1239, estimated to finish: 2268.5\n",
      "epoch 623(3.72)/1200(2444.91) - gen_loss = 3.71591, disc_loss = 0.12199, estimated to finish: 2264.38\n",
      "epoch 624(3.78)/1200(2448.68) - gen_loss = 3.75091, disc_loss = 0.11564, estimated to finish: 2260.32\n",
      "epoch 625(3.77)/1200(2452.45) - gen_loss = 3.79021, disc_loss = 0.11207, estimated to finish: 2256.25\n",
      "epoch 626(3.76)/1200(2456.21) - gen_loss = 3.83393, disc_loss = 0.11199, estimated to finish: 2252.18\n",
      "epoch 627(3.75)/1200(2459.95) - gen_loss = 3.85363, disc_loss = 0.10842, estimated to finish: 2248.09\n",
      "epoch 628(3.77)/1200(2463.72) - gen_loss = 3.88237, disc_loss = 0.1076, estimated to finish: 2244.03\n",
      "epoch 629(3.76)/1200(2467.48) - gen_loss = 3.90629, disc_loss = 0.1058, estimated to finish: 2239.96\n",
      "epoch 630(3.72)/1200(2471.2) - gen_loss = 3.93416, disc_loss = 0.10174, estimated to finish: 2235.85\n",
      "epoch 631(3.75)/1200(2474.95) - gen_loss = 3.96164, disc_loss = 0.10435, estimated to finish: 2231.77\n",
      "epoch 632(3.75)/1200(2478.7) - gen_loss = 3.98489, disc_loss = 0.10258, estimated to finish: 2227.69\n",
      "epoch 633(3.76)/1200(2482.46) - gen_loss = 3.99827, disc_loss = 0.1003, estimated to finish: 2223.62\n",
      "epoch 634(3.77)/1200(2486.23) - gen_loss = 3.97471, disc_loss = 0.10867, estimated to finish: 2219.57\n",
      "epoch 635(3.75)/1200(2489.98) - gen_loss = 2.86241, disc_loss = 0.39723, estimated to finish: 2215.49\n",
      "epoch 636(3.79)/1200(2493.77) - gen_loss = 1.7643, disc_loss = 0.57192, estimated to finish: 2211.45\n",
      "epoch 637(3.69)/1200(2497.46) - gen_loss = 1.41633, disc_loss = 0.88688, estimated to finish: 2207.33\n",
      "epoch 638(3.78)/1200(2501.24) - gen_loss = 1.38873, disc_loss = 0.68526, estimated to finish: 2203.29\n",
      "epoch 639(3.8)/1200(2505.04) - gen_loss = 1.42954, disc_loss = 1.0772, estimated to finish: 2199.26\n",
      "epoch 640(3.82)/1200(2508.86) - gen_loss = 1.1004, disc_loss = 1.94066, estimated to finish: 2195.25\n",
      "epoch 641(3.78)/1200(2512.64) - gen_loss = 0.98095, disc_loss = 1.8023, estimated to finish: 2191.21\n",
      "epoch 642(3.74)/1200(2516.37) - gen_loss = 0.90456, disc_loss = 1.69529, estimated to finish: 2187.13\n",
      "epoch 643(3.68)/1200(2520.05) - gen_loss = 0.8549, disc_loss = 1.60836, estimated to finish: 2183.0\n",
      "epoch 644(3.74)/1200(2523.79) - gen_loss = 0.806, disc_loss = 1.55115, estimated to finish: 2178.92\n",
      "epoch 645(3.75)/1200(2527.54) - gen_loss = 0.76754, disc_loss = 1.49406, estimated to finish: 2174.86\n",
      "epoch 646(3.9)/1200(2531.44) - gen_loss = 0.73638, disc_loss = 1.45544, estimated to finish: 2170.93\n",
      "epoch 647(3.94)/1200(2535.38) - gen_loss = 0.71076, disc_loss = 1.4097, estimated to finish: 2167.03\n",
      "epoch 648(3.8)/1200(2539.18) - gen_loss = 0.69402, disc_loss = 1.36754, estimated to finish: 2163.01\n",
      "epoch 649(3.71)/1200(2542.89) - gen_loss = 0.68866, disc_loss = 1.32079, estimated to finish: 2158.91\n",
      "epoch 650(3.73)/1200(2546.62) - gen_loss = 0.68112, disc_loss = 1.23889, estimated to finish: 2154.83\n",
      "epoch 651(3.84)/1200(2550.46) - gen_loss = 0.81573, disc_loss = 1.29818, estimated to finish: 2150.85\n",
      "epoch 652(3.77)/1200(2554.23) - gen_loss = 1.01607, disc_loss = 0.70373, estimated to finish: 2146.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 653(3.76)/1200(2557.99) - gen_loss = 1.11543, disc_loss = 0.52692, estimated to finish: 2142.76\n",
      "epoch 654(3.7)/1200(2561.69) - gen_loss = 1.21358, disc_loss = 0.72566, estimated to finish: 2138.66\n",
      "epoch 655(3.68)/1200(2565.37) - gen_loss = 0.99608, disc_loss = 0.738, estimated to finish: 2134.55\n",
      "epoch 656(3.8)/1200(2569.17) - gen_loss = 1.31548, disc_loss = 0.49939, estimated to finish: 2130.53\n",
      "epoch 657(3.72)/1200(2572.89) - gen_loss = 1.5871, disc_loss = 0.41566, estimated to finish: 2126.45\n",
      "epoch 658(3.84)/1200(2576.73) - gen_loss = 1.79628, disc_loss = 0.35712, estimated to finish: 2122.47\n",
      "epoch 659(3.77)/1200(2580.5) - gen_loss = 1.97509, disc_loss = 0.29738, estimated to finish: 2118.44\n",
      "epoch 660(3.75)/1200(2584.25) - gen_loss = 2.36763, disc_loss = 0.23113, estimated to finish: 2114.38\n",
      "epoch 661(3.82)/1200(2588.07) - gen_loss = 2.58028, disc_loss = 0.19834, estimated to finish: 2110.39\n",
      "epoch 662(3.79)/1200(2591.85) - gen_loss = 2.51961, disc_loss = 0.19068, estimated to finish: 2106.37\n",
      "epoch 663(3.75)/1200(2595.6) - gen_loss = 2.31243, disc_loss = 0.2077, estimated to finish: 2102.32\n",
      "epoch 664(3.75)/1200(2599.35) - gen_loss = 2.28287, disc_loss = 0.20968, estimated to finish: 2098.27\n",
      "epoch 665(3.78)/1200(2603.13) - gen_loss = 2.42973, disc_loss = 0.19515, estimated to finish: 2094.25\n",
      "epoch 666(3.75)/1200(2606.87) - gen_loss = 2.55331, disc_loss = 0.18257, estimated to finish: 2090.2\n",
      "epoch 667(3.75)/1200(2610.63) - gen_loss = 2.7172, disc_loss = 0.16701, estimated to finish: 2086.15\n",
      "epoch 668(3.78)/1200(2614.41) - gen_loss = 2.80633, disc_loss = 0.15857, estimated to finish: 2082.13\n",
      "epoch 669(3.75)/1200(2618.16) - gen_loss = 2.91449, disc_loss = 0.14797, estimated to finish: 2078.09\n",
      "epoch 670(3.78)/1200(2621.93) - gen_loss = 2.98243, disc_loss = 0.14342, estimated to finish: 2074.07\n",
      "epoch 671(3.79)/1200(2625.73) - gen_loss = 3.05319, disc_loss = 0.13944, estimated to finish: 2070.06\n",
      "epoch 672(3.77)/1200(2629.49) - gen_loss = 3.06783, disc_loss = 0.1425, estimated to finish: 2066.03\n",
      "epoch 673(3.71)/1200(2633.2) - gen_loss = 3.14504, disc_loss = 0.16627, estimated to finish: 2061.96\n",
      "epoch 674(3.72)/1200(2636.92) - gen_loss = 3.47468, disc_loss = 0.14308, estimated to finish: 2057.9\n",
      "epoch 675(3.76)/1200(2640.69) - gen_loss = 3.53844, disc_loss = 0.13907, estimated to finish: 2053.87\n",
      "epoch 676(3.69)/1200(2644.37) - gen_loss = 3.56169, disc_loss = 0.1288, estimated to finish: 2049.78\n",
      "epoch 677(3.77)/1200(2648.15) - gen_loss = 3.58892, disc_loss = 0.12262, estimated to finish: 2045.76\n",
      "epoch 678(3.74)/1200(2651.88) - gen_loss = 3.59305, disc_loss = 0.11806, estimated to finish: 2041.72\n",
      "epoch 679(3.77)/1200(2655.66) - gen_loss = 3.65032, disc_loss = 0.1199, estimated to finish: 2037.7\n",
      "epoch 680(3.74)/1200(2659.4) - gen_loss = 3.72212, disc_loss = 0.11457, estimated to finish: 2033.66\n",
      "epoch 681(3.85)/1200(2663.25) - gen_loss = 3.78858, disc_loss = 0.11866, estimated to finish: 2029.7\n",
      "epoch 682(3.8)/1200(2667.05) - gen_loss = 3.77884, disc_loss = 0.11402, estimated to finish: 2025.7\n",
      "epoch 683(3.81)/1200(2670.86) - gen_loss = 3.82294, disc_loss = 0.11149, estimated to finish: 2021.72\n",
      "epoch 684(3.77)/1200(2674.63) - gen_loss = 3.95549, disc_loss = 0.12357, estimated to finish: 2017.7\n",
      "epoch 685(3.74)/1200(2678.36) - gen_loss = 2.7618, disc_loss = 1.63446, estimated to finish: 2013.66\n",
      "epoch 686(3.82)/1200(2682.19) - gen_loss = 0.78563, disc_loss = 1.20271, estimated to finish: 2009.69\n",
      "epoch 687(4.24)/1200(2686.43) - gen_loss = 1.31582, disc_loss = 0.50166, estimated to finish: 2006.02\n",
      "epoch 688(4.39)/1200(2690.81) - gen_loss = 1.5506, disc_loss = 0.41106, estimated to finish: 2002.47\n",
      "epoch 689(4.36)/1200(2695.18) - gen_loss = 2.16506, disc_loss = 0.32989, estimated to finish: 1998.89\n",
      "epoch 690(3.99)/1200(2699.16) - gen_loss = 1.9653, disc_loss = 0.31474, estimated to finish: 1995.03\n",
      "epoch 691(3.79)/1200(2702.95) - gen_loss = 2.0824, disc_loss = 0.2996, estimated to finish: 1991.03\n",
      "epoch 692(3.75)/1200(2706.7) - gen_loss = 3.96714, disc_loss = 0.24131, estimated to finish: 1987.0\n",
      "epoch 693(3.75)/1200(2710.45) - gen_loss = 4.21365, disc_loss = 0.20358, estimated to finish: 1982.97\n",
      "epoch 694(3.76)/1200(2714.21) - gen_loss = 4.27259, disc_loss = 0.19298, estimated to finish: 1978.95\n",
      "epoch 695(3.82)/1200(2718.03) - gen_loss = 4.74421, disc_loss = 0.17441, estimated to finish: 1974.97\n",
      "epoch 696(3.78)/1200(2721.81) - gen_loss = 4.48938, disc_loss = 0.16863, estimated to finish: 1970.97\n",
      "epoch 697(3.78)/1200(2725.59) - gen_loss = 4.35852, disc_loss = 0.149, estimated to finish: 1966.96\n",
      "epoch 698(3.79)/1200(2729.38) - gen_loss = 4.69291, disc_loss = 0.14153, estimated to finish: 1962.96\n",
      "epoch 699(3.75)/1200(2733.13) - gen_loss = 4.57068, disc_loss = 0.14322, estimated to finish: 1958.94\n",
      "epoch 700(3.76)/1200(2736.89) - gen_loss = 4.18642, disc_loss = 0.14432, estimated to finish: 1954.92\n",
      "epoch 701(3.76)/1200(2740.65) - gen_loss = 4.48872, disc_loss = 0.13291, estimated to finish: 1950.91\n",
      "epoch 702(3.74)/1200(2744.4) - gen_loss = 4.59681, disc_loss = 0.12763, estimated to finish: 1946.88\n",
      "epoch 703(3.83)/1200(2748.23) - gen_loss = 4.48568, disc_loss = 0.12468, estimated to finish: 1942.92\n",
      "epoch 704(3.8)/1200(2752.03) - gen_loss = 4.60836, disc_loss = 0.11789, estimated to finish: 1938.93\n",
      "epoch 705(3.78)/1200(2755.82) - gen_loss = 4.52514, disc_loss = 0.12421, estimated to finish: 1934.94\n",
      "epoch 706(3.73)/1200(2759.54) - gen_loss = 4.4008, disc_loss = 0.12257, estimated to finish: 1930.9\n",
      "epoch 707(3.77)/1200(2763.31) - gen_loss = 4.44835, disc_loss = 0.11971, estimated to finish: 1926.89\n",
      "epoch 708(3.75)/1200(2767.07) - gen_loss = 4.49549, disc_loss = 0.11394, estimated to finish: 1922.88\n",
      "epoch 709(3.74)/1200(2770.8) - gen_loss = 4.43943, disc_loss = 0.11745, estimated to finish: 1918.85\n",
      "epoch 710(3.79)/1200(2774.59) - gen_loss = 4.43729, disc_loss = 0.10911, estimated to finish: 1914.86\n",
      "epoch 711(3.84)/1200(2778.43) - gen_loss = 4.48792, disc_loss = 0.10902, estimated to finish: 1910.9\n",
      "epoch 712(3.82)/1200(2782.25) - gen_loss = 4.46345, disc_loss = 0.10701, estimated to finish: 1906.94\n",
      "epoch 713(3.86)/1200(2786.11) - gen_loss = 4.45788, disc_loss = 0.10746, estimated to finish: 1903.0\n",
      "epoch 714(3.77)/1200(2789.88) - gen_loss = 4.44341, disc_loss = 0.10541, estimated to finish: 1899.0\n",
      "epoch 715(3.76)/1200(2793.64) - gen_loss = 4.41711, disc_loss = 0.10412, estimated to finish: 1894.99\n",
      "epoch 716(3.8)/1200(2797.44) - gen_loss = 4.50885, disc_loss = 0.09729, estimated to finish: 1891.01\n",
      "epoch 717(3.77)/1200(2801.21) - gen_loss = 4.47866, disc_loss = 0.10551, estimated to finish: 1887.01\n",
      "epoch 718(3.75)/1200(2804.96) - gen_loss = 4.40961, disc_loss = 0.10432, estimated to finish: 1883.0\n",
      "epoch 719(3.78)/1200(2808.74) - gen_loss = 4.44451, disc_loss = 0.0966, estimated to finish: 1879.01\n",
      "epoch 720(3.77)/1200(2812.52) - gen_loss = 4.50362, disc_loss = 0.10037, estimated to finish: 1875.01\n",
      "epoch 721(3.78)/1200(2816.3) - gen_loss = 4.45291, disc_loss = 0.09923, estimated to finish: 1871.02\n",
      "epoch 722(3.81)/1200(2820.11) - gen_loss = 4.50035, disc_loss = 0.09516, estimated to finish: 1867.05\n",
      "epoch 723(3.79)/1200(2823.9) - gen_loss = 4.54143, disc_loss = 0.09046, estimated to finish: 1863.07\n",
      "epoch 724(3.79)/1200(2827.69) - gen_loss = 4.51329, disc_loss = 0.09171, estimated to finish: 1859.09\n",
      "epoch 725(3.8)/1200(2831.49) - gen_loss = 4.53, disc_loss = 0.08959, estimated to finish: 1855.11\n",
      "epoch 726(3.87)/1200(2835.36) - gen_loss = 4.55349, disc_loss = 0.09055, estimated to finish: 1851.19\n",
      "epoch 727(3.77)/1200(2839.13) - gen_loss = 4.55721, disc_loss = 0.08769, estimated to finish: 1847.19\n",
      "epoch 728(3.82)/1200(2842.95) - gen_loss = 4.59689, disc_loss = 0.08859, estimated to finish: 1843.23\n",
      "epoch 729(3.75)/1200(2846.7) - gen_loss = 4.61278, disc_loss = 0.08884, estimated to finish: 1839.23\n",
      "epoch 730(3.8)/1200(2850.5) - gen_loss = 4.56202, disc_loss = 0.08779, estimated to finish: 1835.25\n",
      "epoch 731(3.77)/1200(2854.27) - gen_loss = 4.60299, disc_loss = 0.08027, estimated to finish: 1831.26\n",
      "epoch 732(3.75)/1200(2858.03) - gen_loss = 4.63642, disc_loss = 0.087, estimated to finish: 1827.26\n",
      "epoch 733(3.78)/1200(2861.8) - gen_loss = 4.62252, disc_loss = 0.08714, estimated to finish: 1823.28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 734(3.76)/1200(2865.57) - gen_loss = 4.62097, disc_loss = 0.08604, estimated to finish: 1819.28\n",
      "epoch 735(3.77)/1200(2869.34) - gen_loss = 4.60665, disc_loss = 0.08045, estimated to finish: 1815.29\n",
      "epoch 736(3.74)/1200(2873.08) - gen_loss = 4.67745, disc_loss = 0.08304, estimated to finish: 1811.29\n",
      "epoch 737(3.82)/1200(2876.9) - gen_loss = 4.67971, disc_loss = 0.07864, estimated to finish: 1807.33\n",
      "epoch 738(3.75)/1200(2880.64) - gen_loss = 4.67494, disc_loss = 0.08679, estimated to finish: 1803.33\n",
      "epoch 739(3.76)/1200(2884.41) - gen_loss = 4.69508, disc_loss = 0.08198, estimated to finish: 1799.34\n",
      "epoch 740(3.76)/1200(2888.17) - gen_loss = 4.69894, disc_loss = 0.08822, estimated to finish: 1795.35\n",
      "epoch 741(3.81)/1200(2891.98) - gen_loss = 4.71499, disc_loss = 0.08834, estimated to finish: 1791.39\n",
      "epoch 742(3.77)/1200(2895.75) - gen_loss = 4.59251, disc_loss = 0.11863, estimated to finish: 1787.4\n",
      "epoch 743(3.79)/1200(2899.54) - gen_loss = 3.17465, disc_loss = 0.84417, estimated to finish: 1783.43\n",
      "epoch 744(3.79)/1200(2903.33) - gen_loss = 2.29698, disc_loss = 0.28332, estimated to finish: 1779.46\n",
      "epoch 745(3.76)/1200(2907.09) - gen_loss = 2.54613, disc_loss = 0.2286, estimated to finish: 1775.47\n",
      "epoch 746(3.72)/1200(2910.81) - gen_loss = 2.7196, disc_loss = 0.20667, estimated to finish: 1771.46\n",
      "epoch 747(3.75)/1200(2914.56) - gen_loss = 2.89516, disc_loss = 0.18787, estimated to finish: 1767.47\n",
      "epoch 748(3.79)/1200(2918.35) - gen_loss = 2.99909, disc_loss = 0.18454, estimated to finish: 1763.5\n",
      "epoch 749(3.81)/1200(2922.16) - gen_loss = 3.09077, disc_loss = 0.17675, estimated to finish: 1759.54\n",
      "epoch 750(3.73)/1200(2925.89) - gen_loss = 3.18171, disc_loss = 0.17887, estimated to finish: 1755.53\n",
      "epoch 751(3.77)/1200(2929.65) - gen_loss = 3.26486, disc_loss = 0.19921, estimated to finish: 1751.55\n",
      "epoch 752(3.78)/1200(2933.43) - gen_loss = 3.44549, disc_loss = 0.20508, estimated to finish: 1747.58\n",
      "epoch 753(3.74)/1200(2937.17) - gen_loss = 3.55623, disc_loss = 0.18352, estimated to finish: 1743.58\n",
      "epoch 754(3.76)/1200(2940.93) - gen_loss = 3.57846, disc_loss = 0.1735, estimated to finish: 1739.6\n",
      "epoch 755(3.82)/1200(2944.75) - gen_loss = 3.682, disc_loss = 0.18784, estimated to finish: 1735.65\n",
      "epoch 756(3.77)/1200(2948.52) - gen_loss = 3.66375, disc_loss = 0.20493, estimated to finish: 1731.67\n",
      "epoch 757(3.72)/1200(2952.24) - gen_loss = 3.69144, disc_loss = 0.19902, estimated to finish: 1727.67\n",
      "epoch 758(3.82)/1200(2956.06) - gen_loss = 3.97332, disc_loss = 0.18117, estimated to finish: 1723.72\n",
      "epoch 759(3.75)/1200(2959.81) - gen_loss = 3.84564, disc_loss = 0.16566, estimated to finish: 1719.73\n",
      "epoch 760(3.8)/1200(2963.61) - gen_loss = 4.25055, disc_loss = 0.20585, estimated to finish: 1715.77\n",
      "epoch 761(3.78)/1200(2967.39) - gen_loss = 3.43645, disc_loss = 0.70167, estimated to finish: 1711.81\n",
      "epoch 762(3.76)/1200(2971.15) - gen_loss = 2.8621, disc_loss = 0.24839, estimated to finish: 1707.83\n",
      "epoch 763(3.76)/1200(2974.92) - gen_loss = 3.19073, disc_loss = 0.25069, estimated to finish: 1703.85\n",
      "epoch 764(3.74)/1200(2978.65) - gen_loss = 3.09819, disc_loss = 0.31799, estimated to finish: 1699.86\n",
      "epoch 765(3.78)/1200(2982.43) - gen_loss = 3.37785, disc_loss = 0.31179, estimated to finish: 1695.89\n",
      "epoch 766(3.84)/1200(2986.27) - gen_loss = 3.46994, disc_loss = 0.35914, estimated to finish: 1691.96\n",
      "epoch 767(4.15)/1200(2990.42) - gen_loss = 2.71405, disc_loss = 0.69976, estimated to finish: 1688.21\n",
      "epoch 768(4.0)/1200(2994.43) - gen_loss = 1.83019, disc_loss = 1.51195, estimated to finish: 1684.37\n",
      "epoch 769(3.79)/1200(2998.22) - gen_loss = 2.7294, disc_loss = 1.32536, estimated to finish: 1680.41\n",
      "epoch 770(3.69)/1200(3001.91) - gen_loss = 2.30741, disc_loss = 0.47437, estimated to finish: 1676.39\n",
      "epoch 771(3.77)/1200(3005.67) - gen_loss = 3.78005, disc_loss = 0.2764, estimated to finish: 1672.42\n",
      "epoch 772(3.77)/1200(3009.44) - gen_loss = 2.82922, disc_loss = 0.72167, estimated to finish: 1668.45\n",
      "epoch 773(3.75)/1200(3013.19) - gen_loss = 2.88084, disc_loss = 0.46288, estimated to finish: 1664.46\n",
      "epoch 774(3.76)/1200(3016.94) - gen_loss = 2.86897, disc_loss = 0.38059, estimated to finish: 1660.49\n",
      "epoch 775(3.77)/1200(3020.72) - gen_loss = 2.90043, disc_loss = 0.33633, estimated to finish: 1656.52\n",
      "epoch 776(3.78)/1200(3024.49) - gen_loss = 3.08661, disc_loss = 0.26609, estimated to finish: 1652.56\n",
      "epoch 777(3.78)/1200(3028.27) - gen_loss = 3.13893, disc_loss = 0.34144, estimated to finish: 1648.6\n",
      "epoch 778(3.76)/1200(3032.03) - gen_loss = 2.75915, disc_loss = 1.21972, estimated to finish: 1644.62\n",
      "epoch 779(3.78)/1200(3035.81) - gen_loss = 4.86817, disc_loss = 0.31317, estimated to finish: 1640.66\n",
      "epoch 780(3.78)/1200(3039.59) - gen_loss = 4.48193, disc_loss = 0.26244, estimated to finish: 1636.7\n",
      "epoch 781(3.75)/1200(3043.33) - gen_loss = 3.15686, disc_loss = 0.21405, estimated to finish: 1632.72\n",
      "epoch 782(3.8)/1200(3047.14) - gen_loss = 2.98743, disc_loss = 0.21307, estimated to finish: 1628.78\n",
      "epoch 783(3.69)/1200(3050.83) - gen_loss = 2.87699, disc_loss = 0.19219, estimated to finish: 1624.77\n",
      "epoch 784(3.78)/1200(3054.62) - gen_loss = 2.91418, disc_loss = 0.17993, estimated to finish: 1620.82\n",
      "epoch 785(3.73)/1200(3058.35) - gen_loss = 2.93652, disc_loss = 0.1939, estimated to finish: 1616.83\n",
      "epoch 786(3.74)/1200(3062.09) - gen_loss = 2.86934, disc_loss = 0.21463, estimated to finish: 1612.86\n",
      "epoch 787(3.76)/1200(3065.84) - gen_loss = 2.91661, disc_loss = 0.2116, estimated to finish: 1608.89\n",
      "epoch 788(3.77)/1200(3069.62) - gen_loss = 3.04947, disc_loss = 0.21629, estimated to finish: 1604.93\n",
      "epoch 789(3.76)/1200(3073.38) - gen_loss = 3.09145, disc_loss = 0.23152, estimated to finish: 1600.96\n",
      "epoch 790(3.79)/1200(3077.17) - gen_loss = 3.10996, disc_loss = 0.22804, estimated to finish: 1597.01\n",
      "epoch 791(3.78)/1200(3080.95) - gen_loss = 3.28588, disc_loss = 0.20529, estimated to finish: 1593.06\n",
      "epoch 792(3.77)/1200(3084.72) - gen_loss = 3.27552, disc_loss = 0.21084, estimated to finish: 1589.1\n",
      "epoch 793(3.8)/1200(3088.53) - gen_loss = 3.14075, disc_loss = 0.25077, estimated to finish: 1585.16\n",
      "epoch 794(3.8)/1200(3092.33) - gen_loss = 3.34998, disc_loss = 0.22129, estimated to finish: 1581.22\n",
      "epoch 795(3.76)/1200(3096.08) - gen_loss = 3.34505, disc_loss = 0.22673, estimated to finish: 1577.25\n",
      "epoch 796(3.76)/1200(3099.84) - gen_loss = 3.35363, disc_loss = 0.22303, estimated to finish: 1573.29\n",
      "epoch 797(3.75)/1200(3103.59) - gen_loss = 3.4774, disc_loss = 0.21861, estimated to finish: 1569.32\n",
      "epoch 798(3.79)/1200(3107.38) - gen_loss = 3.56106, disc_loss = 0.2139, estimated to finish: 1565.37\n",
      "epoch 799(3.81)/1200(3111.19) - gen_loss = 3.44975, disc_loss = 0.2311, estimated to finish: 1561.43\n",
      "epoch 800(3.77)/1200(3114.96) - gen_loss = 3.55844, disc_loss = 0.22878, estimated to finish: 1557.48\n",
      "epoch 801(3.83)/1200(3118.79) - gen_loss = 3.68765, disc_loss = 0.21253, estimated to finish: 1553.55\n",
      "epoch 802(3.79)/1200(3122.58) - gen_loss = 3.64644, disc_loss = 0.22768, estimated to finish: 1549.61\n",
      "epoch 803(3.75)/1200(3126.33) - gen_loss = 3.62831, disc_loss = 0.22698, estimated to finish: 1545.65\n",
      "epoch 804(3.78)/1200(3130.11) - gen_loss = 3.72615, disc_loss = 0.22474, estimated to finish: 1541.7\n",
      "epoch 805(3.82)/1200(3133.93) - gen_loss = 3.70926, disc_loss = 0.21424, estimated to finish: 1537.77\n",
      "epoch 806(3.79)/1200(3137.71) - gen_loss = 3.89149, disc_loss = 0.19918, estimated to finish: 1533.82\n",
      "epoch 807(3.74)/1200(3141.45) - gen_loss = 3.77795, disc_loss = 0.20131, estimated to finish: 1529.85\n",
      "epoch 808(3.77)/1200(3145.22) - gen_loss = 3.79372, disc_loss = 0.21405, estimated to finish: 1525.9\n",
      "epoch 809(3.77)/1200(3148.98) - gen_loss = 3.78241, disc_loss = 0.21823, estimated to finish: 1521.94\n",
      "epoch 810(3.76)/1200(3152.74) - gen_loss = 3.89551, disc_loss = 0.20863, estimated to finish: 1517.99\n",
      "epoch 811(3.78)/1200(3156.52) - gen_loss = 3.92768, disc_loss = 0.21048, estimated to finish: 1514.04\n",
      "epoch 812(3.77)/1200(3160.29) - gen_loss = 4.0163, disc_loss = 0.19395, estimated to finish: 1510.09\n",
      "epoch 813(3.75)/1200(3164.04) - gen_loss = 3.98848, disc_loss = 0.21709, estimated to finish: 1506.13\n",
      "epoch 814(3.81)/1200(3167.85) - gen_loss = 4.07536, disc_loss = 0.19722, estimated to finish: 1502.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 815(3.81)/1200(3171.66) - gen_loss = 4.06379, disc_loss = 0.19641, estimated to finish: 1498.27\n",
      "epoch 816(3.78)/1200(3175.44) - gen_loss = 4.06788, disc_loss = 0.2057, estimated to finish: 1494.33\n",
      "epoch 817(3.81)/1200(3179.25) - gen_loss = 4.12733, disc_loss = 0.20865, estimated to finish: 1490.4\n",
      "epoch 818(3.78)/1200(3183.03) - gen_loss = 4.1087, disc_loss = 0.20261, estimated to finish: 1486.45\n",
      "epoch 819(3.8)/1200(3186.83) - gen_loss = 4.19053, disc_loss = 0.18709, estimated to finish: 1482.52\n",
      "epoch 820(3.81)/1200(3190.65) - gen_loss = 4.23734, disc_loss = 0.18094, estimated to finish: 1478.59\n",
      "epoch 821(3.79)/1200(3194.44) - gen_loss = 4.27457, disc_loss = 0.17927, estimated to finish: 1474.65\n",
      "epoch 822(4.08)/1200(3198.52) - gen_loss = 4.22772, disc_loss = 0.19216, estimated to finish: 1470.85\n",
      "epoch 823(4.2)/1200(3202.72) - gen_loss = 4.31696, disc_loss = 0.18629, estimated to finish: 1467.1\n",
      "epoch 824(4.52)/1200(3207.24) - gen_loss = 4.33709, disc_loss = 0.17508, estimated to finish: 1463.5\n",
      "epoch 825(3.8)/1200(3211.04) - gen_loss = 4.30837, disc_loss = 0.18482, estimated to finish: 1459.56\n",
      "epoch 826(3.71)/1200(3214.75) - gen_loss = 4.37687, disc_loss = 0.17005, estimated to finish: 1455.59\n",
      "epoch 827(3.77)/1200(3218.52) - gen_loss = 4.42629, disc_loss = 0.17355, estimated to finish: 1451.64\n",
      "epoch 828(3.78)/1200(3222.3) - gen_loss = 4.44473, disc_loss = 0.183, estimated to finish: 1447.7\n",
      "epoch 829(3.76)/1200(3226.06) - gen_loss = 4.50262, disc_loss = 0.17192, estimated to finish: 1443.75\n",
      "epoch 830(3.82)/1200(3229.88) - gen_loss = 4.39621, disc_loss = 0.19353, estimated to finish: 1439.83\n",
      "epoch 831(3.95)/1200(3233.83) - gen_loss = 5.10332, disc_loss = 0.17491, estimated to finish: 1435.96\n",
      "epoch 832(3.76)/1200(3237.59) - gen_loss = 3.99942, disc_loss = 0.15523, estimated to finish: 1432.01\n",
      "epoch 833(3.74)/1200(3241.33) - gen_loss = 3.89444, disc_loss = 0.15452, estimated to finish: 1428.05\n",
      "epoch 834(3.74)/1200(3245.07) - gen_loss = 4.05411, disc_loss = 0.15058, estimated to finish: 1424.1\n",
      "epoch 835(3.81)/1200(3248.88) - gen_loss = 4.20943, disc_loss = 0.1333, estimated to finish: 1420.17\n",
      "epoch 836(3.83)/1200(3252.71) - gen_loss = 4.35471, disc_loss = 0.12215, estimated to finish: 1416.25\n",
      "epoch 837(3.74)/1200(3256.45) - gen_loss = 4.41327, disc_loss = 0.12057, estimated to finish: 1412.3\n",
      "epoch 838(3.78)/1200(3260.24) - gen_loss = 4.51191, disc_loss = 0.1125, estimated to finish: 1408.36\n",
      "epoch 839(3.79)/1200(3264.03) - gen_loss = 4.61267, disc_loss = 0.10738, estimated to finish: 1404.43\n",
      "epoch 840(3.82)/1200(3267.85) - gen_loss = 4.73294, disc_loss = 0.10389, estimated to finish: 1400.51\n",
      "epoch 841(3.89)/1200(3271.74) - gen_loss = 4.76943, disc_loss = 0.09967, estimated to finish: 1396.62\n",
      "epoch 842(3.77)/1200(3275.51) - gen_loss = 4.7974, disc_loss = 0.09757, estimated to finish: 1392.67\n",
      "epoch 843(3.78)/1200(3279.29) - gen_loss = 4.89429, disc_loss = 0.09567, estimated to finish: 1388.74\n",
      "epoch 844(3.8)/1200(3283.09) - gen_loss = 4.89914, disc_loss = 0.09283, estimated to finish: 1384.81\n",
      "epoch 845(3.76)/1200(3286.84) - gen_loss = 4.95574, disc_loss = 0.09229, estimated to finish: 1380.86\n",
      "epoch 846(3.8)/1200(3290.64) - gen_loss = 4.99898, disc_loss = 0.09261, estimated to finish: 1376.94\n",
      "epoch 847(3.8)/1200(3294.44) - gen_loss = 5.05257, disc_loss = 0.08874, estimated to finish: 1373.01\n",
      "epoch 848(3.79)/1200(3298.23) - gen_loss = 5.06272, disc_loss = 0.08986, estimated to finish: 1369.08\n",
      "epoch 849(3.76)/1200(3301.99) - gen_loss = 5.12912, disc_loss = 0.0829, estimated to finish: 1365.14\n",
      "epoch 850(3.74)/1200(3305.74) - gen_loss = 5.18129, disc_loss = 0.08511, estimated to finish: 1361.19\n",
      "epoch 851(3.87)/1200(3309.61) - gen_loss = 5.19008, disc_loss = 0.08175, estimated to finish: 1357.29\n",
      "epoch 852(3.75)/1200(3313.36) - gen_loss = 5.21766, disc_loss = 0.0824, estimated to finish: 1353.34\n",
      "epoch 853(3.78)/1200(3317.14) - gen_loss = 5.256, disc_loss = 0.07846, estimated to finish: 1349.41\n",
      "epoch 854(3.77)/1200(3320.91) - gen_loss = 5.3107, disc_loss = 0.08165, estimated to finish: 1345.47\n",
      "epoch 855(3.74)/1200(3324.65) - gen_loss = 5.27769, disc_loss = 0.08237, estimated to finish: 1341.52\n",
      "epoch 856(3.76)/1200(3328.41) - gen_loss = 5.30493, disc_loss = 0.07991, estimated to finish: 1337.59\n",
      "epoch 857(3.79)/1200(3332.2) - gen_loss = 5.31251, disc_loss = 0.07878, estimated to finish: 1333.66\n",
      "epoch 858(3.74)/1200(3335.95) - gen_loss = 5.35565, disc_loss = 0.07972, estimated to finish: 1329.71\n",
      "epoch 859(3.8)/1200(3339.75) - gen_loss = 5.36749, disc_loss = 0.07774, estimated to finish: 1325.79\n",
      "epoch 860(3.79)/1200(3343.54) - gen_loss = 5.396, disc_loss = 0.07651, estimated to finish: 1321.87\n",
      "epoch 861(3.92)/1200(3347.46) - gen_loss = 5.41172, disc_loss = 0.07913, estimated to finish: 1317.99\n",
      "epoch 862(3.77)/1200(3351.22) - gen_loss = 5.41997, disc_loss = 0.0777, estimated to finish: 1314.05\n",
      "epoch 863(3.83)/1200(3355.05) - gen_loss = 5.4432, disc_loss = 0.07827, estimated to finish: 1310.14\n",
      "epoch 864(3.78)/1200(3358.83) - gen_loss = 5.47409, disc_loss = 0.0751, estimated to finish: 1306.21\n",
      "epoch 865(3.77)/1200(3362.6) - gen_loss = 5.49158, disc_loss = 0.07914, estimated to finish: 1302.28\n",
      "epoch 866(3.8)/1200(3366.4) - gen_loss = 5.49182, disc_loss = 0.08247, estimated to finish: 1298.36\n",
      "epoch 867(4.16)/1200(3370.56) - gen_loss = 5.47796, disc_loss = 0.07914, estimated to finish: 1294.57\n",
      "epoch 868(4.31)/1200(3374.86) - gen_loss = 5.49581, disc_loss = 0.08432, estimated to finish: 1290.85\n",
      "epoch 869(3.9)/1200(3378.77) - gen_loss = 5.51509, disc_loss = 0.07575, estimated to finish: 1286.96\n",
      "epoch 870(3.8)/1200(3382.57) - gen_loss = 5.54176, disc_loss = 0.07871, estimated to finish: 1283.04\n",
      "epoch 871(4.0)/1200(3386.57) - gen_loss = 5.53381, disc_loss = 0.08744, estimated to finish: 1279.2\n",
      "epoch 872(3.98)/1200(3390.55) - gen_loss = 5.56548, disc_loss = 0.08531, estimated to finish: 1275.35\n",
      "epoch 873(3.78)/1200(3394.33) - gen_loss = 5.56343, disc_loss = 0.0959, estimated to finish: 1271.42\n",
      "epoch 874(3.8)/1200(3398.13) - gen_loss = 5.28016, disc_loss = 0.27213, estimated to finish: 1267.49\n",
      "epoch 875(3.79)/1200(3401.92) - gen_loss = 4.67473, disc_loss = 0.61409, estimated to finish: 1263.57\n",
      "epoch 876(3.78)/1200(3405.69) - gen_loss = 4.90671, disc_loss = 0.24282, estimated to finish: 1259.64\n",
      "epoch 877(3.77)/1200(3409.46) - gen_loss = 4.71374, disc_loss = 0.77013, estimated to finish: 1255.71\n",
      "epoch 878(3.84)/1200(3413.3) - gen_loss = 4.58084, disc_loss = 0.89118, estimated to finish: 1251.8\n",
      "epoch 879(3.75)/1200(3417.05) - gen_loss = 5.22886, disc_loss = 0.27506, estimated to finish: 1247.86\n",
      "epoch 880(3.77)/1200(3420.82) - gen_loss = 5.34752, disc_loss = 0.23536, estimated to finish: 1243.93\n",
      "epoch 881(3.79)/1200(3424.6) - gen_loss = 5.28313, disc_loss = 0.21829, estimated to finish: 1240.01\n",
      "epoch 882(3.77)/1200(3428.37) - gen_loss = 4.93337, disc_loss = 0.29196, estimated to finish: 1236.08\n",
      "epoch 883(3.83)/1200(3432.2) - gen_loss = 5.24694, disc_loss = 0.21841, estimated to finish: 1232.17\n",
      "epoch 884(3.8)/1200(3436.0) - gen_loss = 5.25718, disc_loss = 0.25217, estimated to finish: 1228.25\n",
      "epoch 885(3.77)/1200(3439.77) - gen_loss = 4.96102, disc_loss = 0.21002, estimated to finish: 1224.33\n",
      "epoch 886(3.8)/1200(3443.58) - gen_loss = 5.01457, disc_loss = 0.22635, estimated to finish: 1220.41\n",
      "epoch 887(3.79)/1200(3447.37) - gen_loss = 4.99336, disc_loss = 0.24228, estimated to finish: 1216.49\n",
      "epoch 888(3.78)/1200(3451.15) - gen_loss = 5.05656, disc_loss = 0.23471, estimated to finish: 1212.57\n",
      "epoch 889(3.8)/1200(3454.94) - gen_loss = 4.93884, disc_loss = 0.26197, estimated to finish: 1208.65\n",
      "epoch 890(3.77)/1200(3458.71) - gen_loss = 4.07393, disc_loss = 0.33497, estimated to finish: 1204.72\n",
      "epoch 891(3.81)/1200(3462.52) - gen_loss = 4.46006, disc_loss = 0.37143, estimated to finish: 1200.81\n",
      "epoch 892(3.79)/1200(3466.31) - gen_loss = 4.63079, disc_loss = 0.31072, estimated to finish: 1196.89\n",
      "epoch 893(3.83)/1200(3470.13) - gen_loss = 4.67676, disc_loss = 0.32194, estimated to finish: 1192.98\n",
      "epoch 894(3.76)/1200(3473.89) - gen_loss = 4.82989, disc_loss = 0.27623, estimated to finish: 1189.05\n",
      "epoch 895(3.79)/1200(3477.68) - gen_loss = 4.50811, disc_loss = 0.28658, estimated to finish: 1185.13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 896(3.76)/1200(3481.44) - gen_loss = 4.74321, disc_loss = 0.29253, estimated to finish: 1181.2\n",
      "epoch 897(3.81)/1200(3485.25) - gen_loss = 4.63429, disc_loss = 0.36773, estimated to finish: 1177.29\n",
      "epoch 898(3.83)/1200(3489.08) - gen_loss = 4.29864, disc_loss = 0.29219, estimated to finish: 1173.39\n",
      "epoch 899(3.8)/1200(3492.88) - gen_loss = 4.78478, disc_loss = 0.29372, estimated to finish: 1169.47\n",
      "epoch 900(3.86)/1200(3496.74) - gen_loss = 4.65717, disc_loss = 0.28921, estimated to finish: 1165.58\n",
      "epoch 901(3.77)/1200(3500.51) - gen_loss = 4.55785, disc_loss = 0.31096, estimated to finish: 1161.66\n",
      "epoch 902(3.82)/1200(3504.33) - gen_loss = 4.67681, disc_loss = 0.28881, estimated to finish: 1157.75\n",
      "epoch 903(3.77)/1200(3508.11) - gen_loss = 4.61426, disc_loss = 0.33636, estimated to finish: 1153.83\n",
      "epoch 904(3.8)/1200(3511.9) - gen_loss = 4.65084, disc_loss = 0.34209, estimated to finish: 1149.92\n",
      "epoch 905(3.8)/1200(3515.71) - gen_loss = 4.64547, disc_loss = 0.36226, estimated to finish: 1146.0\n",
      "epoch 906(3.79)/1200(3519.5) - gen_loss = 4.65256, disc_loss = 0.29918, estimated to finish: 1142.09\n",
      "epoch 907(3.83)/1200(3523.33) - gen_loss = 4.53684, disc_loss = 0.28538, estimated to finish: 1138.19\n",
      "epoch 908(3.81)/1200(3527.14) - gen_loss = 4.53077, disc_loss = 0.30351, estimated to finish: 1134.28\n",
      "epoch 909(3.79)/1200(3530.93) - gen_loss = 4.67928, disc_loss = 0.29679, estimated to finish: 1130.36\n",
      "epoch 910(3.77)/1200(3534.7) - gen_loss = 4.6969, disc_loss = 0.28087, estimated to finish: 1126.44\n",
      "epoch 911(3.83)/1200(3538.53) - gen_loss = 4.73391, disc_loss = 0.27549, estimated to finish: 1122.54\n",
      "epoch 912(3.79)/1200(3542.32) - gen_loss = 4.7577, disc_loss = 0.3101, estimated to finish: 1118.63\n",
      "epoch 913(3.75)/1200(3546.07) - gen_loss = 3.07587, disc_loss = 0.42015, estimated to finish: 1114.7\n",
      "epoch 914(3.78)/1200(3549.85) - gen_loss = 3.75802, disc_loss = 0.36398, estimated to finish: 1110.79\n",
      "epoch 915(3.77)/1200(3553.62) - gen_loss = 4.96266, disc_loss = 0.24109, estimated to finish: 1106.87\n",
      "epoch 916(3.81)/1200(3557.43) - gen_loss = 4.88065, disc_loss = 0.28177, estimated to finish: 1102.96\n",
      "epoch 917(3.82)/1200(3561.25) - gen_loss = 4.79719, disc_loss = 0.27973, estimated to finish: 1099.05\n",
      "epoch 918(3.78)/1200(3565.03) - gen_loss = 4.75736, disc_loss = 0.30015, estimated to finish: 1095.14\n",
      "epoch 919(3.79)/1200(3568.82) - gen_loss = 4.67602, disc_loss = 0.2951, estimated to finish: 1091.23\n",
      "epoch 920(3.77)/1200(3572.59) - gen_loss = 4.75993, disc_loss = 0.27573, estimated to finish: 1087.31\n",
      "epoch 921(3.79)/1200(3576.38) - gen_loss = 4.86968, disc_loss = 0.26226, estimated to finish: 1083.4\n",
      "epoch 922(3.78)/1200(3580.16) - gen_loss = 4.98763, disc_loss = 0.25961, estimated to finish: 1079.48\n",
      "epoch 923(3.79)/1200(3583.95) - gen_loss = 4.98183, disc_loss = 0.25185, estimated to finish: 1075.57\n",
      "epoch 924(3.77)/1200(3587.71) - gen_loss = 4.96564, disc_loss = 0.26048, estimated to finish: 1071.65\n",
      "epoch 925(3.8)/1200(3591.51) - gen_loss = 4.90211, disc_loss = 0.26949, estimated to finish: 1067.75\n",
      "epoch 926(3.82)/1200(3595.33) - gen_loss = 5.0175, disc_loss = 0.25667, estimated to finish: 1063.85\n",
      "epoch 927(3.81)/1200(3599.14) - gen_loss = 4.93218, disc_loss = 0.26308, estimated to finish: 1059.94\n",
      "epoch 928(3.85)/1200(3602.99) - gen_loss = 4.95539, disc_loss = 0.26151, estimated to finish: 1056.05\n",
      "epoch 929(3.71)/1200(3606.7) - gen_loss = 5.11004, disc_loss = 0.23977, estimated to finish: 1052.12\n",
      "epoch 930(3.83)/1200(3610.54) - gen_loss = 4.89955, disc_loss = 0.28018, estimated to finish: 1048.22\n",
      "epoch 931(3.84)/1200(3614.37) - gen_loss = 4.90314, disc_loss = 0.26408, estimated to finish: 1044.32\n",
      "epoch 932(3.75)/1200(3618.12) - gen_loss = 5.12051, disc_loss = 0.25785, estimated to finish: 1040.4\n",
      "epoch 933(3.86)/1200(3621.99) - gen_loss = 5.15694, disc_loss = 0.26448, estimated to finish: 1036.52\n",
      "epoch 934(3.95)/1200(3625.94) - gen_loss = 4.73098, disc_loss = 0.25516, estimated to finish: 1032.65\n",
      "epoch 935(3.91)/1200(3629.85) - gen_loss = 4.95048, disc_loss = 0.24633, estimated to finish: 1028.78\n",
      "epoch 936(3.76)/1200(3633.6) - gen_loss = 5.22983, disc_loss = 0.24237, estimated to finish: 1024.86\n",
      "epoch 937(3.83)/1200(3637.44) - gen_loss = 5.10877, disc_loss = 0.23489, estimated to finish: 1020.97\n",
      "epoch 938(3.82)/1200(3641.26) - gen_loss = 5.08284, disc_loss = 0.24636, estimated to finish: 1017.07\n",
      "epoch 939(3.8)/1200(3645.06) - gen_loss = 4.85233, disc_loss = 0.31922, estimated to finish: 1013.16\n",
      "epoch 940(3.8)/1200(3648.86) - gen_loss = 5.09343, disc_loss = 0.24111, estimated to finish: 1009.26\n",
      "epoch 941(3.83)/1200(3652.69) - gen_loss = 5.10584, disc_loss = 0.26834, estimated to finish: 1005.36\n",
      "epoch 942(3.83)/1200(3656.51) - gen_loss = 5.03002, disc_loss = 0.23859, estimated to finish: 1001.47\n",
      "epoch 943(3.81)/1200(3660.32) - gen_loss = 4.98427, disc_loss = 0.24978, estimated to finish: 997.56\n",
      "epoch 944(3.79)/1200(3664.11) - gen_loss = 5.19464, disc_loss = 0.21231, estimated to finish: 993.66\n",
      "epoch 945(3.79)/1200(3667.89) - gen_loss = 5.10568, disc_loss = 0.24744, estimated to finish: 989.75\n",
      "epoch 946(3.83)/1200(3671.73) - gen_loss = 5.15801, disc_loss = 0.26505, estimated to finish: 985.85\n",
      "epoch 947(3.87)/1200(3675.6) - gen_loss = 3.56321, disc_loss = 0.49051, estimated to finish: 981.97\n",
      "epoch 948(3.8)/1200(3679.39) - gen_loss = 3.86498, disc_loss = 0.30192, estimated to finish: 978.07\n",
      "epoch 949(3.79)/1200(3683.18) - gen_loss = 5.22167, disc_loss = 0.23897, estimated to finish: 974.16\n",
      "epoch 950(3.76)/1200(3686.94) - gen_loss = 5.12105, disc_loss = 0.2499, estimated to finish: 970.25\n",
      "epoch 951(3.78)/1200(3690.72) - gen_loss = 5.11909, disc_loss = 0.24717, estimated to finish: 966.34\n",
      "epoch 952(3.79)/1200(3694.51) - gen_loss = 5.08151, disc_loss = 0.2434, estimated to finish: 962.43\n",
      "epoch 953(3.81)/1200(3698.32) - gen_loss = 5.14995, disc_loss = 0.23788, estimated to finish: 958.54\n",
      "epoch 954(3.81)/1200(3702.12) - gen_loss = 5.14721, disc_loss = 0.23283, estimated to finish: 954.64\n",
      "epoch 955(3.83)/1200(3705.95) - gen_loss = 5.31416, disc_loss = 0.20587, estimated to finish: 950.74\n",
      "epoch 956(3.81)/1200(3709.76) - gen_loss = 5.24776, disc_loss = 0.2223, estimated to finish: 946.84\n",
      "epoch 957(3.82)/1200(3713.58) - gen_loss = 5.31576, disc_loss = 0.21388, estimated to finish: 942.95\n",
      "epoch 958(3.8)/1200(3717.38) - gen_loss = 5.23219, disc_loss = 0.22398, estimated to finish: 939.04\n",
      "epoch 959(3.86)/1200(3721.23) - gen_loss = 5.30403, disc_loss = 0.21593, estimated to finish: 935.16\n",
      "epoch 960(3.77)/1200(3725.0) - gen_loss = 5.20843, disc_loss = 0.23997, estimated to finish: 931.25\n",
      "epoch 961(3.8)/1200(3728.8) - gen_loss = 5.22213, disc_loss = 0.21536, estimated to finish: 927.35\n",
      "epoch 962(3.87)/1200(3732.67) - gen_loss = 5.32926, disc_loss = 0.20307, estimated to finish: 923.47\n",
      "epoch 963(3.93)/1200(3736.6) - gen_loss = 5.32233, disc_loss = 0.20621, estimated to finish: 919.6\n",
      "epoch 964(3.81)/1200(3740.41) - gen_loss = 5.31097, disc_loss = 0.22228, estimated to finish: 915.7\n",
      "epoch 965(3.79)/1200(3744.2) - gen_loss = 5.20603, disc_loss = 0.23626, estimated to finish: 911.8\n",
      "epoch 966(3.81)/1200(3748.01) - gen_loss = 4.8603, disc_loss = 0.34604, estimated to finish: 907.9\n",
      "epoch 967(3.82)/1200(3751.83) - gen_loss = 4.95717, disc_loss = 0.25214, estimated to finish: 904.01\n",
      "epoch 968(3.82)/1200(3755.65) - gen_loss = 5.27469, disc_loss = 0.24199, estimated to finish: 900.11\n",
      "epoch 969(3.85)/1200(3759.49) - gen_loss = 5.37066, disc_loss = 0.20198, estimated to finish: 896.23\n",
      "epoch 970(3.83)/1200(3763.32) - gen_loss = 5.39918, disc_loss = 0.21105, estimated to finish: 892.33\n",
      "epoch 971(3.83)/1200(3767.15) - gen_loss = 5.30617, disc_loss = 0.24362, estimated to finish: 888.44\n",
      "epoch 972(3.8)/1200(3770.94) - gen_loss = 5.3923, disc_loss = 0.19647, estimated to finish: 884.54\n",
      "epoch 973(3.79)/1200(3774.74) - gen_loss = 5.40922, disc_loss = 0.21091, estimated to finish: 880.64\n",
      "epoch 974(3.74)/1200(3778.47) - gen_loss = 5.36653, disc_loss = 0.24405, estimated to finish: 876.73\n",
      "epoch 975(3.78)/1200(3782.25) - gen_loss = 5.00543, disc_loss = 0.28386, estimated to finish: 872.83\n",
      "epoch 976(3.76)/1200(3786.01) - gen_loss = 5.24403, disc_loss = 0.20465, estimated to finish: 868.92\n",
      "epoch 977(3.8)/1200(3789.81) - gen_loss = 5.34502, disc_loss = 0.19252, estimated to finish: 865.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 978(3.76)/1200(3793.58) - gen_loss = 5.45828, disc_loss = 0.19194, estimated to finish: 861.12\n",
      "epoch 979(3.77)/1200(3797.35) - gen_loss = 5.44005, disc_loss = 0.27993, estimated to finish: 857.22\n",
      "epoch 980(3.76)/1200(3801.11) - gen_loss = 3.2695, disc_loss = 0.80567, estimated to finish: 853.31\n",
      "epoch 981(3.77)/1200(3804.88) - gen_loss = 3.94835, disc_loss = 0.35512, estimated to finish: 849.41\n",
      "epoch 982(3.77)/1200(3808.66) - gen_loss = 4.61467, disc_loss = 0.24403, estimated to finish: 845.51\n",
      "epoch 983(3.77)/1200(3812.43) - gen_loss = 5.21281, disc_loss = 0.22555, estimated to finish: 841.6\n",
      "epoch 984(3.8)/1200(3816.23) - gen_loss = 5.31827, disc_loss = 0.22488, estimated to finish: 837.71\n",
      "epoch 985(3.78)/1200(3820.01) - gen_loss = 5.40534, disc_loss = 0.22883, estimated to finish: 833.81\n",
      "epoch 986(3.83)/1200(3823.84) - gen_loss = 5.31996, disc_loss = 0.22634, estimated to finish: 829.92\n",
      "epoch 987(3.8)/1200(3827.64) - gen_loss = 5.3143, disc_loss = 0.22605, estimated to finish: 826.03\n",
      "epoch 988(3.77)/1200(3831.42) - gen_loss = 5.38832, disc_loss = 0.18816, estimated to finish: 822.13\n",
      "epoch 989(3.82)/1200(3835.24) - gen_loss = 5.52917, disc_loss = 0.18203, estimated to finish: 818.24\n",
      "epoch 990(3.83)/1200(3839.06) - gen_loss = 5.46464, disc_loss = 0.19177, estimated to finish: 814.35\n",
      "epoch 991(3.77)/1200(3842.84) - gen_loss = 5.51019, disc_loss = 0.20921, estimated to finish: 810.45\n",
      "epoch 992(3.76)/1200(3846.6) - gen_loss = 5.56523, disc_loss = 0.21123, estimated to finish: 806.55\n",
      "epoch 993(3.8)/1200(3850.4) - gen_loss = 5.52579, disc_loss = 0.21758, estimated to finish: 802.65\n",
      "epoch 994(3.83)/1200(3854.23) - gen_loss = 5.49187, disc_loss = 0.21549, estimated to finish: 798.76\n",
      "epoch 995(4.15)/1200(3858.38) - gen_loss = 5.64252, disc_loss = 0.20622, estimated to finish: 794.94\n",
      "epoch 996(3.82)/1200(3862.2) - gen_loss = 5.60766, disc_loss = 0.22508, estimated to finish: 791.05\n",
      "epoch 997(3.82)/1200(3866.02) - gen_loss = 5.26724, disc_loss = 0.33331, estimated to finish: 787.16\n",
      "epoch 998(3.88)/1200(3869.91) - gen_loss = 5.43714, disc_loss = 0.22333, estimated to finish: 783.29\n",
      "epoch 999(3.92)/1200(3873.83) - gen_loss = 5.50407, disc_loss = 0.19067, estimated to finish: 779.42\n",
      "epoch 1000(3.99)/1200(3877.82) - gen_loss = 5.50963, disc_loss = 0.18944, estimated to finish: 775.56\n",
      "epoch 1001(4.04)/1200(3881.86) - gen_loss = 5.60181, disc_loss = 0.21515, estimated to finish: 771.72\n",
      "epoch 1002(4.35)/1200(3886.2) - gen_loss = 5.5432, disc_loss = 0.19603, estimated to finish: 767.93\n",
      "epoch 1003(3.93)/1200(3890.14) - gen_loss = 5.53116, disc_loss = 0.23033, estimated to finish: 764.06\n",
      "epoch 1004(4.03)/1200(3894.16) - gen_loss = 2.17053, disc_loss = 1.11191, estimated to finish: 760.21\n",
      "epoch 1005(4.54)/1200(3898.7) - gen_loss = 2.04986, disc_loss = 0.98668, estimated to finish: 756.46\n",
      "epoch 1006(4.12)/1200(3902.82) - gen_loss = 2.37025, disc_loss = 0.88073, estimated to finish: 752.63\n",
      "epoch 1007(4.66)/1200(3907.48) - gen_loss = 2.25871, disc_loss = 0.81208, estimated to finish: 748.9\n",
      "epoch 1008(4.13)/1200(3911.62) - gen_loss = 1.40965, disc_loss = 1.26701, estimated to finish: 745.07\n",
      "epoch 1009(3.84)/1200(3915.46) - gen_loss = 0.49523, disc_loss = 1.83591, estimated to finish: 741.18\n",
      "epoch 1010(3.84)/1200(3919.3) - gen_loss = 0.41423, disc_loss = 1.83912, estimated to finish: 737.29\n",
      "epoch 1011(3.87)/1200(3923.17) - gen_loss = 0.44614, disc_loss = 1.77715, estimated to finish: 733.41\n",
      "epoch 1012(3.75)/1200(3926.92) - gen_loss = 0.46512, disc_loss = 1.76438, estimated to finish: 729.51\n",
      "epoch 1013(3.82)/1200(3930.74) - gen_loss = 0.48072, disc_loss = 1.73524, estimated to finish: 725.61\n",
      "epoch 1014(3.78)/1200(3934.52) - gen_loss = 0.49988, disc_loss = 1.72253, estimated to finish: 721.72\n",
      "epoch 1015(3.8)/1200(3938.32) - gen_loss = 0.51133, disc_loss = 1.70107, estimated to finish: 717.82\n",
      "epoch 1016(3.78)/1200(3942.1) - gen_loss = 0.52098, disc_loss = 1.68507, estimated to finish: 713.92\n",
      "epoch 1017(3.76)/1200(3945.86) - gen_loss = 0.52799, disc_loss = 1.67265, estimated to finish: 710.02\n",
      "epoch 1018(3.83)/1200(3949.69) - gen_loss = 0.53884, disc_loss = 1.65228, estimated to finish: 706.13\n",
      "epoch 1019(3.84)/1200(3953.53) - gen_loss = 0.5467, disc_loss = 1.6344, estimated to finish: 702.25\n",
      "epoch 1020(3.75)/1200(3957.28) - gen_loss = 0.55382, disc_loss = 1.61908, estimated to finish: 698.34\n",
      "epoch 1021(3.83)/1200(3961.11) - gen_loss = 0.56108, disc_loss = 1.6034, estimated to finish: 694.46\n",
      "epoch 1022(3.75)/1200(3964.86) - gen_loss = 0.56857, disc_loss = 1.59027, estimated to finish: 690.55\n",
      "epoch 1023(3.79)/1200(3968.65) - gen_loss = 0.57782, disc_loss = 1.57303, estimated to finish: 686.66\n",
      "epoch 1024(3.79)/1200(3972.44) - gen_loss = 0.58772, disc_loss = 1.54966, estimated to finish: 682.76\n",
      "epoch 1025(3.81)/1200(3976.24) - gen_loss = 0.59337, disc_loss = 1.539, estimated to finish: 678.87\n",
      "epoch 1026(3.79)/1200(3980.03) - gen_loss = 0.60263, disc_loss = 1.52088, estimated to finish: 674.98\n",
      "epoch 1027(3.81)/1200(3983.84) - gen_loss = 0.61016, disc_loss = 1.50406, estimated to finish: 671.09\n",
      "epoch 1028(3.81)/1200(3987.65) - gen_loss = 0.61707, disc_loss = 1.49085, estimated to finish: 667.19\n",
      "epoch 1029(3.77)/1200(3991.42) - gen_loss = 0.62448, disc_loss = 1.4757, estimated to finish: 663.3\n",
      "epoch 1030(3.82)/1200(3995.25) - gen_loss = 0.63407, disc_loss = 1.45899, estimated to finish: 659.41\n",
      "epoch 1031(3.82)/1200(3999.07) - gen_loss = 0.64108, disc_loss = 1.44378, estimated to finish: 655.52\n",
      "epoch 1032(3.79)/1200(4002.86) - gen_loss = 0.64542, disc_loss = 1.42957, estimated to finish: 651.63\n",
      "epoch 1033(3.79)/1200(4006.65) - gen_loss = 0.65083, disc_loss = 1.41784, estimated to finish: 647.74\n",
      "epoch 1034(3.79)/1200(4010.44) - gen_loss = 0.66327, disc_loss = 1.40367, estimated to finish: 643.84\n",
      "epoch 1035(3.81)/1200(4014.25) - gen_loss = 0.67964, disc_loss = 1.38619, estimated to finish: 639.95\n",
      "epoch 1036(3.77)/1200(4018.02) - gen_loss = 0.6788, disc_loss = 1.38134, estimated to finish: 636.06\n",
      "epoch 1037(3.77)/1200(4021.79) - gen_loss = 0.66405, disc_loss = 1.38431, estimated to finish: 632.16\n",
      "epoch 1038(3.79)/1200(4025.58) - gen_loss = 0.66609, disc_loss = 1.37067, estimated to finish: 628.27\n",
      "epoch 1039(3.8)/1200(4029.38) - gen_loss = 0.72295, disc_loss = 1.30362, estimated to finish: 624.38\n",
      "epoch 1040(3.74)/1200(4033.12) - gen_loss = 0.75303, disc_loss = 1.26546, estimated to finish: 620.48\n",
      "epoch 1041(3.78)/1200(4036.9) - gen_loss = 0.59675, disc_loss = 1.44221, estimated to finish: 616.59\n",
      "epoch 1042(3.79)/1200(4040.68) - gen_loss = 0.58992, disc_loss = 1.46325, estimated to finish: 612.69\n",
      "epoch 1043(3.76)/1200(4044.44) - gen_loss = 0.68782, disc_loss = 1.37498, estimated to finish: 608.8\n",
      "epoch 1044(3.83)/1200(4048.27) - gen_loss = 0.74448, disc_loss = 1.33009, estimated to finish: 604.91\n",
      "epoch 1045(3.79)/1200(4052.07) - gen_loss = 0.76495, disc_loss = 1.31346, estimated to finish: 601.02\n",
      "epoch 1046(3.77)/1200(4055.84) - gen_loss = 0.75585, disc_loss = 1.31197, estimated to finish: 597.13\n",
      "epoch 1047(3.77)/1200(4059.61) - gen_loss = 0.66322, disc_loss = 1.38806, estimated to finish: 593.24\n",
      "epoch 1048(3.8)/1200(4063.41) - gen_loss = 0.64085, disc_loss = 1.39876, estimated to finish: 589.35\n",
      "epoch 1049(3.81)/1200(4067.22) - gen_loss = 0.78309, disc_loss = 1.26612, estimated to finish: 585.46\n",
      "epoch 1050(3.83)/1200(4071.05) - gen_loss = 0.90984, disc_loss = 1.16083, estimated to finish: 581.58\n",
      "epoch 1051(3.78)/1200(4074.84) - gen_loss = 0.95181, disc_loss = 1.11551, estimated to finish: 577.69\n",
      "epoch 1052(3.81)/1200(4078.64) - gen_loss = 0.73103, disc_loss = 1.32178, estimated to finish: 573.8\n",
      "epoch 1053(3.81)/1200(4082.45) - gen_loss = 0.4796, disc_loss = 1.62784, estimated to finish: 569.92\n",
      "epoch 1054(3.79)/1200(4086.24) - gen_loss = 0.60564, disc_loss = 1.45057, estimated to finish: 566.03\n",
      "epoch 1055(3.83)/1200(4090.07) - gen_loss = 0.70222, disc_loss = 1.35392, estimated to finish: 562.14\n",
      "epoch 1056(3.84)/1200(4093.9) - gen_loss = 0.75602, disc_loss = 1.30848, estimated to finish: 558.26\n",
      "epoch 1057(3.8)/1200(4097.71) - gen_loss = 0.77977, disc_loss = 1.28363, estimated to finish: 554.37\n",
      "epoch 1058(3.84)/1200(4101.55) - gen_loss = 0.79029, disc_loss = 1.26765, estimated to finish: 550.49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1059(3.81)/1200(4105.35) - gen_loss = 0.7595, disc_loss = 1.28466, estimated to finish: 546.6\n",
      "epoch 1060(3.75)/1200(4109.1) - gen_loss = 0.62121, disc_loss = 1.40247, estimated to finish: 542.71\n",
      "epoch 1061(3.83)/1200(4112.93) - gen_loss = 0.73315, disc_loss = 1.29372, estimated to finish: 538.83\n",
      "epoch 1062(3.82)/1200(4116.75) - gen_loss = 0.89015, disc_loss = 1.16321, estimated to finish: 534.94\n",
      "epoch 1063(3.79)/1200(4120.54) - gen_loss = 0.95381, disc_loss = 1.0984, estimated to finish: 531.06\n",
      "epoch 1064(3.84)/1200(4124.38) - gen_loss = 0.73631, disc_loss = 1.2781, estimated to finish: 527.18\n",
      "epoch 1065(3.8)/1200(4128.18) - gen_loss = 0.52332, disc_loss = 1.51361, estimated to finish: 523.29\n",
      "epoch 1066(3.82)/1200(4131.99) - gen_loss = 0.65331, disc_loss = 1.34894, estimated to finish: 519.41\n",
      "epoch 1067(3.81)/1200(4135.8) - gen_loss = 0.73828, disc_loss = 1.27036, estimated to finish: 515.52\n",
      "epoch 1068(3.76)/1200(4139.56) - gen_loss = 0.7872, disc_loss = 1.22554, estimated to finish: 511.63\n",
      "epoch 1069(3.77)/1200(4143.34) - gen_loss = 0.80256, disc_loss = 1.20734, estimated to finish: 507.74\n",
      "epoch 1070(3.83)/1200(4147.17) - gen_loss = 0.80132, disc_loss = 1.19661, estimated to finish: 503.86\n",
      "epoch 1071(3.82)/1200(4150.98) - gen_loss = 0.73943, disc_loss = 1.22893, estimated to finish: 499.98\n",
      "epoch 1072(3.76)/1200(4154.75) - gen_loss = 0.67747, disc_loss = 1.26974, estimated to finish: 496.09\n",
      "epoch 1073(3.82)/1200(4158.57) - gen_loss = 0.88279, disc_loss = 1.09097, estimated to finish: 492.21\n",
      "epoch 1074(3.79)/1200(4162.36) - gen_loss = 0.98297, disc_loss = 0.99464, estimated to finish: 488.32\n",
      "epoch 1075(3.84)/1200(4166.2) - gen_loss = 0.67033, disc_loss = 1.24169, estimated to finish: 484.44\n",
      "epoch 1076(3.83)/1200(4170.03) - gen_loss = 0.59518, disc_loss = 1.29236, estimated to finish: 480.56\n",
      "epoch 1077(3.83)/1200(4173.86) - gen_loss = 0.7296, disc_loss = 1.14494, estimated to finish: 476.68\n",
      "epoch 1078(3.82)/1200(4177.67) - gen_loss = 0.80521, disc_loss = 1.066, estimated to finish: 472.8\n",
      "epoch 1079(3.8)/1200(4181.47) - gen_loss = 0.84722, disc_loss = 1.02592, estimated to finish: 468.91\n",
      "epoch 1080(3.78)/1200(4185.25) - gen_loss = 0.87371, disc_loss = 0.9804, estimated to finish: 465.03\n",
      "epoch 1081(3.88)/1200(4189.13) - gen_loss = 0.86462, disc_loss = 0.96294, estimated to finish: 461.15\n",
      "epoch 1082(3.79)/1200(4192.93) - gen_loss = 0.76565, disc_loss = 1.01503, estimated to finish: 457.27\n",
      "epoch 1083(3.78)/1200(4196.71) - gen_loss = 0.79558, disc_loss = 0.97085, estimated to finish: 453.38\n",
      "epoch 1084(3.71)/1200(4200.42) - gen_loss = 1.40329, disc_loss = 0.62618, estimated to finish: 449.49\n",
      "epoch 1085(3.8)/1200(4204.22) - gen_loss = 1.26039, disc_loss = 0.62892, estimated to finish: 445.61\n",
      "epoch 1086(3.84)/1200(4208.06) - gen_loss = 0.62676, disc_loss = 1.04815, estimated to finish: 441.73\n",
      "epoch 1087(3.86)/1200(4211.92) - gen_loss = 0.8012, disc_loss = 0.84004, estimated to finish: 437.85\n",
      "epoch 1088(3.82)/1200(4215.73) - gen_loss = 0.95976, disc_loss = 0.71185, estimated to finish: 433.97\n",
      "epoch 1089(3.78)/1200(4219.52) - gen_loss = 1.06582, disc_loss = 0.63911, estimated to finish: 430.09\n",
      "epoch 1090(3.8)/1200(4223.32) - gen_loss = 1.12559, disc_loss = 0.59254, estimated to finish: 426.21\n",
      "epoch 1091(3.82)/1200(4227.14) - gen_loss = 1.21198, disc_loss = 0.54521, estimated to finish: 422.33\n",
      "epoch 1092(3.8)/1200(4230.94) - gen_loss = 1.3476, disc_loss = 0.48055, estimated to finish: 418.44\n",
      "epoch 1093(3.82)/1200(4234.76) - gen_loss = 1.37793, disc_loss = 0.44256, estimated to finish: 414.56\n",
      "epoch 1094(3.77)/1200(4238.53) - gen_loss = 1.51722, disc_loss = 0.40606, estimated to finish: 410.68\n",
      "epoch 1095(3.78)/1200(4242.31) - gen_loss = 1.49327, disc_loss = 0.39564, estimated to finish: 406.8\n",
      "epoch 1096(3.81)/1200(4246.12) - gen_loss = 1.66725, disc_loss = 0.36955, estimated to finish: 402.92\n",
      "epoch 1097(3.77)/1200(4249.89) - gen_loss = 1.7357, disc_loss = 0.3536, estimated to finish: 399.03\n",
      "epoch 1098(3.78)/1200(4253.67) - gen_loss = 1.67446, disc_loss = 0.35885, estimated to finish: 395.15\n",
      "epoch 1099(3.8)/1200(4257.47) - gen_loss = 1.84195, disc_loss = 0.31774, estimated to finish: 391.27\n",
      "epoch 1100(3.83)/1200(4261.3) - gen_loss = 1.89531, disc_loss = 0.29735, estimated to finish: 387.39\n",
      "epoch 1101(3.79)/1200(4265.09) - gen_loss = 2.07909, disc_loss = 0.25593, estimated to finish: 383.51\n",
      "epoch 1102(3.83)/1200(4268.91) - gen_loss = 2.07377, disc_loss = 0.25529, estimated to finish: 379.63\n",
      "epoch 1103(3.86)/1200(4272.77) - gen_loss = 2.32866, disc_loss = 0.27224, estimated to finish: 375.76\n",
      "epoch 1104(3.87)/1200(4276.65) - gen_loss = 2.17286, disc_loss = 0.30905, estimated to finish: 371.88\n",
      "epoch 1105(3.81)/1200(4280.46) - gen_loss = 2.40319, disc_loss = 0.28941, estimated to finish: 368.0\n",
      "epoch 1106(3.84)/1200(4284.3) - gen_loss = 2.13796, disc_loss = 0.35953, estimated to finish: 364.13\n",
      "epoch 1107(3.85)/1200(4288.15) - gen_loss = 2.32045, disc_loss = 0.30351, estimated to finish: 360.25\n",
      "epoch 1108(3.85)/1200(4291.99) - gen_loss = 2.30579, disc_loss = 0.31191, estimated to finish: 356.37\n",
      "epoch 1109(3.82)/1200(4295.81) - gen_loss = 2.31673, disc_loss = 0.27026, estimated to finish: 352.5\n",
      "epoch 1110(3.75)/1200(4299.56) - gen_loss = 2.45244, disc_loss = 0.30506, estimated to finish: 348.61\n",
      "epoch 1111(3.88)/1200(4303.43) - gen_loss = 2.40887, disc_loss = 0.2553, estimated to finish: 344.74\n",
      "epoch 1112(3.81)/1200(4307.25) - gen_loss = 2.72768, disc_loss = 0.25277, estimated to finish: 340.86\n",
      "epoch 1113(3.81)/1200(4311.06) - gen_loss = 3.25679, disc_loss = 0.15969, estimated to finish: 336.98\n",
      "epoch 1114(3.84)/1200(4314.9) - gen_loss = 3.49352, disc_loss = 0.15607, estimated to finish: 333.11\n",
      "epoch 1115(3.82)/1200(4318.72) - gen_loss = 3.67305, disc_loss = 0.14753, estimated to finish: 329.23\n",
      "epoch 1116(3.82)/1200(4322.54) - gen_loss = 3.57708, disc_loss = 0.17428, estimated to finish: 325.35\n",
      "epoch 1117(3.81)/1200(4326.36) - gen_loss = 3.31118, disc_loss = 0.15704, estimated to finish: 321.47\n",
      "epoch 1118(3.84)/1200(4330.2) - gen_loss = 2.73036, disc_loss = 0.19496, estimated to finish: 317.6\n",
      "epoch 1119(3.8)/1200(4333.99) - gen_loss = 2.82687, disc_loss = 0.20361, estimated to finish: 313.72\n",
      "epoch 1120(3.83)/1200(4337.82) - gen_loss = 2.80181, disc_loss = 0.21294, estimated to finish: 309.84\n",
      "epoch 1121(3.83)/1200(4341.66) - gen_loss = 2.6916, disc_loss = 0.2478, estimated to finish: 305.97\n",
      "epoch 1122(3.84)/1200(4345.5) - gen_loss = 2.83929, disc_loss = 1.94481, estimated to finish: 302.09\n",
      "epoch 1123(3.83)/1200(4349.33) - gen_loss = 3.6776, disc_loss = 1.80695, estimated to finish: 298.22\n",
      "epoch 1124(3.88)/1200(4353.21) - gen_loss = 3.7028, disc_loss = 0.50811, estimated to finish: 294.35\n",
      "epoch 1125(3.79)/1200(4357.0) - gen_loss = 3.63696, disc_loss = 0.28823, estimated to finish: 290.47\n",
      "epoch 1126(3.85)/1200(4360.85) - gen_loss = 3.74365, disc_loss = 0.30882, estimated to finish: 286.59\n",
      "epoch 1127(3.84)/1200(4364.69) - gen_loss = 3.7324, disc_loss = 0.28615, estimated to finish: 282.72\n",
      "epoch 1128(3.87)/1200(4368.57) - gen_loss = 3.83573, disc_loss = 0.31848, estimated to finish: 278.84\n",
      "epoch 1129(4.23)/1200(4372.79) - gen_loss = 3.8196, disc_loss = 0.37232, estimated to finish: 274.99\n",
      "epoch 1130(4.24)/1200(4377.04) - gen_loss = 3.59708, disc_loss = 0.51819, estimated to finish: 271.14\n",
      "epoch 1131(3.93)/1200(4380.97) - gen_loss = 3.26889, disc_loss = 0.73158, estimated to finish: 267.27\n",
      "epoch 1132(4.27)/1200(4385.24) - gen_loss = 3.2929, disc_loss = 0.77267, estimated to finish: 263.42\n",
      "epoch 1133(4.38)/1200(4389.62) - gen_loss = 3.40669, disc_loss = 0.69825, estimated to finish: 259.58\n",
      "epoch 1134(4.33)/1200(4393.94) - gen_loss = 3.33648, disc_loss = 0.68547, estimated to finish: 255.73\n",
      "epoch 1135(4.06)/1200(4398.0) - gen_loss = 3.39118, disc_loss = 0.64514, estimated to finish: 251.87\n",
      "epoch 1136(4.03)/1200(4402.03) - gen_loss = 3.39299, disc_loss = 0.58736, estimated to finish: 248.0\n",
      "epoch 1137(3.93)/1200(4405.96) - gen_loss = 3.34095, disc_loss = 0.58591, estimated to finish: 244.13\n",
      "epoch 1138(3.85)/1200(4409.81) - gen_loss = 3.39882, disc_loss = 0.54378, estimated to finish: 240.25\n",
      "epoch 1139(3.91)/1200(4413.71) - gen_loss = 3.30952, disc_loss = 0.55822, estimated to finish: 236.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1140(3.99)/1200(4417.71) - gen_loss = 3.367, disc_loss = 0.52356, estimated to finish: 232.51\n",
      "epoch 1141(3.98)/1200(4421.69) - gen_loss = 3.37378, disc_loss = 0.50572, estimated to finish: 228.64\n",
      "epoch 1142(4.07)/1200(4425.76) - gen_loss = 3.39215, disc_loss = 0.48499, estimated to finish: 224.78\n",
      "epoch 1143(4.08)/1200(4429.84) - gen_loss = 3.34652, disc_loss = 0.49783, estimated to finish: 220.91\n",
      "epoch 1144(4.18)/1200(4434.02) - gen_loss = 3.35196, disc_loss = 0.46589, estimated to finish: 217.05\n",
      "epoch 1145(4.14)/1200(4438.17) - gen_loss = 3.36357, disc_loss = 0.48452, estimated to finish: 213.19\n",
      "epoch 1146(4.25)/1200(4442.42) - gen_loss = 3.35041, disc_loss = 0.46668, estimated to finish: 209.33\n",
      "epoch 1147(4.18)/1200(4446.6) - gen_loss = 3.39125, disc_loss = 0.45573, estimated to finish: 205.47\n",
      "epoch 1148(3.89)/1200(4450.49) - gen_loss = 3.34995, disc_loss = 0.47124, estimated to finish: 201.59\n",
      "epoch 1149(3.84)/1200(4454.33) - gen_loss = 3.38257, disc_loss = 0.4468, estimated to finish: 197.71\n",
      "epoch 1150(3.8)/1200(4458.13) - gen_loss = 3.39024, disc_loss = 0.46059, estimated to finish: 193.83\n",
      "epoch 1151(3.93)/1200(4462.06) - gen_loss = 3.41175, disc_loss = 0.46786, estimated to finish: 189.96\n",
      "epoch 1152(3.9)/1200(4465.96) - gen_loss = 3.45689, disc_loss = 0.46116, estimated to finish: 186.08\n",
      "epoch 1153(3.87)/1200(4469.83) - gen_loss = 3.50332, disc_loss = 0.45981, estimated to finish: 182.2\n",
      "epoch 1154(3.93)/1200(4473.76) - gen_loss = 3.55382, disc_loss = 0.44305, estimated to finish: 178.33\n",
      "epoch 1155(3.87)/1200(4477.63) - gen_loss = 3.47917, disc_loss = 0.4659, estimated to finish: 174.45\n",
      "epoch 1156(3.9)/1200(4481.54) - gen_loss = 3.42173, disc_loss = 0.47875, estimated to finish: 170.58\n",
      "epoch 1157(3.94)/1200(4485.48) - gen_loss = 3.48091, disc_loss = 0.47072, estimated to finish: 166.7\n",
      "epoch 1158(3.83)/1200(4489.31) - gen_loss = 3.3615, disc_loss = 0.48827, estimated to finish: 162.82\n",
      "epoch 1159(3.98)/1200(4493.29) - gen_loss = 3.27275, disc_loss = 0.45691, estimated to finish: 158.95\n",
      "epoch 1160(3.9)/1200(4497.19) - gen_loss = 3.17585, disc_loss = 0.4138, estimated to finish: 155.08\n",
      "epoch 1161(4.04)/1200(4501.23) - gen_loss = 2.92438, disc_loss = 0.42273, estimated to finish: 151.2\n",
      "epoch 1162(3.82)/1200(4505.05) - gen_loss = 2.70955, disc_loss = 0.4099, estimated to finish: 147.33\n",
      "epoch 1163(3.92)/1200(4508.97) - gen_loss = 2.54413, disc_loss = 0.38958, estimated to finish: 143.45\n",
      "epoch 1164(3.88)/1200(4512.85) - gen_loss = 2.30359, disc_loss = 0.36942, estimated to finish: 139.57\n",
      "epoch 1165(3.85)/1200(4516.7) - gen_loss = 2.12646, disc_loss = 0.36861, estimated to finish: 135.69\n",
      "epoch 1166(3.86)/1200(4520.56) - gen_loss = 2.05364, disc_loss = 0.35283, estimated to finish: 131.82\n",
      "epoch 1167(3.96)/1200(4524.51) - gen_loss = 2.00061, disc_loss = 0.36097, estimated to finish: 127.94\n",
      "epoch 1168(3.91)/1200(4528.43) - gen_loss = 2.05887, disc_loss = 0.33376, estimated to finish: 124.07\n",
      "epoch 1169(4.01)/1200(4532.43) - gen_loss = 2.02015, disc_loss = 0.33225, estimated to finish: 120.19\n",
      "epoch 1170(3.94)/1200(4536.38) - gen_loss = 2.17536, disc_loss = 0.61581, estimated to finish: 116.32\n",
      "epoch 1171(4.1)/1200(4540.48) - gen_loss = 3.0259, disc_loss = 2.62154, estimated to finish: 112.45\n",
      "epoch 1172(4.05)/1200(4544.53) - gen_loss = 2.15572, disc_loss = 1.29829, estimated to finish: 108.57\n",
      "epoch 1173(3.98)/1200(4548.52) - gen_loss = 1.41271, disc_loss = 0.59077, estimated to finish: 104.7\n",
      "epoch 1174(4.0)/1200(4552.51) - gen_loss = 1.46272, disc_loss = 0.53526, estimated to finish: 100.82\n",
      "epoch 1175(3.95)/1200(4556.46) - gen_loss = 1.5778, disc_loss = 0.48095, estimated to finish: 96.95\n",
      "epoch 1176(3.87)/1200(4560.34) - gen_loss = 1.69975, disc_loss = 0.42958, estimated to finish: 93.07\n",
      "epoch 1177(3.88)/1200(4564.22) - gen_loss = 1.79543, disc_loss = 0.3967, estimated to finish: 89.19\n",
      "epoch 1178(3.93)/1200(4568.15) - gen_loss = 1.86041, disc_loss = 0.38039, estimated to finish: 85.31\n",
      "epoch 1179(3.98)/1200(4572.13) - gen_loss = 1.94525, disc_loss = 0.35496, estimated to finish: 81.44\n",
      "epoch 1180(3.92)/1200(4576.05) - gen_loss = 1.98839, disc_loss = 0.35464, estimated to finish: 77.56\n",
      "epoch 1181(4.06)/1200(4580.11) - gen_loss = 2.0441, disc_loss = 0.32607, estimated to finish: 73.69\n",
      "epoch 1182(4.21)/1200(4584.32) - gen_loss = 2.08264, disc_loss = 0.32097, estimated to finish: 69.81\n",
      "epoch 1183(4.04)/1200(4588.35) - gen_loss = 2.09797, disc_loss = 0.32621, estimated to finish: 65.94\n",
      "epoch 1184(4.21)/1200(4592.56) - gen_loss = 2.13132, disc_loss = 0.31214, estimated to finish: 62.06\n",
      "epoch 1185(3.99)/1200(4596.56) - gen_loss = 2.06468, disc_loss = 0.31785, estimated to finish: 58.18\n",
      "epoch 1186(3.9)/1200(4600.46) - gen_loss = 1.92654, disc_loss = 0.74931, estimated to finish: 54.31\n",
      "epoch 1187(3.91)/1200(4604.37) - gen_loss = 2.2383, disc_loss = 0.37359, estimated to finish: 50.43\n",
      "epoch 1188(3.97)/1200(4608.34) - gen_loss = 2.15146, disc_loss = 0.34742, estimated to finish: 46.55\n",
      "epoch 1189(3.92)/1200(4612.26) - gen_loss = 2.14151, disc_loss = 0.33246, estimated to finish: 42.67\n",
      "epoch 1190(3.85)/1200(4616.11) - gen_loss = 2.16701, disc_loss = 0.31636, estimated to finish: 38.79\n",
      "epoch 1191(4.04)/1200(4620.15) - gen_loss = 2.1421, disc_loss = 0.30386, estimated to finish: 34.91\n",
      "epoch 1192(3.88)/1200(4624.04) - gen_loss = 2.11562, disc_loss = 0.30688, estimated to finish: 31.03\n",
      "epoch 1193(3.86)/1200(4627.9) - gen_loss = 2.06828, disc_loss = 0.3296, estimated to finish: 27.15\n",
      "epoch 1194(3.83)/1200(4631.73) - gen_loss = 2.09395, disc_loss = 0.32132, estimated to finish: 23.28\n",
      "epoch 1195(3.85)/1200(4635.58) - gen_loss = 2.14229, disc_loss = 0.33884, estimated to finish: 19.4\n",
      "epoch 1196(3.86)/1200(4639.44) - gen_loss = 2.08552, disc_loss = 0.3405, estimated to finish: 15.52\n",
      "epoch 1197(3.85)/1200(4643.29) - gen_loss = 2.07021, disc_loss = 0.33009, estimated to finish: 11.64\n",
      "epoch 1198(3.84)/1200(4647.13) - gen_loss = 2.02196, disc_loss = 0.3726, estimated to finish: 7.76\n",
      "epoch 1199(3.83)/1200(4650.96) - gen_loss = 2.15999, disc_loss = 0.36961, estimated to finish: 3.88\n",
      "epoch 1200(3.86)/1200(4654.82) - gen_loss = 2.1575, disc_loss = 0.38209, estimated to finish: 0.0\n"
     ]
    }
   ],
   "source": [
    "train = Train(seqs_normal, adj, node_f, epochs, lr = lr, adam_beta_1 = adm1, base=base, dropout=dropout, alpha=alpha)\n",
    "train(epochs, save_path+'/'+name+'_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
