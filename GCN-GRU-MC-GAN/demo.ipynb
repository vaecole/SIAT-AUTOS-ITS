{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "basic_info_df = pd.read_csv('data/parkings_info.csv')\n",
    "basic_info_df['lat_long'] = list(zip(basic_info_df['latitude'], basic_info_df['longitude']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_utils import build_graph\n",
    "\n",
    "target_park = '电影大厦'\n",
    "target_area, adj, target_map, nks, kns = build_graph(basic_info_df, target_park)\n",
    "target_park_basic_info = basic_info_df.loc[basic_info_df.parking_name == target_park].iloc[0]\n",
    "\n",
    "seqs_raw = build_area_seqs(target_area, start='2016-10-01', end='2016-11-01')\n",
    "# normalization\n",
    "seqs_normal = seqs_raw/seqs_raw.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes_features(area_df):\n",
    "    node_f = area_df[['total_space','monthly_fee','building_type']]\n",
    "    node_f['total_space'] = node_f.total_space/node_f.total_space.max()\n",
    "    node_f['monthly_fee'] = node_f.monthly_fee/node_f.monthly_fee.max()\n",
    "    building_type_oneHot = pd.get_dummies(node_f['building_type'])\n",
    "    node_f = node_f.drop('building_type',axis = 1)\n",
    "    node_f = node_f.join(building_type_oneHot)\n",
    "    return node_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-6246592cf25e>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  node_f['total_space'] = node_f.total_space/node_f.total_space.max()\n",
      "<ipython-input-3-6246592cf25e>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  node_f['monthly_fee'] = node_f.monthly_fee/node_f.monthly_fee.max()\n"
     ]
    }
   ],
   "source": [
    "node_f = get_nodes_features(target_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from datetime import date, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def build_area_seqs(target_area, start='2016-08-01', end='2017-01-01'):\n",
    "    # 整合到一个文件中\n",
    "    area_df = pd.DataFrame()\n",
    "    for name in target_area.parking_name:\n",
    "        file_name = 'data/seqs/'+name+'_seq.csv'\n",
    "        file_df = pd.read_csv(file_name)\n",
    "        file_df['parking'] = nks[name]\n",
    "        cols = file_df.columns.tolist()\n",
    "        cols = [cols[0], cols[2], cols[1]]\n",
    "        file_df = file_df[cols]\n",
    "        if len(area_df)>0:\n",
    "            area_df = pd.concat([area_df, file_df])\n",
    "        else:\n",
    "            area_df = file_df\n",
    "\n",
    "    out_bound_indexes = area_df[(area_df['date'] < start) | (area_df['date'] >= end)].index \n",
    "    area_df.drop(out_bound_indexes, inplace = True) \n",
    "    return area_df.pivot_table('occupy', ['date'], 'parking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from abc import ABC\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dropout, GRU, Flatten, Dense, LeakyReLU\n",
    "from spektral.layers import GraphConv\n",
    "from spektral.utils import normalized_laplacian\n",
    "\n",
    "l2_reg = 5e-4 / 2       # L2 regularization rate\n",
    "\n",
    "class Generator(tf.keras.Model, ABC):\n",
    "\n",
    "    def __init__(self, seq=96, N=11):\n",
    "        super(Generator, self).__init__()\n",
    "        self.dropout = Dropout(0.25)\n",
    "        self.flatten = Flatten()\n",
    "        self.graph_conv_1 = GraphConv(32,\n",
    "                               activation='elu',\n",
    "                               kernel_regularizer=l2(l2_reg),\n",
    "                               use_bias=False)\n",
    "        self.graph_conv_2 = GraphConv(16,\n",
    "                               activation='elu',\n",
    "                               kernel_regularizer=l2(l2_reg),\n",
    "                               use_bias=False)\n",
    "        self.dense_1 = Dense(32, activation='relu')\n",
    "        self.dense_2 = Dense(64, activation='relu')\n",
    "        self.gru = GRU(128, return_sequences=True)\n",
    "        self.final_dense = Dense(1, activation='tanh')\n",
    "\n",
    "    def call(self, seq, adj, nodes_features, training=True):\n",
    "        f = tf.convert_to_tensor(nodes_features) # 11*F\n",
    "        g = tf.convert_to_tensor(normalized_laplacian(adj)) # 11*11\n",
    "        s = tf.convert_to_tensor(seq) # 96*11\n",
    "        \n",
    "        # https://github.com/danielegrattarola/spektral/blob/master/examples/node_prediction/citation_gcn.py\n",
    "        c = self.graph_conv_1([f, g]) # 11*11\n",
    "        c = self.graph_conv_2([c, g]) # 11*11\n",
    "        \n",
    "        s_g = tf.matmul(s, c) # 96*11\n",
    "        \n",
    "        fc = self.dense_1(s_g)  # 96*32\n",
    "        fc = self.dropout(fc, training=training)\n",
    "        fc = self.dense_2(fc)   # 96*32             \n",
    "        fc = self.dropout(fc, training=training)\n",
    "\n",
    "        fc = tf.expand_dims(fc, axis=0) # 1*96*32 \n",
    "        ro = self.gru(fc)\n",
    "        ro = tf.squeeze(ro, axis=0) # 96*32\n",
    "        return self.final_dense(ro) # 96*1\n",
    "\n",
    "    \n",
    "class Discriminator(tf.keras.Model, ABC):\n",
    "\n",
    "    def __init__(self, seq=96, N=11):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.leaky_relu = LeakyReLU(alpha=0.2)\n",
    "        self.dropout = Dropout(0.25)\n",
    "        self.flatten = Flatten()\n",
    "        self.graph_conv_1 = GraphConv(32,\n",
    "                               activation='elu',\n",
    "                               kernel_regularizer=l2(l2_reg),\n",
    "                               use_bias=False)\n",
    "        self.graph_conv_2 = GraphConv(16,\n",
    "                               activation='elu',\n",
    "                               kernel_regularizer=l2(l2_reg),\n",
    "                               use_bias=False)\n",
    "        self.dense_1 = Dense(32)\n",
    "        self.dense_2 = Dense(64)\n",
    "        self.gru = GRU(128, return_sequences=True)\n",
    "        self.final_dense = Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, seq, adj, nodes_features, training=True):\n",
    "        s = tf.convert_to_tensor(seq) # 96*1\n",
    "\n",
    "        fc = self.dense_1(s)  # 96*32    \n",
    "        fc = self.leaky_relu(fc)\n",
    "        fc = self.dropout(fc, training=training)\n",
    "        \n",
    "        fc = self.dense_2(fc) # 96*64\n",
    "        fc = self.leaky_relu(fc)\n",
    "        fc = self.dropout(fc, training=training)\n",
    "\n",
    "        fc = tf.expand_dims(fc, axis=0)\n",
    "        ro = self.gru(fc)\n",
    "        ro = tf.squeeze(ro, axis=0) # 96*64\n",
    "        return self.final_dense(ro) # 96*1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from image_utils import save_images, save_images_batch, sample_noise\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch_size = 96\n",
    "save_interval = 5\n",
    "learning_rate = 2e-3\n",
    "adam_beta_1 = 0.5\n",
    "\n",
    "\n",
    "class Train:\n",
    "    def __init__(self, seqs, adj, nodes_features, epochs=1000, key=9):\n",
    "        self.epochs = epochs\n",
    "        self.gen_optimizer = Adam(learning_rate, adam_beta_1)\n",
    "        self.desc_optimizer = Adam(learning_rate, adam_beta_1)\n",
    "        self.generator = Generator(seqs.shape[0], seqs.shape[1])\n",
    "        self.discriminator = Discriminator(seqs.shape[0], seqs.shape[1])\n",
    "        self.cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        self.seqs = seqs.astype('float32')\n",
    "        self.adj = adj.astype('float32')\n",
    "        self.nodes_features = nodes_features.astype('float32')\n",
    "        self.key=key\n",
    "        \n",
    "    def __call__(self, save_path='saved'):\n",
    "        save_path+=str(time.time())\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        \n",
    "        time_len = self.seqs.shape[0]\n",
    "        num_nodes = self.seqs.shape[1]\n",
    "        total_batch = int(time_len / batch_size) # 2976/96=31\n",
    "        \n",
    "        time_consumed_total = 0.\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            start = time.time()\n",
    "            total_gen_loss = 0\n",
    "            total_disc_loss = 0\n",
    "            \n",
    "            for week in range(0, total_batch):\n",
    "                gen_loss, disc_loss = self.train_step(self.seqs[week:week+batch_size], self.adj, self.nodes_features)\n",
    "                total_gen_loss += gen_loss\n",
    "                total_disc_loss += disc_loss\n",
    "\n",
    "            time_consumed = time.time() - start\n",
    "            time_consumed_total += time_consumed\n",
    "            time_consumed_agv = time_consumed_total / epoch\n",
    "            self.epochs_last = self.epochs - epoch\n",
    "            estimate_time_last = self.epochs_last * time_consumed_agv\n",
    "            print('epoch {}({})/{}({}) - gen_loss = {}, disc_loss = {}, estimated to finish: {}'\n",
    "                  .format(epoch, round(time.time() - start, 2),\n",
    "                          self.epochs, round(time_consumed_total,2),\n",
    "                          round(float(total_gen_loss/total_batch),5),\n",
    "                          round(float(total_disc_loss/total_batch),5),\n",
    "                          round(estimate_time_last,2)))\n",
    "            \n",
    "            if epoch%save_interval==0:\n",
    "                plot = self.generate()\n",
    "                fig = plot.get_figure()\n",
    "                fig.savefig(save_path+\"/gen_\"+str(epoch)+\".png\")\n",
    "                plt.clf()\n",
    "            \n",
    "    def train_step(self, seqs, adj, nodes_features, key=9):\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            seqs_noise = seqs.copy()\n",
    "            max_s = seqs[key].max()\n",
    "            seqs_noise[key] = np.random.normal(max_s/2.0, max_s/10.0, size=(seqs.shape[0])).astype('float32')\n",
    "            \n",
    "            generated = self.generator(seqs_noise, adj, nodes_features)\n",
    "            real_output = self.discriminator(tf.expand_dims(seqs[key], axis=1), adj, nodes_features) # 评价高\n",
    "            generated_output = self.discriminator(generated, adj, nodes_features) # 初始评价低\n",
    "\n",
    "            loss_g = self.generator_loss(self.cross_entropy, generated_output)\n",
    "            loss_d = self.discriminator_loss(self.cross_entropy, real_output, generated_output)\n",
    "\n",
    "        grad_gen = tape.gradient(loss_g, self.generator.trainable_variables)\n",
    "        grad_disc = tape.gradient(loss_d, self.discriminator.trainable_variables)\n",
    "\n",
    "        self.gen_optimizer.apply_gradients(zip(grad_gen, self.generator.trainable_variables))\n",
    "        self.desc_optimizer.apply_gradients(zip(grad_disc, self.discriminator.trainable_variables))\n",
    "\n",
    "        return loss_g, loss_d\n",
    "    \n",
    "    def generate(self):\n",
    "        seqs_replace = self.seqs[:batch_size].copy()\n",
    "        max_s = seqs_replace[self.key].max()\n",
    "        seqs_replace[self.key] = np.random.normal(max_s/2.0, max_s/10.0, size=(seqs_replace.shape[0])).astype('float32')\n",
    "        gen_data = self.generator(seqs_replace, self.adj, self.nodes_features, training=False)\n",
    "        \n",
    "        from sklearn import preprocessing\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        x_scaled = min_max_scaler.fit_transform(gen_data.numpy())\n",
    "        return pd.DataFrame(x_scaled).plot() # [self.key]\n",
    "    \n",
    "    @staticmethod\n",
    "    def discriminator_loss(loss_object, real_output, fake_output):\n",
    "        \"\"\"\n",
    "        ...\n",
    "        \"\"\"\n",
    "        real_loss = loss_object(tf.ones_like(real_output), real_output)\n",
    "        fake_loss = loss_object(tf.zeros_like(fake_output), fake_output)\n",
    "        total_loss = real_loss + fake_loss\n",
    "        return total_loss\n",
    "\n",
    "    @staticmethod\n",
    "    def generator_loss(loss_object, fake_output):\n",
    "        \"\"\"\n",
    "        ...\n",
    "        \"\"\"\n",
    "        return loss_object(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1(10.26)/100(10.26) - gen_loss = 1.00989, disc_loss = 1.33514, estimated to finish: 1015.94\n",
      "epoch 2(4.45)/100(14.71) - gen_loss = 0.67996, disc_loss = 1.38744, estimated to finish: 720.65\n",
      "epoch 3(4.39)/100(19.1) - gen_loss = 0.75091, disc_loss = 1.33014, estimated to finish: 617.44\n",
      "epoch 4(4.36)/100(23.46) - gen_loss = 0.7146, disc_loss = 1.37127, estimated to finish: 562.94\n",
      "epoch 5(4.35)/100(27.8) - gen_loss = 0.68639, disc_loss = 1.39661, estimated to finish: 528.25\n",
      "epoch 6(4.36)/100(32.16) - gen_loss = 0.69267, disc_loss = 1.39256, estimated to finish: 503.85\n",
      "epoch 7(4.39)/100(36.55) - gen_loss = 0.69573, disc_loss = 1.39084, estimated to finish: 485.58\n",
      "epoch 8(4.39)/100(40.94) - gen_loss = 0.69748, disc_loss = 1.38798, estimated to finish: 470.78\n",
      "epoch 9(4.38)/100(45.32) - gen_loss = 0.69928, disc_loss = 1.38611, estimated to finish: 458.24\n",
      "epoch 10(4.35)/100(49.67) - gen_loss = 0.70659, disc_loss = 1.38119, estimated to finish: 447.01\n",
      "epoch 11(4.35)/100(54.02) - gen_loss = 0.70653, disc_loss = 1.37885, estimated to finish: 437.07\n",
      "epoch 12(4.41)/100(58.43) - gen_loss = 0.6914, disc_loss = 1.38761, estimated to finish: 428.5\n",
      "epoch 13(4.35)/100(62.78) - gen_loss = 0.69155, disc_loss = 1.38854, estimated to finish: 420.15\n",
      "epoch 14(4.68)/100(67.46) - gen_loss = 0.70123, disc_loss = 1.3851, estimated to finish: 414.41\n",
      "epoch 15(4.36)/100(71.82) - gen_loss = 0.71907, disc_loss = 1.37987, estimated to finish: 406.98\n",
      "epoch 16(4.34)/100(76.16) - gen_loss = 0.66946, disc_loss = 1.38659, estimated to finish: 399.83\n",
      "epoch 17(4.34)/100(80.5) - gen_loss = 0.71418, disc_loss = 1.38495, estimated to finish: 393.03\n",
      "epoch 18(4.36)/100(84.86) - gen_loss = 0.68514, disc_loss = 1.39244, estimated to finish: 386.58\n",
      "epoch 19(4.34)/100(89.2) - gen_loss = 0.7025, disc_loss = 1.38654, estimated to finish: 380.28\n",
      "epoch 20(4.32)/100(93.52) - gen_loss = 0.71334, disc_loss = 1.38426, estimated to finish: 374.09\n",
      "epoch 21(4.42)/100(97.94) - gen_loss = 0.66738, disc_loss = 1.39081, estimated to finish: 368.44\n",
      "epoch 22(4.39)/100(102.33) - gen_loss = 0.7154, disc_loss = 1.38692, estimated to finish: 362.8\n",
      "epoch 23(4.44)/100(106.77) - gen_loss = 0.70031, disc_loss = 1.38364, estimated to finish: 357.45\n",
      "epoch 24(4.4)/100(111.17) - gen_loss = 0.67122, disc_loss = 1.3868, estimated to finish: 352.04\n",
      "epoch 25(4.29)/100(115.46) - gen_loss = 0.70674, disc_loss = 1.38666, estimated to finish: 346.39\n",
      "epoch 26(4.34)/100(119.81) - gen_loss = 0.69499, disc_loss = 1.38251, estimated to finish: 341.0\n",
      "epoch 27(4.36)/100(124.17) - gen_loss = 0.71183, disc_loss = 1.38467, estimated to finish: 335.71\n",
      "epoch 28(4.46)/100(128.63) - gen_loss = 0.71047, disc_loss = 1.38935, estimated to finish: 330.76\n",
      "epoch 29(4.4)/100(133.03) - gen_loss = 0.81003, disc_loss = 1.55674, estimated to finish: 325.69\n",
      "epoch 30(4.41)/100(137.43) - gen_loss = 0.6843, disc_loss = 1.39556, estimated to finish: 320.68\n",
      "epoch 31(4.46)/100(141.9) - gen_loss = 0.70984, disc_loss = 1.38228, estimated to finish: 315.83\n",
      "epoch 32(4.36)/100(146.26) - gen_loss = 0.70546, disc_loss = 1.38866, estimated to finish: 310.8\n",
      "epoch 33(4.34)/100(150.6) - gen_loss = 0.68082, disc_loss = 1.3854, estimated to finish: 305.77\n",
      "epoch 34(4.35)/100(154.95) - gen_loss = 0.74124, disc_loss = 1.37736, estimated to finish: 300.79\n",
      "epoch 35(4.37)/100(159.33) - gen_loss = 0.69144, disc_loss = 1.38734, estimated to finish: 295.89\n",
      "epoch 36(4.39)/100(163.72) - gen_loss = 0.71038, disc_loss = 1.38524, estimated to finish: 291.06\n",
      "epoch 37(4.33)/100(168.05) - gen_loss = 0.68483, disc_loss = 1.38513, estimated to finish: 286.13\n",
      "epoch 38(4.34)/100(172.39) - gen_loss = 0.70721, disc_loss = 1.38604, estimated to finish: 281.27\n",
      "epoch 39(4.35)/100(176.74) - gen_loss = 0.70771, disc_loss = 1.38061, estimated to finish: 276.45\n",
      "epoch 40(4.34)/100(181.09) - gen_loss = 0.70936, disc_loss = 1.384, estimated to finish: 271.63\n",
      "epoch 41(4.34)/100(185.42) - gen_loss = 0.69083, disc_loss = 1.38217, estimated to finish: 266.83\n",
      "epoch 42(4.34)/100(189.76) - gen_loss = 0.69323, disc_loss = 1.39076, estimated to finish: 262.06\n",
      "epoch 43(4.36)/100(194.12) - gen_loss = 0.7374, disc_loss = 1.36391, estimated to finish: 257.32\n",
      "epoch 44(4.31)/100(198.43) - gen_loss = 0.71249, disc_loss = 1.38995, estimated to finish: 252.55\n",
      "epoch 45(4.35)/100(202.79) - gen_loss = 0.74184, disc_loss = 1.3477, estimated to finish: 247.85\n",
      "epoch 46(4.33)/100(207.11) - gen_loss = 0.68591, disc_loss = 1.40897, estimated to finish: 243.13\n",
      "epoch 47(4.37)/100(211.49) - gen_loss = 0.7096, disc_loss = 1.38324, estimated to finish: 238.49\n",
      "epoch 48(4.33)/100(215.82) - gen_loss = 0.69993, disc_loss = 1.38202, estimated to finish: 233.8\n",
      "epoch 49(4.33)/100(220.14) - gen_loss = 0.69561, disc_loss = 1.38569, estimated to finish: 229.13\n",
      "epoch 50(4.33)/100(224.48) - gen_loss = 0.69459, disc_loss = 1.38461, estimated to finish: 224.48\n",
      "epoch 51(4.36)/100(228.83) - gen_loss = 0.71206, disc_loss = 1.38014, estimated to finish: 219.86\n",
      "epoch 52(4.33)/100(233.16) - gen_loss = 0.71427, disc_loss = 1.36716, estimated to finish: 215.23\n",
      "epoch 53(4.3)/100(237.47) - gen_loss = 0.71652, disc_loss = 1.38346, estimated to finish: 210.58\n",
      "epoch 54(4.31)/100(241.77) - gen_loss = 0.71092, disc_loss = 1.37287, estimated to finish: 205.95\n",
      "epoch 55(4.29)/100(246.07) - gen_loss = 0.71339, disc_loss = 1.40207, estimated to finish: 201.33\n",
      "epoch 56(4.33)/100(250.39) - gen_loss = 0.71126, disc_loss = 1.37211, estimated to finish: 196.74\n",
      "epoch 57(4.34)/100(254.74) - gen_loss = 0.7265, disc_loss = 1.36831, estimated to finish: 192.17\n",
      "epoch 58(4.26)/100(259.0) - gen_loss = 0.69247, disc_loss = 1.39268, estimated to finish: 187.55\n",
      "epoch 59(4.3)/100(263.3) - gen_loss = 0.69433, disc_loss = 1.38739, estimated to finish: 182.97\n",
      "epoch 60(4.32)/100(267.62) - gen_loss = 0.69997, disc_loss = 1.3854, estimated to finish: 178.41\n",
      "epoch 61(4.3)/100(271.92) - gen_loss = 0.70454, disc_loss = 1.37809, estimated to finish: 173.85\n",
      "epoch 62(4.34)/100(276.26) - gen_loss = 0.70264, disc_loss = 1.37895, estimated to finish: 169.32\n",
      "epoch 63(4.31)/100(280.57) - gen_loss = 0.70445, disc_loss = 1.38529, estimated to finish: 164.78\n",
      "epoch 64(4.33)/100(284.89) - gen_loss = 0.70116, disc_loss = 1.38173, estimated to finish: 160.25\n",
      "epoch 65(4.31)/100(289.2) - gen_loss = 0.70008, disc_loss = 1.38594, estimated to finish: 155.72\n",
      "epoch 66(4.32)/100(293.52) - gen_loss = 0.70222, disc_loss = 1.37903, estimated to finish: 151.21\n",
      "epoch 67(4.33)/100(297.85) - gen_loss = 0.70545, disc_loss = 1.37946, estimated to finish: 146.7\n",
      "epoch 68(4.32)/100(302.17) - gen_loss = 0.71279, disc_loss = 1.37714, estimated to finish: 142.2\n",
      "epoch 69(4.34)/100(306.51) - gen_loss = 0.68595, disc_loss = 1.38655, estimated to finish: 137.71\n",
      "epoch 70(4.36)/100(310.87) - gen_loss = 0.70877, disc_loss = 1.37887, estimated to finish: 133.23\n",
      "epoch 71(4.35)/100(315.22) - gen_loss = 0.70912, disc_loss = 1.3727, estimated to finish: 128.75\n",
      "epoch 72(4.3)/100(319.52) - gen_loss = 0.70061, disc_loss = 1.38896, estimated to finish: 124.26\n",
      "epoch 73(4.33)/100(323.85) - gen_loss = 0.69266, disc_loss = 1.39127, estimated to finish: 119.78\n",
      "epoch 74(4.33)/100(328.18) - gen_loss = 0.71362, disc_loss = 1.36983, estimated to finish: 115.31\n",
      "epoch 75(4.31)/100(332.49) - gen_loss = 0.6847, disc_loss = 1.39901, estimated to finish: 110.83\n",
      "epoch 76(4.31)/100(336.81) - gen_loss = 0.69126, disc_loss = 1.38785, estimated to finish: 106.36\n",
      "epoch 77(4.33)/100(341.14) - gen_loss = 0.69024, disc_loss = 1.3862, estimated to finish: 101.9\n",
      "epoch 78(4.32)/100(345.46) - gen_loss = 0.7077, disc_loss = 1.38687, estimated to finish: 97.44\n",
      "epoch 79(4.36)/100(349.81) - gen_loss = 0.69086, disc_loss = 1.38398, estimated to finish: 92.99\n",
      "epoch 80(4.31)/100(354.12) - gen_loss = 0.69934, disc_loss = 1.38279, estimated to finish: 88.53\n",
      "epoch 81(4.31)/100(358.43) - gen_loss = 0.69986, disc_loss = 1.38188, estimated to finish: 84.08\n",
      "epoch 82(4.35)/100(362.77) - gen_loss = 0.69364, disc_loss = 1.38808, estimated to finish: 79.63\n",
      "epoch 83(4.37)/100(367.14) - gen_loss = 0.71124, disc_loss = 1.37264, estimated to finish: 75.2\n",
      "epoch 84(4.36)/100(371.5) - gen_loss = 0.69457, disc_loss = 1.38754, estimated to finish: 70.76\n",
      "epoch 85(4.32)/100(375.82) - gen_loss = 0.69145, disc_loss = 1.39612, estimated to finish: 66.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86(4.31)/100(380.14) - gen_loss = 0.70206, disc_loss = 1.38572, estimated to finish: 61.88\n",
      "epoch 87(4.32)/100(384.45) - gen_loss = 0.68672, disc_loss = 1.39356, estimated to finish: 57.45\n",
      "epoch 88(4.31)/100(388.77) - gen_loss = 0.69279, disc_loss = 1.39715, estimated to finish: 53.01\n",
      "epoch 89(4.32)/100(393.09) - gen_loss = 0.7003, disc_loss = 1.37264, estimated to finish: 48.58\n",
      "epoch 90(4.31)/100(397.39) - gen_loss = 0.68599, disc_loss = 1.39874, estimated to finish: 44.15\n",
      "epoch 91(4.29)/100(401.68) - gen_loss = 0.69595, disc_loss = 1.39362, estimated to finish: 39.73\n",
      "epoch 92(4.3)/100(405.98) - gen_loss = 0.69177, disc_loss = 1.38613, estimated to finish: 35.3\n",
      "epoch 93(4.26)/100(410.24) - gen_loss = 0.69302, disc_loss = 1.39483, estimated to finish: 30.88\n",
      "epoch 94(4.36)/100(414.6) - gen_loss = 0.69375, disc_loss = 1.37638, estimated to finish: 26.46\n",
      "epoch 95(4.35)/100(418.95) - gen_loss = 0.69776, disc_loss = 1.38479, estimated to finish: 22.05\n",
      "epoch 96(4.36)/100(423.31) - gen_loss = 0.69599, disc_loss = 1.38531, estimated to finish: 17.64\n",
      "epoch 97(4.34)/100(427.65) - gen_loss = 0.69152, disc_loss = 1.39463, estimated to finish: 13.23\n",
      "epoch 98(4.28)/100(431.93) - gen_loss = 0.69518, disc_loss = 1.38197, estimated to finish: 8.81\n",
      "epoch 99(4.34)/100(436.27) - gen_loss = 0.68847, disc_loss = 1.39383, estimated to finish: 4.41\n",
      "epoch 100(4.3)/100(440.57) - gen_loss = 0.69456, disc_loss = 1.38008, estimated to finish: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = Train(seqs_normal, adj, node_f, 100)\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for w in range(5,6):\n",
    "    seqs_normal[w:w+96][9].plot(title='Target 9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for w in range(5,10):          \n",
    "    plot = train.generate()\n",
    "    fig = plot.get_figure()\n",
    "    fig.savefig(\"gen_data/gen_\"+str(w)+\".png\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_space</th>\n",
       "      <th>monthly_fee</th>\n",
       "      <th>住宅</th>\n",
       "      <th>公共</th>\n",
       "      <th>写字楼</th>\n",
       "      <th>商业</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.091667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.486667</td>\n",
       "      <td>0.091667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.091667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.386667</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.686667</td>\n",
       "      <td>0.091667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    total_space  monthly_fee  住宅  公共  写字楼  商业\n",
       "0      0.200000     0.375000   0   0    1   0\n",
       "1      0.900000     0.416667   0   0    1   0\n",
       "2      0.173333     0.750000   0   0    0   1\n",
       "3      0.266667     0.091667   1   0    0   0\n",
       "4      0.486667     0.091667   1   0    0   0\n",
       "5      1.000000     0.250000   0   1    0   0\n",
       "6      0.600000     0.416667   0   0    1   0\n",
       "7      0.620000     0.091667   0   0    1   0\n",
       "8      0.320000     1.000000   0   0    0   1\n",
       "9      0.386667     0.208333   1   0    0   0\n",
       "10     0.686667     0.091667   1   0    0   0"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
